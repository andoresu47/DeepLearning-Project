{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from data_utils import get_CIFAR10_data, get_MNIST_data\n",
    "from CNN import ThreeLayerConvNet\n",
    "from model import Model\n",
    "from ResNet164.resnet164 import ResNet164\n",
    "\n",
    "import h5py\n",
    "import time\n",
    "import pickle\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "# for auto-reloading external modules\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unpickle(file):    \n",
    "    with open(file, 'rb') as fo:\n",
    "        dict = pickle.load(fo, encoding='bytes')\n",
    "    return dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test with CIFAR-10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train:  (49000, 3, 32, 32)\n",
      "y_train:  (49000,)\n",
      "X_val:  (1000, 3, 32, 32)\n",
      "y_val:  (1000,)\n",
      "X_test:  (1000, 3, 32, 32)\n",
      "y_test:  (1000,)\n"
     ]
    }
   ],
   "source": [
    "# Load the (preprocessed) CIFAR10 data.\n",
    "\n",
    "cifar10_data = get_CIFAR10_data()\n",
    "for k, v in cifar10_data.items():\n",
    "  print('%s: ' % k, v.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Iteration 1 / 980) loss: 2.315664\n",
      "(Epoch 0 / 1) train acc: 0.124265; val_acc: 0.121000\n",
      "(Iteration 101 / 980) loss: 1.780725\n",
      "(Iteration 201 / 980) loss: 1.696385\n",
      "(Iteration 301 / 980) loss: 1.507722\n",
      "(Iteration 401 / 980) loss: 1.603677\n",
      "(Iteration 501 / 980) loss: 1.371052\n",
      "(Iteration 601 / 980) loss: 1.662679\n",
      "(Iteration 701 / 980) loss: 1.441571\n",
      "(Iteration 801 / 980) loss: 1.572337\n",
      "(Iteration 901 / 980) loss: 1.395455\n",
      "(Epoch 1 / 1) train acc: 0.503878; val_acc: 0.500000\n"
     ]
    }
   ],
   "source": [
    "net = ThreeLayerConvNet(reg=0.001,weight_scale=0.1)\n",
    "\n",
    "small_model = Model(net, cifar10_data,\n",
    "                num_epochs=1, batch_size=50,\n",
    "                optimizer='adam',\n",
    "                optim_config={\n",
    "                  'learning_rate': 1e-3,\n",
    "                },\n",
    "                verbose=True, print_every=100)\n",
    "tic = time.time()\n",
    "small_model.train()\n",
    "toc = time.time()\n",
    "print('Execution time: ',toc-tic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test with MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train:  (59000, 1, 28, 28)\n",
      "y_train:  (59000,)\n",
      "X_val:  (1000, 1, 28, 28)\n",
      "y_val:  (1000,)\n",
      "X_test:  (10000, 1, 28, 28)\n",
      "y_test:  (10000,)\n"
     ]
    }
   ],
   "source": [
    "# Load MNIST data\n",
    "mnist_data = get_MNIST_data(num_test=10000)\n",
    "for k, v in mnist_data.items():\n",
    "  print('%s: ' % k, v.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Iteration 1 / 590) loss: 2.413948\n",
      "(Epoch 0 / 1) train acc: 0.195034; val_acc: 0.181000\n",
      "(Iteration 101 / 590) loss: 0.808981\n",
      "(Iteration 201 / 590) loss: 0.480308\n",
      "(Iteration 301 / 590) loss: 0.333304\n",
      "(Iteration 401 / 590) loss: 0.365276\n",
      "(Iteration 501 / 590) loss: 0.183830\n",
      "(Epoch 1 / 1) train acc: 0.959441; val_acc: 0.961000\n",
      "Execution time:  447.68891406059265\n"
     ]
    }
   ],
   "source": [
    "net = ThreeLayerConvNet(input_dim=(1, 28, 28),num_filters=28,filter_size=5,hidden_dim=10,\n",
    "                        reg=0.001,weight_scale=1,dtype=np.float32)\n",
    "small_model = Model(net, mnist_data,\n",
    "                num_epochs=1, batch_size=100,\n",
    "                optimizer='adam',\n",
    "                optim_config={\n",
    "                  'learning_rate': 1e-3,\n",
    "                },\n",
    "                verbose=True, print_every=100)\n",
    "tic = time.time()\n",
    "small_model.train()\n",
    "toc = time.time()\n",
    "print('Execution time: ',toc-tic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.9578\n"
     ]
    }
   ],
   "source": [
    "X_test, y_test = mnist_data['X_test'], mnist_data['y_test']\n",
    "\n",
    "print('Test accuracy: {}'.format(small_model.check_accuracy(X_test,y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using data with own preprocessing ResNet164 gives ~87% in test accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(59000, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "# Data for ResNet164\n",
    "x_train = mnist_data['X_train'].transpose(0,2,3,1).copy()\n",
    "x_val = mnist_data['X_val'].transpose(0,2,3,1).copy()\n",
    "x_test = mnist_data['X_test'].transpose(0,2,3,1).copy()\n",
    "print(x_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distill ResNet to small_model for MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ResNet164.utils import load_mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data used in ResNet164\n",
    "(x_train, y_train), (x_val, y_val), (x_test, y_test) = load_mnist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 28, 28, 1)\n",
      "(50000, 10)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "# Load ResNet which achieve 99.7% test accuracy\n",
    "big_model = ResNet164()\n",
    "\n",
    "big_model.compile()\n",
    "# Load pre-trained model\n",
    "big_model.load_weights('ResNet164/ResNet164.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 1662s 33ms/step\n",
      "[-6.2030087  -3.9134192  -6.317644    6.6796656  -2.957327   12.809154\n",
      " -3.4207807   0.18087192  2.3757007   0.04373608]\n"
     ]
    }
   ],
   "source": [
    "logits_train = big_model.predict(x_train, verbose = 1)\n",
    "print(logits_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy of big model: 0.99966\n"
     ]
    }
   ],
   "source": [
    "y_pred_big = np.argmax(SoftMax(logits_train),axis=1)\n",
    "y_true = np.argmax(y_train,axis=1)\n",
    "print('Test accuracy of big model: {}'.format(np.mean(y_true==y_pred_big)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 10)\n"
     ]
    }
   ],
   "source": [
    "print(logits_train.shape)\n",
    "with open('resnet164_logits_train.txt', 'wb') as fp:\n",
    "    pickle.dump(logits_train, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For being faster pick up file of logit from resnet164\n",
    "logits_train = unpickle('resnet164_logits_train.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check accuracy of big model (ResNet164)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 329s 33ms/step\n"
     ]
    }
   ],
   "source": [
    "logits_test = big_model.predict(x_test, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SoftMax(s):\n",
    "    p = np.exp(s-np.expand_dims(np.max(s,axis=1),axis=1))/\\   # minus max to avoid large s case\n",
    "    np.expand_dims(np.exp(s-np.expand_dims(np.max(s,axis=1),axis=1)).sum(axis=1),axis=1)  # matrix of size NxK\n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy of big model: 0.997\n"
     ]
    }
   ],
   "source": [
    "y_pred_big = np.argmax(SoftMax(logits_test),axis=1)\n",
    "y_true = np.argmax(y_test,axis=1)\n",
    "print('Test accuracy of big model: {}'.format(np.mean(y_true==y_pred_big)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data to train with small model\n",
    "data = {'X_train': x_train.transpose(0,3,1,2).copy(), 'y_train': np.argmax(y_train,axis=1),\n",
    "        'X_val': x_val.transpose(0,3,1,2).copy(), 'y_val': np.argmax(y_val,axis=1),\n",
    "        'X_test': x_test.transpose(0,3,1,2).copy(), 'y_test': np.argmax(y_test,axis=1),\n",
    "       }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 28, 28, 1) (50000, 10)\n",
      "(50000, 1, 28, 28) (50000,)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape, y_train.shape)\n",
    "\n",
    "print(data['X_train'].shape, data['y_train'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Iteration 1 / 500) loss: 3.470583\n",
      "(Epoch 0 / 1) train acc: 0.172860; val_acc: 0.175800\n",
      "(Iteration 101 / 500) loss: 0.316082\n",
      "(Iteration 201 / 500) loss: 0.309362\n",
      "(Iteration 301 / 500) loss: 0.142844\n",
      "(Iteration 401 / 500) loss: 0.179971\n",
      "(Epoch 1 / 1) train acc: 0.975500; val_acc: 0.973300\n",
      "Execution time:  394.203412771225\n"
     ]
    }
   ],
   "source": [
    "# Train small model without distilling\n",
    "net = ThreeLayerConvNet(input_dim=(1, 28, 28),num_filters=28,filter_size=5,hidden_dim=50,\n",
    "                        reg=0.001,weight_scale=1,dtype=np.float32)\n",
    "small_model = Model(net, data,\n",
    "                num_epochs=1, batch_size=100,\n",
    "                optimizer='adam',\n",
    "                optim_config={\n",
    "                  'learning_rate': 1e-3,\n",
    "                },\n",
    "                verbose=True, print_every=100)\n",
    "tic = time.time()\n",
    "small_model.train()\n",
    "toc = time.time()\n",
    "print('Execution time: ',toc-tic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.9702\n"
     ]
    }
   ],
   "source": [
    "print('Test accuracy: {}'.format(small_model.check_accuracy(data['X_test'],data['y_test'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Iteration 1 / 500) loss: 31.128427\n",
      "(Epoch 0 / 1) train acc: 0.207020; val_acc: 0.219400\n",
      "(Iteration 101 / 500) loss: 12.530449\n",
      "(Iteration 201 / 500) loss: 11.674805\n",
      "(Iteration 301 / 500) loss: 11.588711\n",
      "(Iteration 401 / 500) loss: 11.688246\n",
      "(Epoch 1 / 1) train acc: 0.980920; val_acc: 0.981300\n",
      "Execution time:  402.96113777160645\n"
     ]
    }
   ],
   "source": [
    "# Train small model with distilling knowledge from big model\n",
    "net = ThreeLayerConvNet(input_dim=(1, 28, 28),num_filters=28,filter_size=5,hidden_dim=50,\n",
    "                        reg=0.001,weight_scale=1,dtype=np.float32)\n",
    "small_model = Model(net, data,\n",
    "                num_epochs=1, batch_size=100,\n",
    "                optimizer='adam',\n",
    "                optim_config={\n",
    "                  'learning_rate': 1e-3,\n",
    "                },\n",
    "                temperature=5.0,logit_distill=logits_train,\n",
    "                verbose=True, print_every=100)\n",
    "tic = time.time()\n",
    "small_model.train()\n",
    "toc = time.time()\n",
    "print('Execution time: ',toc-tic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.9816\n"
     ]
    }
   ],
   "source": [
    "print('Test accuracy: {}'.format(small_model.check_accuracy(data['X_test'],data['y_test'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
