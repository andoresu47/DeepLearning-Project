{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distilling the knowledge in a Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from data_utils import get_CIFAR10_data, get_MNIST_data, unpickle\n",
    "from CNN import ThreeLayerConvNet\n",
    "from model import myModel\n",
    "\n",
    "from ResNet164.resnet164 import ResNet164\n",
    "from ResNet164.utils import load_mnist\n",
    "from VGG16.VGG16 import VGG16\n",
    "from keras.models import Model\n",
    "\n",
    "import h5py\n",
    "import time\n",
    "import pickle\n",
    "import timeit, os, math\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "# for auto-reloading external modules\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNIST data set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ResNet164 as a big model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick up the logit (input of the final SoftMax) which was predicted using ResNet 164 before\n",
    "logits_train = unpickle('ResNet164/resnet164_logits_train.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data used in ResNet164\n",
    "(x_train, y_train), (x_val, y_val), (x_test, y_test) = load_mnist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data to train with small model\n",
    "data = {'X_train': x_train.transpose(0,3,1,2).copy(), 'y_train': np.argmax(y_train,axis=1),\n",
    "        'X_val': x_val.transpose(0,3,1,2).copy(), 'y_val': np.argmax(y_val,axis=1),\n",
    "        'X_test': x_test.transpose(0,3,1,2).copy(), 'y_test': np.argmax(y_test,axis=1),\n",
    "       }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search best temperature for a studen model\n",
    "def searchDistill_temperature(data, num_epochs, batch_size, learning_rate, \n",
    "                              logits_teacher, class_out=None, class_in=None, save_name=None):\n",
    "    T = np.arange(1.0,50.0,0.5)\n",
    "    if class_out is not None or class_in is not None:\n",
    "        accuracy = np.zeros((3,len(T)))\n",
    "    else:\n",
    "        accuracy = np.zeros((2,len(T)))\n",
    "    for i,t in enumerate(T):\n",
    "        tic = time.time()\n",
    "        # Must call network first to reinitialize the parameters. \n",
    "        # Without this the model will use the trained parameters to train\n",
    "        net = ThreeLayerConvNet(input_dim=(1, 28, 28),num_filters=28,filter_size=5,hidden_dim=50,\n",
    "                        reg=0.001,weight_scale=1,dtype=np.float32)\n",
    "        small_model = myModel(net, data,\n",
    "                        num_epochs=num_epochs, batch_size=batch_size,\n",
    "                        optimizer='adam',\n",
    "                        optim_config={\n",
    "                          'learning_rate': learning_rate,\n",
    "                        },\n",
    "                        temperature=t,logit_distill=logits_teacher,\n",
    "                        verbose=False)\n",
    "        small_model.train()\n",
    "        \n",
    "        accuracy[0,i] = t\n",
    "        accuracy[1,i] = small_model.best_val_acc\n",
    "        \n",
    "        if class_out is not None:\n",
    "            mask = data['y_val']==class_out\n",
    "            accuracy[2,i] = small_model.check_accuracy(data['X_val'][mask], data['y_val'][mask])\n",
    "        if class_in is not None:\n",
    "            mask = True\n",
    "            for cl in class_in:\n",
    "                mask = np.logical_and(mask, data['y_val']!=cl)\n",
    "            accuracy[2,i] = small_model.check_accuracy(data['X_val'][mask], data['y_val'][mask])\n",
    "        toc = time.time()\n",
    "        print('Temperature {}, Training acc {}, Validation acc {}, Execution time {}'.format(\n",
    "            t,small_model.train_acc_history[-1], accuracy[1,i],toc-tic))\n",
    "                \n",
    "    # write to the file\n",
    "    if save_name is not None: \n",
    "        name = save_name + '_temperature_search.txt'\n",
    "    else:\n",
    "        name = 'temperature_search.txt'\n",
    "\n",
    "    with open(name, 'wb') as fp:\n",
    "        pickle.dump(accuracy, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time for temperature 1.0 is 387.4820120334625\n",
      "Execution time for temperature 1.5 is 404.292197227478\n",
      "Execution time for temperature 2.0 is 412.21479296684265\n",
      "Execution time for temperature 2.5 is 371.93810391426086\n",
      "Execution time for temperature 3.0 is 366.4074969291687\n",
      "Execution time for temperature 3.5 is 367.27303814888\n",
      "Execution time for temperature 4.0 is 422.70680809020996\n",
      "Execution time for temperature 4.5 is 395.60803604125977\n",
      "Execution time for temperature 5.0 is 370.8509747982025\n",
      "Execution time for temperature 5.5 is 372.39865708351135\n",
      "Execution time for temperature 6.0 is 372.6793038845062\n",
      "Execution time for temperature 6.5 is 372.3903729915619\n",
      "Execution time for temperature 7.0 is 372.86075091362\n",
      "Execution time for temperature 7.5 is 372.43779015541077\n",
      "Execution time for temperature 8.0 is 373.5046968460083\n",
      "Execution time for temperature 8.5 is 372.1003658771515\n",
      "Execution time for temperature 9.0 is 372.278094291687\n",
      "Execution time for temperature 9.5 is 374.2587938308716\n",
      "Execution time for temperature 10.0 is 370.70457339286804\n",
      "Execution time for temperature 10.5 is 374.9321472644806\n",
      "Execution time for temperature 11.0 is 377.47652983665466\n",
      "Execution time for temperature 11.5 is 376.23825097084045\n",
      "Execution time for temperature 12.0 is 393.81321811676025\n",
      "Execution time for temperature 12.5 is 377.26100993156433\n",
      "Execution time for temperature 13.0 is 374.0152049064636\n",
      "Execution time for temperature 13.5 is 377.1446568965912\n",
      "Execution time for temperature 14.0 is 3573.1357679367065\n",
      "Execution time for temperature 14.5 is 397.8638331890106\n",
      "Execution time for temperature 15.0 is 420.30552315711975\n",
      "Execution time for temperature 15.5 is 403.4919979572296\n",
      "Execution time for temperature 16.0 is 398.9339919090271\n",
      "Execution time for temperature 16.5 is 834.6941828727722\n",
      "Execution time for temperature 17.0 is 409.28261494636536\n",
      "Execution time for temperature 17.5 is 374.4482989311218\n",
      "Execution time for temperature 18.0 is 374.14534878730774\n",
      "Execution time for temperature 18.5 is 374.20555090904236\n",
      "Execution time for temperature 19.0 is 372.50093603134155\n",
      "Execution time for temperature 19.5 is 373.06513476371765\n",
      "Execution time for temperature 20.0 is 373.3253779411316\n",
      "Execution time for temperature 20.5 is 370.9899067878723\n",
      "Execution time for temperature 21.0 is 370.806174993515\n",
      "Execution time for temperature 21.5 is 371.21418285369873\n",
      "Execution time for temperature 22.0 is 369.937992811203\n",
      "Execution time for temperature 22.5 is 371.9011151790619\n",
      "Execution time for temperature 23.0 is 371.31463289260864\n",
      "Execution time for temperature 23.5 is 371.3648567199707\n",
      "Execution time for temperature 24.0 is 370.9640519618988\n",
      "Execution time for temperature 24.5 is 370.26444005966187\n",
      "Execution time for temperature 25.0 is 372.0735008716583\n",
      "Execution time for temperature 25.5 is 370.4875121116638\n",
      "Execution time for temperature 26.0 is 371.5469539165497\n",
      "Execution time for temperature 26.5 is 370.4406189918518\n",
      "Execution time for temperature 27.0 is 371.2754099369049\n",
      "Execution time for temperature 27.5 is 370.4753930568695\n",
      "Execution time for temperature 28.0 is 371.78251600265503\n",
      "Execution time for temperature 28.5 is 402.42392587661743\n",
      "Execution time for temperature 29.0 is 398.2497169971466\n",
      "Execution time for temperature 29.5 is 393.39793705940247\n",
      "Execution time for temperature 30.0 is 392.758513212204\n",
      "Execution time for temperature 30.5 is 399.7251739501953\n",
      "Execution time for temperature 31.0 is 457.92074394226074\n",
      "Execution time for temperature 31.5 is 414.3492851257324\n",
      "Execution time for temperature 32.0 is 390.79886984825134\n",
      "Execution time for temperature 32.5 is 400.4172029495239\n",
      "Execution time for temperature 33.0 is 402.98997712135315\n",
      "Execution time for temperature 33.5 is 406.01052689552307\n",
      "Execution time for temperature 34.0 is 401.4237928390503\n",
      "Execution time for temperature 34.5 is 398.82948780059814\n",
      "Execution time for temperature 35.0 is 393.5212028026581\n",
      "Execution time for temperature 35.5 is 398.9375350475311\n",
      "Execution time for temperature 36.0 is 404.2025496959686\n",
      "Execution time for temperature 36.5 is 409.6787009239197\n",
      "Execution time for temperature 37.0 is 388.0445590019226\n",
      "Execution time for temperature 37.5 is 408.22395300865173\n",
      "Execution time for temperature 38.0 is 411.8874008655548\n",
      "Execution time for temperature 38.5 is 394.9163579940796\n",
      "Execution time for temperature 39.0 is 399.5889070034027\n",
      "Execution time for temperature 39.5 is 395.424880027771\n",
      "Execution time for temperature 40.0 is 394.6778178215027\n",
      "Execution time for temperature 40.5 is 431.3330588340759\n",
      "Execution time for temperature 41.0 is 370.44614696502686\n",
      "Execution time for temperature 41.5 is 365.8236873149872\n",
      "Execution time for temperature 42.0 is 370.1821639537811\n",
      "Execution time for temperature 42.5 is 367.0121982097626\n",
      "Execution time for temperature 43.0 is 367.78421902656555\n",
      "Execution time for temperature 43.5 is 365.4746413230896\n",
      "Execution time for temperature 44.0 is 373.6945037841797\n",
      "Execution time for temperature 44.5 is 366.44090485572815\n",
      "Execution time for temperature 45.0 is 365.8129506111145\n",
      "Execution time for temperature 45.5 is 366.27407574653625\n",
      "Execution time for temperature 46.0 is 366.1211566925049\n",
      "Execution time for temperature 46.5 is 366.14461302757263\n",
      "Execution time for temperature 47.0 is 366.1688163280487\n",
      "Execution time for temperature 47.5 is 365.9134359359741\n",
      "Execution time for temperature 48.0 is 366.512912273407\n",
      "Execution time for temperature 48.5 is 366.47870993614197\n",
      "Execution time for temperature 49.0 is 367.15278601646423\n",
      "Execution time for temperature 49.5 is 366.8684780597687\n"
     ]
    }
   ],
   "source": [
    "searchDistill_temperature(data, num_epochs=1, batch_size=100,\n",
    "                              learning_rate=1e-3, logits_teacher=logits_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "T = unpickle('ResNet164/temperature_search.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.      1.5     2.      2.5     3.      3.5     4.      4.5     5.\n",
      "   5.5     6.      6.5     7.      7.5     8.      8.5     9.      9.5\n",
      "  10.     10.5    11.     11.5    12.     12.5    13.     13.5    14.\n",
      "  14.5    15.     15.5    16.     16.5    17.     17.5    18.     18.5\n",
      "  19.     19.5    20.     20.5    21.     21.5    22.     22.5    23.\n",
      "  23.5    24.     24.5    25.     25.5    26.     26.5    27.     27.5\n",
      "  28.     28.5    29.     29.5    30.     30.5    31.     31.5    32.\n",
      "  32.5    33.     33.5    34.     34.5    35.     35.5    36.     36.5\n",
      "  37.     37.5    38.     38.5    39.     39.5    40.     40.5    41.\n",
      "  41.5    42.     42.5    43.     43.5    44.     44.5    45.     45.5\n",
      "  46.     46.5    47.     47.5    48.     48.5    49.     49.5   ]\n",
      " [ 0.977   0.9768  0.9747  0.9735  0.9774  0.9782  0.98    0.9797  0.9795\n",
      "   0.9798  0.9794  0.9781  0.9805  0.9811  0.9788  0.9795  0.9804  0.9808\n",
      "   0.98    0.9786  0.9819  0.9798  0.9792  0.9817  0.9803  0.9796  0.9804\n",
      "   0.9796  0.9804  0.979   0.9775  0.9798  0.9795  0.9791  0.9781  0.9782\n",
      "   0.9779  0.9806  0.9812  0.979   0.9803  0.9792  0.9775  0.9776  0.9793\n",
      "   0.9772  0.9807  0.9806  0.9783  0.9777  0.9776  0.9789  0.9792  0.9778\n",
      "   0.9776  0.9809  0.9795  0.9753  0.9778  0.9784  0.9779  0.9809  0.9795\n",
      "   0.9785  0.98    0.9795  0.9783  0.9781  0.981   0.9782  0.9784  0.9782\n",
      "   0.9785  0.978   0.9794  0.977   0.9798  0.9783  0.9793  0.9781  0.9776\n",
      "   0.9791  0.9766  0.9773  0.9782  0.978   0.9772  0.9785  0.9724  0.98\n",
      "   0.9794  0.9808  0.9789  0.9796  0.9754  0.9789  0.979   0.9791]]\n"
     ]
    }
   ],
   "source": [
    "print(T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.0\n"
     ]
    }
   ],
   "source": [
    "# accuracy increase a little until T = 4.0 and then not change so much\n",
    "i = np.argmax(T[1,:])\n",
    "print(T[0,i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train distill model with dataset omitting a specific class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get out digit 3 from data\n",
    "data_not_3 = data.copy()\n",
    "mask_not_3 = data_not_3['y_train']!=3\n",
    "    \n",
    "data_not_3['X_train'] = data_not_3['X_train'][mask_not_3]\n",
    "data_not_3['y_train'] = data_not_3['y_train'][mask_not_3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "# Load ResNet which achieve 99.7% test accuracy\n",
    "big_model = ResNet164()\n",
    "\n",
    "big_model.compile()\n",
    "# Load pre-trained model\n",
    "big_model.load_weights('ResNet164/ResNet164.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44899/44899 [==============================] - 1583s 35ms/step\n",
      "[-6.2030087  -3.9134192  -6.317644    6.6796656  -2.957327   12.809154\n",
      " -3.4207807   0.18087192  2.3757007   0.04373608]\n"
     ]
    }
   ],
   "source": [
    "# Get logits from teacher model for new dataset\n",
    "logits_not_3 = big_model.predict(x_train[mask_not_3], verbose = 1)\n",
    "print(logits_not_3[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(44899, 10)\n"
     ]
    }
   ],
   "source": [
    "print(logits_not_3.shape)\n",
    "with open('ResNet164/resnet164_logits_not_3.txt', 'wb') as fp:\n",
    "    pickle.dump(logits_not_3, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For being faster pick up file of logit from resnet164\n",
    "logits_not_3 = unpickle('ResNet164/resnet164_logits_not_3.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Temperature 1.0, Validation accuracy 0.8715, Execution time 363.0232141017914\n",
      "Temperature 1.5, Validation accuracy 0.8787, Execution time 335.13925313949585\n",
      "Temperature 2.0, Validation accuracy 0.8755, Execution time 333.1119830608368\n",
      "Temperature 2.5, Validation accuracy 0.8809, Execution time 329.9299228191376\n",
      "Temperature 3.0, Validation accuracy 0.883, Execution time 331.1158969402313\n",
      "Temperature 3.5, Validation accuracy 0.8834, Execution time 329.57569193840027\n",
      "Temperature 4.0, Validation accuracy 0.8795, Execution time 329.90114998817444\n",
      "Temperature 4.5, Validation accuracy 0.8811, Execution time 329.37685918807983\n",
      "Temperature 5.0, Validation accuracy 0.8847, Execution time 330.04841232299805\n",
      "Temperature 5.5, Validation accuracy 0.889, Execution time 332.824871301651\n",
      "Temperature 6.0, Validation accuracy 0.8837, Execution time 332.21027302742004\n",
      "Temperature 6.5, Validation accuracy 0.8883, Execution time 329.65273809432983\n",
      "Temperature 7.0, Validation accuracy 0.8924, Execution time 347.9413809776306\n",
      "Temperature 7.5, Validation accuracy 0.8817, Execution time 357.1751160621643\n",
      "Temperature 8.0, Validation accuracy 0.9033, Execution time 352.6449167728424\n",
      "Temperature 8.5, Validation accuracy 0.8882, Execution time 331.73727083206177\n",
      "Temperature 9.0, Validation accuracy 0.8887, Execution time 330.7622230052948\n",
      "Temperature 9.5, Validation accuracy 0.8817, Execution time 334.841765165329\n",
      "Temperature 10.0, Validation accuracy 0.8869, Execution time 332.6545946598053\n",
      "Temperature 10.5, Validation accuracy 0.8864, Execution time 334.61921429634094\n",
      "Temperature 11.0, Validation accuracy 0.8922, Execution time 337.80496191978455\n",
      "Temperature 11.5, Validation accuracy 0.8851, Execution time 330.9969811439514\n",
      "Temperature 12.0, Validation accuracy 0.8877, Execution time 331.6245348453522\n",
      "Temperature 12.5, Validation accuracy 0.8875, Execution time 330.920866727829\n",
      "Temperature 13.0, Validation accuracy 0.8945, Execution time 330.87878823280334\n",
      "Temperature 13.5, Validation accuracy 0.884, Execution time 330.7653169631958\n",
      "Temperature 14.0, Validation accuracy 0.8849, Execution time 331.73564863204956\n",
      "Temperature 14.5, Validation accuracy 0.8882, Execution time 331.94025588035583\n",
      "Temperature 15.0, Validation accuracy 0.8893, Execution time 332.9639301300049\n",
      "Temperature 15.5, Validation accuracy 0.8892, Execution time 334.453341960907\n",
      "Temperature 16.0, Validation accuracy 0.8808, Execution time 333.4018919467926\n",
      "Temperature 16.5, Validation accuracy 0.9005, Execution time 333.3526096343994\n",
      "Temperature 17.0, Validation accuracy 0.9188, Execution time 333.89109897613525\n",
      "Temperature 17.5, Validation accuracy 0.888, Execution time 333.33668088912964\n",
      "Temperature 18.0, Validation accuracy 0.8856, Execution time 336.4868869781494\n",
      "Temperature 18.5, Validation accuracy 0.8853, Execution time 336.30400586128235\n",
      "Temperature 19.0, Validation accuracy 0.901, Execution time 334.21924924850464\n",
      "Temperature 19.5, Validation accuracy 0.8985, Execution time 334.40500712394714\n",
      "Temperature 20.0, Validation accuracy 0.881, Execution time 346.60238814353943\n",
      "Temperature 20.5, Validation accuracy 0.8951, Execution time 333.42657685279846\n",
      "Temperature 21.0, Validation accuracy 0.9095, Execution time 333.28693890571594\n",
      "Temperature 21.5, Validation accuracy 0.8844, Execution time 333.43355989456177\n",
      "Temperature 22.0, Validation accuracy 0.8971, Execution time 332.7848889827728\n",
      "Temperature 22.5, Validation accuracy 0.8954, Execution time 336.8169569969177\n",
      "Temperature 23.0, Validation accuracy 0.9158, Execution time 373.4572927951813\n",
      "Temperature 23.5, Validation accuracy 0.8821, Execution time 391.4016408920288\n",
      "Temperature 24.0, Validation accuracy 0.887, Execution time 382.68016600608826\n",
      "Temperature 24.5, Validation accuracy 0.8965, Execution time 369.271644115448\n",
      "Temperature 25.0, Validation accuracy 0.8953, Execution time 359.41104912757874\n",
      "Temperature 25.5, Validation accuracy 0.9115, Execution time 351.1094968318939\n",
      "Temperature 26.0, Validation accuracy 0.9135, Execution time 355.94043707847595\n",
      "Temperature 26.5, Validation accuracy 0.9053, Execution time 361.0485141277313\n",
      "Temperature 27.0, Validation accuracy 0.8833, Execution time 352.2778968811035\n",
      "Temperature 27.5, Validation accuracy 0.9007, Execution time 362.0451500415802\n",
      "Temperature 28.0, Validation accuracy 0.9074, Execution time 357.81065583229065\n",
      "Temperature 28.5, Validation accuracy 0.9124, Execution time 385.7215940952301\n",
      "Temperature 29.0, Validation accuracy 0.913, Execution time 396.9828591346741\n",
      "Temperature 29.5, Validation accuracy 0.8842, Execution time 390.6865119934082\n",
      "Temperature 30.0, Validation accuracy 0.8885, Execution time 347.7753987312317\n",
      "Temperature 30.5, Validation accuracy 0.8954, Execution time 345.83280897140503\n",
      "Temperature 31.0, Validation accuracy 0.8893, Execution time 364.4556269645691\n",
      "Temperature 31.5, Validation accuracy 0.8811, Execution time 365.0923330783844\n",
      "Temperature 32.0, Validation accuracy 0.8845, Execution time 354.8907618522644\n",
      "Temperature 32.5, Validation accuracy 0.9021, Execution time 364.2330701351166\n",
      "Temperature 33.0, Validation accuracy 0.8799, Execution time 352.6189522743225\n",
      "Temperature 33.5, Validation accuracy 0.8938, Execution time 353.29319286346436\n",
      "Temperature 34.0, Validation accuracy 0.9022, Execution time 369.6336028575897\n",
      "Temperature 34.5, Validation accuracy 0.8822, Execution time 379.69110679626465\n",
      "Temperature 35.0, Validation accuracy 0.8891, Execution time 378.50274109840393\n",
      "Temperature 35.5, Validation accuracy 0.9141, Execution time 380.42086601257324\n",
      "Temperature 36.0, Validation accuracy 0.9178, Execution time 367.631530046463\n",
      "Temperature 36.5, Validation accuracy 0.9072, Execution time 363.63326692581177\n",
      "Temperature 37.0, Validation accuracy 0.8926, Execution time 362.50896883010864\n",
      "Temperature 37.5, Validation accuracy 0.8949, Execution time 364.55182933807373\n",
      "Temperature 38.0, Validation accuracy 0.9082, Execution time 368.69571900367737\n",
      "Temperature 38.5, Validation accuracy 0.909, Execution time 453.3123106956482\n",
      "Temperature 39.0, Validation accuracy 0.9068, Execution time 337.0215916633606\n",
      "Temperature 39.5, Validation accuracy 0.8868, Execution time 335.0832886695862\n",
      "Temperature 40.0, Validation accuracy 0.88, Execution time 340.23708605766296\n",
      "Temperature 40.5, Validation accuracy 0.8994, Execution time 336.6101288795471\n",
      "Temperature 41.0, Validation accuracy 0.9115, Execution time 334.27570509910583\n",
      "Temperature 41.5, Validation accuracy 0.8943, Execution time 334.45667004585266\n",
      "Temperature 42.0, Validation accuracy 0.8875, Execution time 333.6848289966583\n",
      "Temperature 42.5, Validation accuracy 0.8802, Execution time 334.31892800331116\n",
      "Temperature 43.0, Validation accuracy 0.9055, Execution time 335.9469072818756\n",
      "Temperature 43.5, Validation accuracy 0.8808, Execution time 333.6867461204529\n",
      "Temperature 44.0, Validation accuracy 0.9147, Execution time 336.20032382011414\n",
      "Temperature 44.5, Validation accuracy 0.8872, Execution time 334.5976939201355\n",
      "Temperature 45.0, Validation accuracy 0.913, Execution time 334.2925271987915\n",
      "Temperature 45.5, Validation accuracy 0.8981, Execution time 333.77885127067566\n",
      "Temperature 46.0, Validation accuracy 0.8822, Execution time 333.5999710559845\n",
      "Temperature 46.5, Validation accuracy 0.8875, Execution time 335.0279848575592\n",
      "Temperature 47.0, Validation accuracy 0.8862, Execution time 334.684916973114\n",
      "Temperature 47.5, Validation accuracy 0.8863, Execution time 334.97758412361145\n",
      "Temperature 48.0, Validation accuracy 0.8972, Execution time 335.6517918109894\n",
      "Temperature 48.5, Validation accuracy 0.9024, Execution time 340.39299607276917\n",
      "Temperature 49.0, Validation accuracy 0.8877, Execution time 337.2701208591461\n",
      "Temperature 49.5, Validation accuracy 0.8897, Execution time 335.2986361980438\n"
     ]
    }
   ],
   "source": [
    "searchDistill_temperature(data_not_3, num_epochs=1, batch_size=100,\n",
    "                          learning_rate=1e-3, logits_teacher=logits_not_3, \n",
    "                          class_out=3, save_name='ResNet164/not_3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.00000000e+00 8.71500000e-01 0.00000000e+00]\n",
      " [1.50000000e+00 8.78700000e-01 0.00000000e+00]\n",
      " [2.00000000e+00 8.75500000e-01 0.00000000e+00]\n",
      " [2.50000000e+00 8.80900000e-01 5.82524272e-03]\n",
      " [3.00000000e+00 8.83000000e-01 2.62135922e-02]\n",
      " [3.50000000e+00 8.83400000e-01 2.81553398e-02]\n",
      " [4.00000000e+00 8.79500000e-01 1.26213592e-02]\n",
      " [4.50000000e+00 8.81100000e-01 0.00000000e+00]\n",
      " [5.00000000e+00 8.84700000e-01 4.75728155e-02]\n",
      " [5.50000000e+00 8.89000000e-01 6.89320388e-02]\n",
      " [6.00000000e+00 8.83700000e-01 1.84466019e-02]\n",
      " [6.50000000e+00 8.88300000e-01 7.66990291e-02]\n",
      " [7.00000000e+00 8.92400000e-01 9.70873786e-02]\n",
      " [7.50000000e+00 8.81700000e-01 0.00000000e+00]\n",
      " [8.00000000e+00 9.03300000e-01 2.25242718e-01]\n",
      " [8.50000000e+00 8.88200000e-01 7.66990291e-02]\n",
      " [9.00000000e+00 8.88700000e-01 5.92233010e-02]\n",
      " [9.50000000e+00 8.81700000e-01 8.73786408e-03]\n",
      " [1.00000000e+01 8.86900000e-01 6.21359223e-02]\n",
      " [1.05000000e+01 8.86400000e-01 5.43689320e-02]\n",
      " [1.10000000e+01 8.92200000e-01 1.17475728e-01]\n",
      " [1.15000000e+01 8.85100000e-01 3.98058252e-02]\n",
      " [1.20000000e+01 8.87700000e-01 5.63106796e-02]\n",
      " [1.25000000e+01 8.87500000e-01 8.34951456e-02]\n",
      " [1.30000000e+01 8.94500000e-01 1.34951456e-01]\n",
      " [1.35000000e+01 8.84000000e-01 2.42718447e-02]\n",
      " [1.40000000e+01 8.84900000e-01 3.30097087e-02]\n",
      " [1.45000000e+01 8.88200000e-01 7.57281553e-02]\n",
      " [1.50000000e+01 8.89300000e-01 8.64077670e-02]\n",
      " [1.55000000e+01 8.89200000e-01 9.02912621e-02]\n",
      " [1.60000000e+01 8.80800000e-01 0.00000000e+00]\n",
      " [1.65000000e+01 9.00500000e-01 1.91262136e-01]\n",
      " [1.70000000e+01 9.18800000e-01 3.78640777e-01]\n",
      " [1.75000000e+01 8.88000000e-01 5.24271845e-02]\n",
      " [1.80000000e+01 8.85600000e-01 3.39805825e-02]\n",
      " [1.85000000e+01 8.85300000e-01 4.66019417e-02]\n",
      " [1.90000000e+01 9.01000000e-01 1.98058252e-01]\n",
      " [1.95000000e+01 8.98500000e-01 1.68932039e-01]\n",
      " [2.00000000e+01 8.81000000e-01 3.30097087e-02]\n",
      " [2.05000000e+01 8.95100000e-01 1.45631068e-01]\n",
      " [2.10000000e+01 9.09500000e-01 2.78640777e-01]\n",
      " [2.15000000e+01 8.84400000e-01 4.85436893e-02]\n",
      " [2.20000000e+01 8.97100000e-01 1.79611650e-01]\n",
      " [2.25000000e+01 8.95400000e-01 1.47572816e-01]\n",
      " [2.30000000e+01 9.15800000e-01 3.58252427e-01]\n",
      " [2.35000000e+01 8.82100000e-01 5.82524272e-03]\n",
      " [2.40000000e+01 8.87000000e-01 8.44660194e-02]\n",
      " [2.45000000e+01 8.96500000e-01 1.66019417e-01]\n",
      " [2.50000000e+01 8.95300000e-01 1.51456311e-01]\n",
      " [2.55000000e+01 9.11500000e-01 2.89320388e-01]\n",
      " [2.60000000e+01 9.13500000e-01 3.18446602e-01]\n",
      " [2.65000000e+01 9.05300000e-01 2.52427184e-01]\n",
      " [2.70000000e+01 8.83300000e-01 4.56310680e-02]\n",
      " [2.75000000e+01 9.00700000e-01 2.03883495e-01]\n",
      " [2.80000000e+01 9.07400000e-01 2.52427184e-01]\n",
      " [2.85000000e+01 9.12400000e-01 2.98058252e-01]\n",
      " [2.90000000e+01 9.13000000e-01 3.16504854e-01]\n",
      " [2.95000000e+01 8.84200000e-01 4.36893204e-02]\n",
      " [3.00000000e+01 8.88500000e-01 8.54368932e-02]\n",
      " [3.05000000e+01 8.95400000e-01 1.55339806e-01]\n",
      " [3.10000000e+01 8.89300000e-01 7.57281553e-02]\n",
      " [3.15000000e+01 8.81100000e-01 5.82524272e-03]\n",
      " [3.20000000e+01 8.84500000e-01 2.62135922e-02]\n",
      " [3.25000000e+01 9.02100000e-01 2.18446602e-01]\n",
      " [3.30000000e+01 8.79900000e-01 5.63106796e-02]\n",
      " [3.35000000e+01 8.93800000e-01 1.30097087e-01]\n",
      " [3.40000000e+01 9.02200000e-01 2.10679612e-01]\n",
      " [3.45000000e+01 8.82200000e-01 2.42718447e-02]\n",
      " [3.50000000e+01 8.89100000e-01 8.54368932e-02]\n",
      " [3.55000000e+01 9.14100000e-01 3.28155340e-01]\n",
      " [3.60000000e+01 9.17800000e-01 3.63106796e-01]\n",
      " [3.65000000e+01 9.07200000e-01 2.72815534e-01]\n",
      " [3.70000000e+01 8.92600000e-01 1.28155340e-01]\n",
      " [3.75000000e+01 8.94900000e-01 1.43689320e-01]\n",
      " [3.80000000e+01 9.08200000e-01 2.62135922e-01]\n",
      " [3.85000000e+01 9.09000000e-01 2.70873786e-01]\n",
      " [3.90000000e+01 9.06800000e-01 2.72815534e-01]\n",
      " [3.95000000e+01 8.86800000e-01 7.66990291e-02]\n",
      " [4.00000000e+01 8.80000000e-01 1.55339806e-02]\n",
      " [4.05000000e+01 8.99400000e-01 1.88349515e-01]\n",
      " [4.10000000e+01 9.11500000e-01 3.09708738e-01]\n",
      " [4.15000000e+01 8.94300000e-01 1.41747573e-01]\n",
      " [4.20000000e+01 8.87500000e-01 7.37864078e-02]\n",
      " [4.25000000e+01 8.80200000e-01 2.81553398e-02]\n",
      " [4.30000000e+01 9.05500000e-01 2.40776699e-01]\n",
      " [4.35000000e+01 8.80800000e-01 2.03883495e-02]\n",
      " [4.40000000e+01 9.14700000e-01 3.36893204e-01]\n",
      " [4.45000000e+01 8.87200000e-01 8.93203883e-02]\n",
      " [4.50000000e+01 9.13000000e-01 3.28155340e-01]\n",
      " [4.55000000e+01 8.98100000e-01 1.61165049e-01]\n",
      " [4.60000000e+01 8.82200000e-01 1.55339806e-02]\n",
      " [4.65000000e+01 8.87500000e-01 1.03883495e-01]\n",
      " [4.70000000e+01 8.86200000e-01 6.79611650e-02]\n",
      " [4.75000000e+01 8.86300000e-01 6.89320388e-02]\n",
      " [4.80000000e+01 8.97200000e-01 1.58252427e-01]\n",
      " [4.85000000e+01 9.02400000e-01 2.04854369e-01]\n",
      " [4.90000000e+01 8.87700000e-01 8.44660194e-02]\n",
      " [4.95000000e+01 8.89700000e-01 9.41747573e-02]]\n"
     ]
    }
   ],
   "source": [
    "T = unpickle('ResNet164/not_3_temperature_search.txt')\n",
    "print(T.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get data with only digit 7 and 8\n",
    "data_7_8 = data.copy()\n",
    "mask_7_8 = np.logical_or(data['y_train']==7, data['y_train']==8)\n",
    "    \n",
    "data_7_8['X_train'] = data_7_8['X_train'][mask_7_8]\n",
    "data_7_8['y_train'] = data_7_8['y_train'][mask_7_8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10017\n"
     ]
    }
   ],
   "source": [
    "print(sum(mask_7_8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10017/10017 [==============================] - 324s 32ms/step\n",
      "[-1.1341337  0.8800306  2.634239  -0.8169588 -1.7799497 -5.7832465\n",
      " -9.071484  16.43823   -4.005032   3.3581958]\n",
      "(10017, 10)\n"
     ]
    }
   ],
   "source": [
    "# Get logits from teacher model for new dataset\n",
    "logits_7_8 = big_model.predict(x_train[mask_7_8], verbose = 1)\n",
    "print(logits_7_8[0])\n",
    "print(logits_7_8.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('ResNet164/resnet164_logits_7_8.txt', 'wb') as fp:\n",
    "    pickle.dump(logits_7_8, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Temperature 1.0, Training acc 0.9959069581711091, Validation acc 0.2083, Execution time 86.46539497375488\n",
      "Temperature 1.5, Training acc 0.9916142557651991, Validation acc 0.2076, Execution time 86.74065589904785\n",
      "Temperature 2.0, Training acc 0.9949086552860138, Validation acc 0.2089, Execution time 85.94187068939209\n",
      "Temperature 2.5, Training acc 0.9962064490366377, Validation acc 0.2126, Execution time 90.26660513877869\n",
      "Temperature 3.0, Training acc 0.9962064490366377, Validation acc 0.2106, Execution time 86.58881402015686\n",
      "Temperature 3.5, Training acc 0.99570729759409, Validation acc 0.2091, Execution time 88.85907030105591\n",
      "Temperature 4.0, Training acc 0.9953079764400519, Validation acc 0.2085, Execution time 86.62404584884644\n",
      "Temperature 4.5, Training acc 0.9944095038434662, Validation acc 0.2086, Execution time 87.35391306877136\n",
      "Temperature 5.0, Training acc 0.9963062793251473, Validation acc 0.2087, Execution time 88.70967197418213\n",
      "Temperature 5.5, Training acc 0.9951083158630328, Validation acc 0.2091, Execution time 88.69212579727173\n",
      "Temperature 6.0, Training acc 0.9964061096136568, Validation acc 0.2089, Execution time 87.16164898872375\n",
      "Temperature 6.5, Training acc 0.9960067884596187, Validation acc 0.209, Execution time 86.99484014511108\n",
      "Temperature 7.0, Training acc 0.9953079764400519, Validation acc 0.2086, Execution time 86.790118932724\n",
      "Temperature 7.5, Training acc 0.9949086552860138, Validation acc 0.2088, Execution time 86.8297131061554\n",
      "Temperature 8.0, Training acc 0.9953079764400519, Validation acc 0.2086, Execution time 86.85235404968262\n",
      "Temperature 8.5, Training acc 0.9949086552860138, Validation acc 0.2089, Execution time 86.80561470985413\n",
      "Temperature 9.0, Training acc 0.9962064490366377, Validation acc 0.2089, Execution time 669.1826841831207\n",
      "Temperature 9.5, Training acc 0.9958071278825996, Validation acc 0.2088, Execution time 87.17821478843689\n",
      "Temperature 10.0, Training acc 0.9945093341319756, Validation acc 0.2086, Execution time 90.46909070014954\n",
      "Temperature 10.5, Training acc 0.9953079764400519, Validation acc 0.2119, Execution time 88.83232402801514\n",
      "Temperature 11.0, Training acc 0.9954078067285614, Validation acc 0.2104, Execution time 90.6022720336914\n",
      "Temperature 11.5, Training acc 0.99570729759409, Validation acc 0.2087, Execution time 89.0306990146637\n",
      "Temperature 12.0, Training acc 0.9958071278825996, Validation acc 0.2093, Execution time 93.74546980857849\n",
      "Temperature 12.5, Training acc 0.9949086552860138, Validation acc 0.2089, Execution time 91.84997606277466\n",
      "Temperature 13.0, Training acc 0.9967056004791854, Validation acc 0.2091, Execution time 92.6866397857666\n",
      "Temperature 13.5, Training acc 0.9952081461515424, Validation acc 0.2091, Execution time 86.68630290031433\n",
      "Temperature 14.0, Training acc 0.9953079764400519, Validation acc 0.2122, Execution time 86.53800797462463\n",
      "Temperature 14.5, Training acc 0.99570729759409, Validation acc 0.2092, Execution time 87.10872292518616\n",
      "Temperature 15.0, Training acc 0.995507637017071, Validation acc 0.2101, Execution time 86.17732810974121\n",
      "Temperature 15.5, Training acc 0.9951083158630328, Validation acc 0.209, Execution time 86.35888934135437\n",
      "Temperature 16.0, Training acc 0.9946091644204852, Validation acc 0.2102, Execution time 87.52779603004456\n",
      "Temperature 16.5, Training acc 0.9952081461515424, Validation acc 0.2088, Execution time 265.3206708431244\n",
      "Temperature 17.0, Training acc 0.9952081461515424, Validation acc 0.2088, Execution time 90.28440809249878\n",
      "Temperature 17.5, Training acc 0.9948088249975042, Validation acc 0.2091, Execution time 91.40161085128784\n",
      "Temperature 18.0, Training acc 0.995507637017071, Validation acc 0.2094, Execution time 95.3511860370636\n",
      "Temperature 18.5, Training acc 0.9951083158630328, Validation acc 0.2103, Execution time 90.56528091430664\n",
      "Temperature 19.0, Training acc 0.9954078067285614, Validation acc 0.2089, Execution time 93.16698288917542\n",
      "Temperature 19.5, Training acc 0.9952081461515424, Validation acc 0.2088, Execution time 90.5825891494751\n",
      "Temperature 20.0, Training acc 0.9958071278825996, Validation acc 0.2097, Execution time 93.4381411075592\n",
      "Temperature 20.5, Training acc 0.9952081461515424, Validation acc 0.2088, Execution time 92.1558883190155\n",
      "Temperature 21.0, Training acc 0.994209843266447, Validation acc 0.2097, Execution time 93.21042776107788\n",
      "Temperature 21.5, Training acc 0.9958071278825996, Validation acc 0.2092, Execution time 93.15896010398865\n",
      "Temperature 22.0, Training acc 0.995507637017071, Validation acc 0.2099, Execution time 89.67056918144226\n",
      "Temperature 22.5, Training acc 0.9952081461515424, Validation acc 0.2104, Execution time 91.04089188575745\n",
      "Temperature 23.0, Training acc 0.9953079764400519, Validation acc 0.2091, Execution time 95.52242112159729\n",
      "Temperature 23.5, Training acc 0.9959069581711091, Validation acc 0.2091, Execution time 90.64765214920044\n",
      "Temperature 24.0, Training acc 0.995507637017071, Validation acc 0.2105, Execution time 97.98893284797668\n",
      "Temperature 24.5, Training acc 0.9954078067285614, Validation acc 0.2088, Execution time 97.47128009796143\n",
      "Temperature 25.0, Training acc 0.9953079764400519, Validation acc 0.2108, Execution time 97.09213900566101\n",
      "Temperature 25.5, Training acc 0.9954078067285614, Validation acc 0.209, Execution time 90.0612587928772\n",
      "Temperature 26.0, Training acc 0.9935110312468803, Validation acc 0.2096, Execution time 92.12911081314087\n",
      "Temperature 26.5, Training acc 0.995507637017071, Validation acc 0.2105, Execution time 96.83396983146667\n",
      "Temperature 27.0, Training acc 0.995507637017071, Validation acc 0.2112, Execution time 87.48353815078735\n",
      "Temperature 27.5, Training acc 0.9946091644204852, Validation acc 0.209, Execution time 86.49890398979187\n",
      "Temperature 28.0, Training acc 0.9951083158630328, Validation acc 0.2091, Execution time 87.84474921226501\n",
      "Temperature 28.5, Training acc 0.9945093341319756, Validation acc 0.2118, Execution time 391.0133602619171\n",
      "Temperature 29.0, Training acc 0.9946091644204852, Validation acc 0.2111, Execution time 104.19572925567627\n",
      "Temperature 29.5, Training acc 0.9954078067285614, Validation acc 0.2142, Execution time 107.65821528434753\n",
      "Temperature 30.0, Training acc 0.9960067884596187, Validation acc 0.2113, Execution time 99.69076919555664\n",
      "Temperature 30.5, Training acc 0.9948088249975042, Validation acc 0.2105, Execution time 92.32502818107605\n",
      "Temperature 31.0, Training acc 0.9949086552860138, Validation acc 0.2092, Execution time 102.00217914581299\n",
      "Temperature 31.5, Training acc 0.9954078067285614, Validation acc 0.2113, Execution time 95.44012784957886\n",
      "Temperature 32.0, Training acc 0.9954078067285614, Validation acc 0.2088, Execution time 98.88430523872375\n",
      "Temperature 32.5, Training acc 0.9951083158630328, Validation acc 0.2095, Execution time 95.28130173683167\n",
      "Temperature 33.0, Training acc 0.9961066187481282, Validation acc 0.2118, Execution time 99.42159080505371\n",
      "Temperature 33.5, Training acc 0.9950084855745233, Validation acc 0.2111, Execution time 94.0969750881195\n",
      "Temperature 34.0, Training acc 0.9959069581711091, Validation acc 0.2091, Execution time 88.2757670879364\n",
      "Temperature 34.5, Training acc 0.995507637017071, Validation acc 0.2123, Execution time 94.5203149318695\n",
      "Temperature 35.0, Training acc 0.9944095038434662, Validation acc 0.2091, Execution time 87.40085792541504\n",
      "Temperature 35.5, Training acc 0.9956074673055805, Validation acc 0.2108, Execution time 87.98967599868774\n",
      "Temperature 36.0, Training acc 0.9945093341319756, Validation acc 0.2128, Execution time 91.00474691390991\n",
      "Temperature 36.5, Training acc 0.9956074673055805, Validation acc 0.2108, Execution time 103.55998015403748\n",
      "Temperature 37.0, Training acc 0.9956074673055805, Validation acc 0.2103, Execution time 93.60013794898987\n",
      "Temperature 37.5, Training acc 0.9950084855745233, Validation acc 0.213, Execution time 92.38389778137207\n",
      "Temperature 38.0, Training acc 0.9946091644204852, Validation acc 0.2103, Execution time 98.00786209106445\n",
      "Temperature 38.5, Training acc 0.994010182689428, Validation acc 0.2098, Execution time 107.78089594841003\n",
      "Temperature 39.0, Training acc 0.9956074673055805, Validation acc 0.2095, Execution time 98.18403697013855\n",
      "Temperature 39.5, Training acc 0.9956074673055805, Validation acc 0.2146, Execution time 101.82977724075317\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Temperature 40.0, Training acc 0.9936108615353898, Validation acc 0.2098, Execution time 95.30957198143005\n",
      "Temperature 40.5, Training acc 0.9956074673055805, Validation acc 0.2086, Execution time 87.16808700561523\n",
      "Temperature 41.0, Training acc 0.9956074673055805, Validation acc 0.2109, Execution time 90.91860389709473\n",
      "Temperature 41.5, Training acc 0.9956074673055805, Validation acc 0.2096, Execution time 90.25294804573059\n",
      "Temperature 42.0, Training acc 0.9945093341319756, Validation acc 0.2092, Execution time 88.49704217910767\n",
      "Temperature 42.5, Training acc 0.9950084855745233, Validation acc 0.2103, Execution time 104.67101621627808\n",
      "Temperature 43.0, Training acc 0.9947089947089947, Validation acc 0.2129, Execution time 92.67923307418823\n",
      "Temperature 43.5, Training acc 0.9952081461515424, Validation acc 0.211, Execution time 89.91246581077576\n",
      "Temperature 44.0, Training acc 0.9962064490366377, Validation acc 0.2107, Execution time 94.59250903129578\n",
      "Temperature 44.5, Training acc 0.9960067884596187, Validation acc 0.2129, Execution time 90.64534878730774\n",
      "Temperature 45.0, Training acc 0.9959069581711091, Validation acc 0.2106, Execution time 94.38356518745422\n",
      "Temperature 45.5, Training acc 0.9949086552860138, Validation acc 0.2101, Execution time 89.08698797225952\n",
      "Temperature 46.0, Training acc 0.9959069581711091, Validation acc 0.2104, Execution time 87.03701996803284\n",
      "Temperature 46.5, Training acc 0.995507637017071, Validation acc 0.2096, Execution time 89.26393008232117\n",
      "Temperature 47.0, Training acc 0.995507637017071, Validation acc 0.2105, Execution time 86.51370596885681\n",
      "Temperature 47.5, Training acc 0.9959069581711091, Validation acc 0.2133, Execution time 84.67297697067261\n",
      "Temperature 48.0, Training acc 0.9949086552860138, Validation acc 0.2112, Execution time 89.88829898834229\n",
      "Temperature 48.5, Training acc 0.9956074673055805, Validation acc 0.2115, Execution time 89.32442998886108\n",
      "Temperature 49.0, Training acc 0.9954078067285614, Validation acc 0.2104, Execution time 88.24894499778748\n",
      "Temperature 49.5, Training acc 0.9947089947089947, Validation acc 0.2096, Execution time 92.33925485610962\n"
     ]
    }
   ],
   "source": [
    "searchDistill_temperature(data_7_8, num_epochs=1, batch_size=50,\n",
    "                          learning_rate=1e-3, logits_teacher=logits_7_8, \n",
    "                          class_in=[7,8], save_name='ResNet164/7_8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Search 'optimal' bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.00000000e+00 2.08300000e-01 0.00000000e+00]\n",
      " [1.50000000e+00 2.07600000e-01 0.00000000e+00]\n",
      " [2.00000000e+00 2.08900000e-01 0.00000000e+00]\n",
      " [2.50000000e+00 2.12600000e-01 5.18921655e-03]\n",
      " [3.00000000e+00 2.10600000e-01 2.15162638e-03]\n",
      " [3.50000000e+00 2.09100000e-01 0.00000000e+00]\n",
      " [4.00000000e+00 2.08500000e-01 0.00000000e+00]\n",
      " [4.50000000e+00 2.08600000e-01 0.00000000e+00]\n",
      " [5.00000000e+00 2.08700000e-01 0.00000000e+00]\n",
      " [5.50000000e+00 2.09100000e-01 1.26566257e-04]\n",
      " [6.00000000e+00 2.08900000e-01 0.00000000e+00]\n",
      " [6.50000000e+00 2.09000000e-01 2.53132515e-04]\n",
      " [7.00000000e+00 2.08600000e-01 0.00000000e+00]\n",
      " [7.50000000e+00 2.08800000e-01 1.26566257e-04]\n",
      " [8.00000000e+00 2.08600000e-01 0.00000000e+00]\n",
      " [8.50000000e+00 2.08900000e-01 0.00000000e+00]\n",
      " [9.00000000e+00 2.08900000e-01 0.00000000e+00]\n",
      " [9.50000000e+00 2.08800000e-01 0.00000000e+00]\n",
      " [1.00000000e+01 2.08600000e-01 0.00000000e+00]\n",
      " [1.05000000e+01 2.11900000e-01 3.41728895e-03]\n",
      " [1.10000000e+01 2.10400000e-01 1.89849386e-03]\n",
      " [1.15000000e+01 2.08700000e-01 0.00000000e+00]\n",
      " [1.20000000e+01 2.09300000e-01 2.53132515e-04]\n",
      " [1.25000000e+01 2.08900000e-01 2.53132515e-04]\n",
      " [1.30000000e+01 2.09100000e-01 0.00000000e+00]\n",
      " [1.35000000e+01 2.09100000e-01 6.32831287e-04]\n",
      " [1.40000000e+01 2.12200000e-01 4.30325275e-03]\n",
      " [1.45000000e+01 2.09200000e-01 0.00000000e+00]\n",
      " [1.50000000e+01 2.10100000e-01 1.89849386e-03]\n",
      " [1.55000000e+01 2.09000000e-01 1.26566257e-04]\n",
      " [1.60000000e+01 2.10200000e-01 1.77192760e-03]\n",
      " [1.65000000e+01 2.08800000e-01 3.79698772e-04]\n",
      " [1.70000000e+01 2.08800000e-01 0.00000000e+00]\n",
      " [1.75000000e+01 2.09100000e-01 6.32831287e-04]\n",
      " [1.80000000e+01 2.09400000e-01 5.06265030e-04]\n",
      " [1.85000000e+01 2.10300000e-01 1.64536135e-03]\n",
      " [1.90000000e+01 2.08900000e-01 0.00000000e+00]\n",
      " [1.95000000e+01 2.08800000e-01 0.00000000e+00]\n",
      " [2.00000000e+01 2.09700000e-01 1.01253006e-03]\n",
      " [2.05000000e+01 2.08800000e-01 2.53132515e-04]\n",
      " [2.10000000e+01 2.09700000e-01 1.13909632e-03]\n",
      " [2.15000000e+01 2.09200000e-01 2.53132515e-04]\n",
      " [2.20000000e+01 2.09900000e-01 1.26566257e-03]\n",
      " [2.25000000e+01 2.10400000e-01 1.89849386e-03]\n",
      " [2.30000000e+01 2.09100000e-01 1.26566257e-04]\n",
      " [2.35000000e+01 2.09100000e-01 2.53132515e-04]\n",
      " [2.40000000e+01 2.10500000e-01 1.89849386e-03]\n",
      " [2.45000000e+01 2.08800000e-01 0.00000000e+00]\n",
      " [2.50000000e+01 2.10800000e-01 2.02506012e-03]\n",
      " [2.55000000e+01 2.09000000e-01 5.06265030e-04]\n",
      " [2.60000000e+01 2.09600000e-01 1.39222883e-03]\n",
      " [2.65000000e+01 2.10500000e-01 2.15162638e-03]\n",
      " [2.70000000e+01 2.11200000e-01 3.16415644e-03]\n",
      " [2.75000000e+01 2.09000000e-01 1.26566257e-04]\n",
      " [2.80000000e+01 2.09100000e-01 2.53132515e-04]\n",
      " [2.85000000e+01 2.11800000e-01 3.16415644e-03]\n",
      " [2.90000000e+01 2.11100000e-01 2.91102392e-03]\n",
      " [2.95000000e+01 2.14200000e-01 6.70801164e-03]\n",
      " [3.00000000e+01 2.11300000e-01 3.16415644e-03]\n",
      " [3.05000000e+01 2.10500000e-01 2.53132515e-03]\n",
      " [3.10000000e+01 2.09200000e-01 1.01253006e-03]\n",
      " [3.15000000e+01 2.11300000e-01 3.16415644e-03]\n",
      " [3.20000000e+01 2.08800000e-01 1.26566257e-04]\n",
      " [3.25000000e+01 2.09500000e-01 3.79698772e-04]\n",
      " [3.30000000e+01 2.11800000e-01 3.54385521e-03]\n",
      " [3.35000000e+01 2.11100000e-01 2.65789141e-03]\n",
      " [3.40000000e+01 2.09100000e-01 3.79698772e-04]\n",
      " [3.45000000e+01 2.12300000e-01 4.68295153e-03]\n",
      " [3.50000000e+01 2.09100000e-01 7.59397545e-04]\n",
      " [3.55000000e+01 2.10800000e-01 2.53132515e-03]\n",
      " [3.60000000e+01 2.12800000e-01 5.18921655e-03]\n",
      " [3.65000000e+01 2.10800000e-01 2.40475889e-03]\n",
      " [3.70000000e+01 2.10300000e-01 1.39222883e-03]\n",
      " [3.75000000e+01 2.13000000e-01 5.94861410e-03]\n",
      " [3.80000000e+01 2.10300000e-01 1.77192760e-03]\n",
      " [3.85000000e+01 2.09800000e-01 1.13909632e-03]\n",
      " [3.90000000e+01 2.09500000e-01 8.85963802e-04]\n",
      " [3.95000000e+01 2.14600000e-01 6.83457790e-03]\n",
      " [4.00000000e+01 2.09800000e-01 1.51879509e-03]\n",
      " [4.05000000e+01 2.08600000e-01 1.26566257e-04]\n",
      " [4.10000000e+01 2.10900000e-01 2.78445766e-03]\n",
      " [4.15000000e+01 2.09600000e-01 1.01253006e-03]\n",
      " [4.20000000e+01 2.09200000e-01 5.06265030e-04]\n",
      " [4.25000000e+01 2.10300000e-01 1.64536135e-03]\n",
      " [4.30000000e+01 2.12900000e-01 5.18921655e-03]\n",
      " [4.35000000e+01 2.11000000e-01 2.53132515e-03]\n",
      " [4.40000000e+01 2.10700000e-01 2.27819263e-03]\n",
      " [4.45000000e+01 2.12900000e-01 4.68295153e-03]\n",
      " [4.50000000e+01 2.10600000e-01 1.89849386e-03]\n",
      " [4.55000000e+01 2.10100000e-01 1.77192760e-03]\n",
      " [4.60000000e+01 2.10400000e-01 1.51879509e-03]\n",
      " [4.65000000e+01 2.09600000e-01 8.85963802e-04]\n",
      " [4.70000000e+01 2.10500000e-01 2.27819263e-03]\n",
      " [4.75000000e+01 2.13300000e-01 5.31578281e-03]\n",
      " [4.80000000e+01 2.11200000e-01 3.03759018e-03]\n",
      " [4.85000000e+01 2.11500000e-01 3.29072269e-03]\n",
      " [4.90000000e+01 2.10400000e-01 2.27819263e-03]\n",
      " [4.95000000e+01 2.09600000e-01 8.85963802e-04]]\n"
     ]
    }
   ],
   "source": [
    "T = unpickle('ResNet164/temperature_search_7_8.txt')\n",
    "print(T.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.95000000e+01, 2.14600000e-01, 6.83457790e-03],\n",
       "       [2.95000000e+01, 2.14200000e-01, 6.70801164e-03],\n",
       "       [3.75000000e+01, 2.13000000e-01, 5.94861410e-03],\n",
       "       [4.75000000e+01, 2.13300000e-01, 5.31578281e-03],\n",
       "       [3.60000000e+01, 2.12800000e-01, 5.18921655e-03]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T[:,T[2,:].argsort()[-5:][::-1]].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_bias(data, num_epochs, batch_size, learning_rate, \n",
    "                logits_teacher, temperature, \n",
    "                class_out=3, class_in=None, save_name='not_3'):\n",
    "    net = ThreeLayerConvNet(input_dim=(1, 28, 28),num_filters=28,filter_size=5,hidden_dim=50,\n",
    "                    reg=0.001,weight_scale=1,dtype=np.float32)\n",
    "    small_model = myModel(net, data,\n",
    "                    num_epochs=num_epochs, batch_size=batch_size,\n",
    "                    optimizer='adam',\n",
    "                    optim_config={\n",
    "                      'learning_rate': learning_rate,\n",
    "                    },\n",
    "                    temperature=temperature,logit_distill=logits_teacher,\n",
    "                    verbose=False)\n",
    "    small_model.train()\n",
    "    \n",
    "    bias_range = np.arange(-10.0,10.1,0.1)\n",
    "    accuracy = np.zeros((3,len(bias_range)))\n",
    "    \n",
    "    if class_out is not None:\n",
    "        mask = data['y_val']==class_out \n",
    "        mask_bias = class_out\n",
    "    if class_in is not None:\n",
    "        mask = True\n",
    "        for cl in class_in:\n",
    "            mask = np.logical_and(mask, data['y_val']!=cl)\n",
    "        mask_bias = class_in\n",
    "    \n",
    "    bias = np.zeros_like(small_model.model.params['b3'])\n",
    "    bias[mask_bias] = 0.1\n",
    "    small_model.model.params['b3'][mask_bias] -= 10.0\n",
    "    \n",
    "    accuracy[0,0] = bias_range[0]\n",
    "    accuracy[1,0] = small_model.check_accuracy(data['X_val'],data['y_val'])\n",
    "    accuracy[2,0] = small_model.check_accuracy(data['X_val'][mask],data['y_val'][mask],sum(mask))\n",
    "    \n",
    "    for i in range(1,len(bias_range)): \n",
    "        small_model.model.params['b3'][mask_bias] += 0.1\n",
    "        accuracy[0,i] = bias_range[i]\n",
    "        accuracy[1,i] = small_model.check_accuracy(data['X_val'],data['y_val'])\n",
    "        accuracy[2,i] = small_model.check_accuracy(data['X_val'][mask], data['y_val'][mask],sum(mask))\n",
    "                \n",
    "    # return to original bias\n",
    "    small_model.model.params['b3'] -= 10.0\n",
    "    \n",
    "    # write to the file\n",
    "    if save_name is not None: \n",
    "        name = save_name + '_bias_search.txt'\n",
    "    else:\n",
    "        name = 'bias_search.txt'\n",
    "\n",
    "    with open(name, 'wb') as fp:\n",
    "        pickle.dump(accuracy, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get out digit 3 from data\n",
    "data_not_3 = data.copy()\n",
    "mask_not_3 = data_not_3['y_train']!=3\n",
    "    \n",
    "data_not_3['X_train'] = data_not_3['X_train'][mask_not_3]\n",
    "data_not_3['y_train'] = data_not_3['y_train'][mask_not_3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For being faster pick up file of logit from resnet164\n",
    "logits_not_3 = unpickle('ResNet164/resnet164_logits_not_3.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_bias(data_not_3, num_epochs=1, batch_size=100, learning_rate=1e-3, \n",
    "                logits_teacher=logits_not_3, temperature=17.0, \n",
    "                class_out=3, save_name='ResNet164/not_3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.00000000e+01  8.81300000e-01  0.00000000e+00]\n",
      " [-9.90000000e+00  8.81300000e-01  0.00000000e+00]\n",
      " [-9.80000000e+00  8.81300000e-01  0.00000000e+00]\n",
      " [-9.70000000e+00  8.81300000e-01  0.00000000e+00]\n",
      " [-9.60000000e+00  8.81300000e-01  0.00000000e+00]\n",
      " [-9.50000000e+00  8.81300000e-01  0.00000000e+00]\n",
      " [-9.40000000e+00  8.81300000e-01  0.00000000e+00]\n",
      " [-9.30000000e+00  8.81300000e-01  0.00000000e+00]\n",
      " [-9.20000000e+00  8.81300000e-01  0.00000000e+00]\n",
      " [-9.10000000e+00  8.81300000e-01  0.00000000e+00]\n",
      " [-9.00000000e+00  8.81300000e-01  0.00000000e+00]\n",
      " [-8.90000000e+00  8.81300000e-01  0.00000000e+00]\n",
      " [-8.80000000e+00  8.81300000e-01  0.00000000e+00]\n",
      " [-8.70000000e+00  8.81300000e-01  0.00000000e+00]\n",
      " [-8.60000000e+00  8.81300000e-01  0.00000000e+00]\n",
      " [-8.50000000e+00  8.81300000e-01  0.00000000e+00]\n",
      " [-8.40000000e+00  8.81300000e-01  0.00000000e+00]\n",
      " [-8.30000000e+00  8.81300000e-01  0.00000000e+00]\n",
      " [-8.20000000e+00  8.81300000e-01  0.00000000e+00]\n",
      " [-8.10000000e+00  8.81300000e-01  0.00000000e+00]\n",
      " [-8.00000000e+00  8.81300000e-01  0.00000000e+00]\n",
      " [-7.90000000e+00  8.81300000e-01  0.00000000e+00]\n",
      " [-7.80000000e+00  8.81300000e-01  0.00000000e+00]\n",
      " [-7.70000000e+00  8.81300000e-01  0.00000000e+00]\n",
      " [-7.60000000e+00  8.81300000e-01  0.00000000e+00]\n",
      " [-7.50000000e+00  8.81300000e-01  0.00000000e+00]\n",
      " [-7.40000000e+00  8.81300000e-01  0.00000000e+00]\n",
      " [-7.30000000e+00  8.81300000e-01  0.00000000e+00]\n",
      " [-7.20000000e+00  8.81300000e-01  0.00000000e+00]\n",
      " [-7.10000000e+00  8.81300000e-01  0.00000000e+00]\n",
      " [-7.00000000e+00  8.81300000e-01  0.00000000e+00]\n",
      " [-6.90000000e+00  8.81300000e-01  0.00000000e+00]\n",
      " [-6.80000000e+00  8.81300000e-01  0.00000000e+00]\n",
      " [-6.70000000e+00  8.81300000e-01  0.00000000e+00]\n",
      " [-6.60000000e+00  8.81300000e-01  0.00000000e+00]\n",
      " [-6.50000000e+00  8.81300000e-01  0.00000000e+00]\n",
      " [-6.40000000e+00  8.81300000e-01  0.00000000e+00]\n",
      " [-6.30000000e+00  8.81300000e-01  0.00000000e+00]\n",
      " [-6.20000000e+00  8.81300000e-01  0.00000000e+00]\n",
      " [-6.10000000e+00  8.81300000e-01  0.00000000e+00]\n",
      " [-6.00000000e+00  8.81300000e-01  0.00000000e+00]\n",
      " [-5.90000000e+00  8.81300000e-01  0.00000000e+00]\n",
      " [-5.80000000e+00  8.81300000e-01  0.00000000e+00]\n",
      " [-5.70000000e+00  8.81300000e-01  0.00000000e+00]\n",
      " [-5.60000000e+00  8.81300000e-01  0.00000000e+00]\n",
      " [-5.50000000e+00  8.81300000e-01  0.00000000e+00]\n",
      " [-5.40000000e+00  8.81300000e-01  0.00000000e+00]\n",
      " [-5.30000000e+00  8.81300000e-01  0.00000000e+00]\n",
      " [-5.20000000e+00  8.81300000e-01  0.00000000e+00]\n",
      " [-5.10000000e+00  8.81300000e-01  0.00000000e+00]\n",
      " [-5.00000000e+00  8.81300000e-01  0.00000000e+00]\n",
      " [-4.90000000e+00  8.81300000e-01  0.00000000e+00]\n",
      " [-4.80000000e+00  8.81300000e-01  0.00000000e+00]\n",
      " [-4.70000000e+00  8.81300000e-01  0.00000000e+00]\n",
      " [-4.60000000e+00  8.81300000e-01  0.00000000e+00]\n",
      " [-4.50000000e+00  8.81300000e-01  0.00000000e+00]\n",
      " [-4.40000000e+00  8.81300000e-01  0.00000000e+00]\n",
      " [-4.30000000e+00  8.81300000e-01  0.00000000e+00]\n",
      " [-4.20000000e+00  8.81300000e-01  0.00000000e+00]\n",
      " [-4.10000000e+00  8.81300000e-01  0.00000000e+00]\n",
      " [-4.00000000e+00  8.81300000e-01  0.00000000e+00]\n",
      " [-3.90000000e+00  8.81300000e-01  0.00000000e+00]\n",
      " [-3.80000000e+00  8.81300000e-01  0.00000000e+00]\n",
      " [-3.70000000e+00  8.81300000e-01  0.00000000e+00]\n",
      " [-3.60000000e+00  8.81300000e-01  0.00000000e+00]\n",
      " [-3.50000000e+00  8.81300000e-01  0.00000000e+00]\n",
      " [-3.40000000e+00  8.81300000e-01  0.00000000e+00]\n",
      " [-3.30000000e+00  8.81300000e-01  0.00000000e+00]\n",
      " [-3.20000000e+00  8.81300000e-01  0.00000000e+00]\n",
      " [-3.10000000e+00  8.81400000e-01  9.70873786e-04]\n",
      " [-3.00000000e+00  8.81400000e-01  9.70873786e-04]\n",
      " [-2.90000000e+00  8.81400000e-01  9.70873786e-04]\n",
      " [-2.80000000e+00  8.81400000e-01  9.70873786e-04]\n",
      " [-2.70000000e+00  8.81400000e-01  9.70873786e-04]\n",
      " [-2.60000000e+00  8.81400000e-01  9.70873786e-04]\n",
      " [-2.50000000e+00  8.81400000e-01  9.70873786e-04]\n",
      " [-2.40000000e+00  8.81400000e-01  9.70873786e-04]\n",
      " [-2.30000000e+00  8.81500000e-01  1.94174757e-03]\n",
      " [-2.20000000e+00  8.81500000e-01  1.94174757e-03]\n",
      " [-2.10000000e+00  8.81500000e-01  1.94174757e-03]\n",
      " [-2.00000000e+00  8.81500000e-01  1.94174757e-03]\n",
      " [-1.90000000e+00  8.81600000e-01  2.91262136e-03]\n",
      " [-1.80000000e+00  8.81700000e-01  3.88349515e-03]\n",
      " [-1.70000000e+00  8.81900000e-01  5.82524272e-03]\n",
      " [-1.60000000e+00  8.82000000e-01  6.79611650e-03]\n",
      " [-1.50000000e+00  8.82400000e-01  1.06796117e-02]\n",
      " [-1.40000000e+00  8.82600000e-01  1.26213592e-02]\n",
      " [-1.30000000e+00  8.82700000e-01  1.35922330e-02]\n",
      " [-1.20000000e+00  8.82800000e-01  1.45631068e-02]\n",
      " [-1.10000000e+00  8.82900000e-01  1.55339806e-02]\n",
      " [-1.00000000e+00  8.83100000e-01  1.74757282e-02]\n",
      " [-9.00000000e-01  8.83400000e-01  2.03883495e-02]\n",
      " [-8.00000000e-01  8.83700000e-01  2.33009709e-02]\n",
      " [-7.00000000e-01  8.84200000e-01  2.91262136e-02]\n",
      " [-6.00000000e-01  8.85000000e-01  3.68932039e-02]\n",
      " [-5.00000000e-01  8.85300000e-01  3.98058252e-02]\n",
      " [-4.00000000e-01  8.85500000e-01  4.17475728e-02]\n",
      " [-3.00000000e-01  8.86100000e-01  4.75728155e-02]\n",
      " [-2.00000000e-01  8.86900000e-01  5.53398058e-02]\n",
      " [-1.00000000e-01  8.87700000e-01  6.31067961e-02]\n",
      " [-3.55271368e-14  8.88200000e-01  6.89320388e-02]\n",
      " [ 1.00000000e-01  8.88800000e-01  7.47572816e-02]\n",
      " [ 2.00000000e-01  8.90100000e-01  8.73786408e-02]\n",
      " [ 3.00000000e-01  8.91100000e-01  9.70873786e-02]\n",
      " [ 4.00000000e-01  8.92100000e-01  1.06796117e-01]\n",
      " [ 5.00000000e-01  8.92900000e-01  1.14563107e-01]\n",
      " [ 6.00000000e-01  8.94700000e-01  1.32038835e-01]\n",
      " [ 7.00000000e-01  8.96200000e-01  1.46601942e-01]\n",
      " [ 8.00000000e-01  8.97700000e-01  1.61165049e-01]\n",
      " [ 9.00000000e-01  8.99800000e-01  1.81553398e-01]\n",
      " [ 1.00000000e+00  9.00900000e-01  1.92233010e-01]\n",
      " [ 1.10000000e+00  9.03500000e-01  2.17475728e-01]\n",
      " [ 1.20000000e+00  9.05100000e-01  2.33009709e-01]\n",
      " [ 1.30000000e+00  9.06700000e-01  2.48543689e-01]\n",
      " [ 1.40000000e+00  9.08800000e-01  2.68932039e-01]\n",
      " [ 1.50000000e+00  9.10800000e-01  2.88349515e-01]\n",
      " [ 1.60000000e+00  9.12100000e-01  3.00970874e-01]\n",
      " [ 1.70000000e+00  9.13100000e-01  3.10679612e-01]\n",
      " [ 1.80000000e+00  9.15000000e-01  3.29126214e-01]\n",
      " [ 1.90000000e+00  9.16500000e-01  3.43689320e-01]\n",
      " [ 2.00000000e+00  9.18800000e-01  3.66990291e-01]\n",
      " [ 2.10000000e+00  9.20300000e-01  3.83495146e-01]\n",
      " [ 2.20000000e+00  9.22000000e-01  4.00000000e-01]\n",
      " [ 2.30000000e+00  9.24100000e-01  4.20388350e-01]\n",
      " [ 2.40000000e+00  9.26500000e-01  4.43689320e-01]\n",
      " [ 2.50000000e+00  9.27700000e-01  4.55339806e-01]\n",
      " [ 2.60000000e+00  9.28800000e-01  4.66019417e-01]\n",
      " [ 2.70000000e+00  9.29900000e-01  4.76699029e-01]\n",
      " [ 2.80000000e+00  9.31600000e-01  4.94174757e-01]\n",
      " [ 2.90000000e+00  9.33000000e-01  5.07766990e-01]\n",
      " [ 3.00000000e+00  9.34100000e-01  5.18446602e-01]\n",
      " [ 3.10000000e+00  9.35500000e-01  5.32038835e-01]\n",
      " [ 3.20000000e+00  9.36800000e-01  5.44660194e-01]\n",
      " [ 3.30000000e+00  9.38000000e-01  5.58252427e-01]\n",
      " [ 3.40000000e+00  9.39800000e-01  5.75728155e-01]\n",
      " [ 3.50000000e+00  9.40800000e-01  5.86407767e-01]\n",
      " [ 3.60000000e+00  9.42200000e-01  6.00970874e-01]\n",
      " [ 3.70000000e+00  9.43300000e-01  6.11650485e-01]\n",
      " [ 3.80000000e+00  9.44400000e-01  6.22330097e-01]\n",
      " [ 3.90000000e+00  9.45500000e-01  6.33009709e-01]\n",
      " [ 4.00000000e+00  9.46200000e-01  6.41747573e-01]\n",
      " [ 4.10000000e+00  9.47000000e-01  6.50485437e-01]\n",
      " [ 4.20000000e+00  9.48100000e-01  6.61165049e-01]\n",
      " [ 4.30000000e+00  9.49400000e-01  6.74757282e-01]\n",
      " [ 4.40000000e+00  9.51200000e-01  6.94174757e-01]\n",
      " [ 4.50000000e+00  9.52300000e-01  7.04854369e-01]\n",
      " [ 4.60000000e+00  9.52800000e-01  7.11650485e-01]\n",
      " [ 4.70000000e+00  9.54500000e-01  7.28155340e-01]\n",
      " [ 4.80000000e+00  9.55800000e-01  7.41747573e-01]\n",
      " [ 4.90000000e+00  9.56800000e-01  7.51456311e-01]\n",
      " [ 5.00000000e+00  9.58100000e-01  7.64077670e-01]\n",
      " [ 5.10000000e+00  9.58700000e-01  7.73786408e-01]\n",
      " [ 5.20000000e+00  9.59500000e-01  7.84466019e-01]\n",
      " [ 5.30000000e+00  9.60300000e-01  7.92233010e-01]\n",
      " [ 5.40000000e+00  9.61300000e-01  8.02912621e-01]\n",
      " [ 5.50000000e+00  9.61500000e-01  8.07766990e-01]\n",
      " [ 5.60000000e+00  9.62100000e-01  8.16504854e-01]\n",
      " [ 5.70000000e+00  9.63100000e-01  8.26213592e-01]\n",
      " [ 5.80000000e+00  9.63300000e-01  8.30097087e-01]\n",
      " [ 5.90000000e+00  9.64200000e-01  8.40776699e-01]\n",
      " [ 6.00000000e+00  9.64400000e-01  8.46601942e-01]\n",
      " [ 6.10000000e+00  9.64900000e-01  8.52427184e-01]\n",
      " [ 6.20000000e+00  9.65500000e-01  8.59223301e-01]\n",
      " [ 6.30000000e+00  9.65800000e-01  8.63106796e-01]\n",
      " [ 6.40000000e+00  9.66100000e-01  8.67961165e-01]\n",
      " [ 6.50000000e+00  9.66400000e-01  8.73786408e-01]\n",
      " [ 6.60000000e+00  9.66300000e-01  8.77669903e-01]\n",
      " [ 6.70000000e+00  9.66300000e-01  8.80582524e-01]\n",
      " [ 6.80000000e+00  9.66300000e-01  8.83495146e-01]\n",
      " [ 6.90000000e+00  9.66700000e-01  8.91262136e-01]\n",
      " [ 7.00000000e+00  9.66900000e-01  8.95145631e-01]\n",
      " [ 7.10000000e+00  9.66400000e-01  8.96116505e-01]\n",
      " [ 7.20000000e+00  9.66500000e-01  8.99029126e-01]\n",
      " [ 7.30000000e+00  9.66600000e-01  9.03883495e-01]\n",
      " [ 7.40000000e+00  9.66500000e-01  9.06796117e-01]\n",
      " [ 7.50000000e+00  9.66600000e-01  9.11650485e-01]\n",
      " [ 7.60000000e+00  9.66700000e-01  9.12621359e-01]\n",
      " [ 7.70000000e+00  9.66700000e-01  9.18446602e-01]\n",
      " [ 7.80000000e+00  9.67000000e-01  9.23300971e-01]\n",
      " [ 7.90000000e+00  9.66500000e-01  9.25242718e-01]\n",
      " [ 8.00000000e+00  9.66100000e-01  9.27184466e-01]\n",
      " [ 8.10000000e+00  9.65500000e-01  9.30097087e-01]\n",
      " [ 8.20000000e+00  9.65400000e-01  9.33009709e-01]\n",
      " [ 8.30000000e+00  9.65300000e-01  9.38834951e-01]\n",
      " [ 8.40000000e+00  9.65600000e-01  9.45631068e-01]\n",
      " [ 8.50000000e+00  9.65700000e-01  9.48543689e-01]\n",
      " [ 8.60000000e+00  9.64500000e-01  9.49514563e-01]\n",
      " [ 8.70000000e+00  9.64200000e-01  9.52427184e-01]\n",
      " [ 8.80000000e+00  9.64100000e-01  9.54368932e-01]\n",
      " [ 8.90000000e+00  9.63100000e-01  9.56310680e-01]\n",
      " [ 9.00000000e+00  9.62400000e-01  9.60194175e-01]\n",
      " [ 9.10000000e+00  9.61600000e-01  9.63106796e-01]\n",
      " [ 9.20000000e+00  9.60900000e-01  9.65048544e-01]\n",
      " [ 9.30000000e+00  9.59500000e-01  9.65048544e-01]\n",
      " [ 9.40000000e+00  9.58100000e-01  9.67961165e-01]\n",
      " [ 9.50000000e+00  9.56700000e-01  9.68932039e-01]\n",
      " [ 9.60000000e+00  9.55500000e-01  9.70873786e-01]\n",
      " [ 9.70000000e+00  9.54200000e-01  9.72815534e-01]\n",
      " [ 9.80000000e+00  9.53200000e-01  9.74757282e-01]\n",
      " [ 9.90000000e+00  9.51700000e-01  9.76699029e-01]\n",
      " [ 1.00000000e+01  9.50400000e-01  9.77669903e-01]]\n"
     ]
    }
   ],
   "source": [
    "bias = unpickle('ResNet164/not_3_bias_search.txt')\n",
    "print(bias.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get data with only digit 7 and 8\n",
    "data_7_8 = data.copy()\n",
    "mask_7_8 = np.logical_or(data['y_train']==7, data['y_train']==8)\n",
    "    \n",
    "data_7_8['X_train'] = data_7_8['X_train'][mask_7_8]\n",
    "data_7_8['y_train'] = data_7_8['y_train'][mask_7_8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For being faster pick up file of logit from resnet164\n",
    "logits_7_8 = unpickle('resnet164_logits_7_8.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_bias(data_7_8, num_epochs=1, batch_size=50, learning_rate=1e-3, \n",
    "                logits_teacher=logits_7_8, temperature=30.0, \n",
    "                class_out=None, class_in=[7,8], save_name='ResNet164/7_8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.00000000e+01  4.09100000e-01  2.73129984e-01]\n",
      " [-9.90000000e+00  4.07800000e-01  2.70851791e-01]\n",
      " [-9.80000000e+00  4.04700000e-01  2.66295406e-01]\n",
      " [-9.70000000e+00  4.03400000e-01  2.63637514e-01]\n",
      " [-9.60000000e+00  4.01100000e-01  2.59967093e-01]\n",
      " [-9.50000000e+00  3.98800000e-01  2.56549804e-01]\n",
      " [-9.40000000e+00  3.96700000e-01  2.53132515e-01]\n",
      " [-9.30000000e+00  3.95000000e-01  2.50474623e-01]\n",
      " [-9.20000000e+00  3.92400000e-01  2.46551069e-01]\n",
      " [-9.10000000e+00  3.89900000e-01  2.42880648e-01]\n",
      " [-9.00000000e+00  3.87500000e-01  2.39336793e-01]\n",
      " [-8.90000000e+00  3.85800000e-01  2.36425769e-01]\n",
      " [-8.80000000e+00  3.84000000e-01  2.33261612e-01]\n",
      " [-8.70000000e+00  3.82600000e-01  2.30730287e-01]\n",
      " [-8.60000000e+00  3.81000000e-01  2.28452095e-01]\n",
      " [-8.50000000e+00  3.78400000e-01  2.24528541e-01]\n",
      " [-8.40000000e+00  3.75700000e-01  2.20478420e-01]\n",
      " [-8.30000000e+00  3.72900000e-01  2.16554866e-01]\n",
      " [-8.20000000e+00  3.71000000e-01  2.13264144e-01]\n",
      " [-8.10000000e+00  3.67800000e-01  2.09087457e-01]\n",
      " [-8.00000000e+00  3.64800000e-01  2.04910771e-01]\n",
      " [-7.90000000e+00  3.62500000e-01  2.01873181e-01]\n",
      " [-7.80000000e+00  3.59500000e-01  1.97316795e-01]\n",
      " [-7.70000000e+00  3.55800000e-01  1.92254145e-01]\n",
      " [-7.60000000e+00  3.53600000e-01  1.89216555e-01]\n",
      " [-7.50000000e+00  3.50200000e-01  1.84786736e-01]\n",
      " [-7.40000000e+00  3.46800000e-01  1.80483483e-01]\n",
      " [-7.30000000e+00  3.44500000e-01  1.77066194e-01]\n",
      " [-7.20000000e+00  3.42100000e-01  1.73522339e-01]\n",
      " [-7.10000000e+00  3.39000000e-01  1.69345652e-01]\n",
      " [-7.00000000e+00  3.35300000e-01  1.64662701e-01]\n",
      " [-6.90000000e+00  3.32800000e-01  1.61498544e-01]\n",
      " [-6.80000000e+00  3.30400000e-01  1.58460954e-01]\n",
      " [-6.70000000e+00  3.28300000e-01  1.55549930e-01]\n",
      " [-6.60000000e+00  3.24900000e-01  1.51120111e-01]\n",
      " [-6.50000000e+00  3.22500000e-01  1.47702822e-01]\n",
      " [-6.40000000e+00  3.20200000e-01  1.44412100e-01]\n",
      " [-6.30000000e+00  3.17300000e-01  1.40741678e-01]\n",
      " [-6.20000000e+00  3.14500000e-01  1.37197823e-01]\n",
      " [-6.10000000e+00  3.12700000e-01  1.34793064e-01]\n",
      " [-6.00000000e+00  3.08900000e-01  1.29730414e-01]\n",
      " [-5.90000000e+00  3.06400000e-01  1.26439691e-01]\n",
      " [-5.80000000e+00  3.03600000e-01  1.22769270e-01]\n",
      " [-5.70000000e+00  3.01300000e-01  1.19858246e-01]\n",
      " [-5.60000000e+00  2.99500000e-01  1.17453487e-01]\n",
      " [-5.50000000e+00  2.95800000e-01  1.12643969e-01]\n",
      " [-5.40000000e+00  2.93200000e-01  1.09100114e-01]\n",
      " [-5.30000000e+00  2.90900000e-01  1.06062524e-01]\n",
      " [-5.20000000e+00  2.88000000e-01  1.02265536e-01]\n",
      " [-5.10000000e+00  2.83400000e-01  9.64434882e-02]\n",
      " [-5.00000000e+00  2.80500000e-01  9.26465004e-02]\n",
      " [-4.90000000e+00  2.78200000e-01  8.93557777e-02]\n",
      " [-4.80000000e+00  2.75300000e-01  8.55587900e-02]\n",
      " [-4.70000000e+00  2.73200000e-01  8.29008986e-02]\n",
      " [-4.60000000e+00  2.70700000e-01  7.96101759e-02]\n",
      " [-4.50000000e+00  2.67600000e-01  7.56866219e-02]\n",
      " [-4.40000000e+00  2.66100000e-01  7.35349956e-02]\n",
      " [-4.30000000e+00  2.63800000e-01  7.06239716e-02]\n",
      " [-4.20000000e+00  2.62100000e-01  6.82192128e-02]\n",
      " [-4.10000000e+00  2.59000000e-01  6.42956588e-02]\n",
      " [-4.00000000e+00  2.57000000e-01  6.17643336e-02]\n",
      " [-3.90000000e+00  2.54600000e-01  5.86001772e-02]\n",
      " [-3.80000000e+00  2.53000000e-01  5.65751171e-02]\n",
      " [-3.70000000e+00  2.50000000e-01  5.27781294e-02]\n",
      " [-3.60000000e+00  2.47300000e-01  4.93608404e-02]\n",
      " [-3.50000000e+00  2.45300000e-01  4.67029490e-02]\n",
      " [-3.40000000e+00  2.42900000e-01  4.36653588e-02]\n",
      " [-3.30000000e+00  2.40000000e-01  3.99949373e-02]\n",
      " [-3.20000000e+00  2.37800000e-01  3.72104797e-02]\n",
      " [-3.10000000e+00  2.35700000e-01  3.44260220e-02]\n",
      " [-3.00000000e+00  2.33400000e-01  3.15149981e-02]\n",
      " [-2.90000000e+00  2.31200000e-01  2.87305404e-02]\n",
      " [-2.80000000e+00  2.29100000e-01  2.60726490e-02]\n",
      " [-2.70000000e+00  2.27900000e-01  2.45538539e-02]\n",
      " [-2.60000000e+00  2.26000000e-01  2.20225288e-02]\n",
      " [-2.50000000e+00  2.25300000e-01  2.11365650e-02]\n",
      " [-2.40000000e+00  2.24100000e-01  1.96177699e-02]\n",
      " [-2.30000000e+00  2.22100000e-01  1.70864448e-02]\n",
      " [-2.20000000e+00  2.21300000e-01  1.60739147e-02]\n",
      " [-2.10000000e+00  2.20600000e-01  1.51879509e-02]\n",
      " [-2.00000000e+00  2.19500000e-01  1.37957221e-02]\n",
      " [-1.90000000e+00  2.18600000e-01  1.26566257e-02]\n",
      " [-1.80000000e+00  2.18100000e-01  1.20237945e-02]\n",
      " [-1.70000000e+00  2.17500000e-01  1.12643969e-02]\n",
      " [-1.60000000e+00  2.16500000e-01  9.87216808e-03]\n",
      " [-1.50000000e+00  2.15800000e-01  8.98620428e-03]\n",
      " [-1.40000000e+00  2.15600000e-01  8.73307176e-03]\n",
      " [-1.30000000e+00  2.15000000e-01  7.97367422e-03]\n",
      " [-1.20000000e+00  2.14800000e-01  7.72054170e-03]\n",
      " [-1.10000000e+00  2.14500000e-01  7.34084293e-03]\n",
      " [-1.00000000e+00  2.13900000e-01  6.58144539e-03]\n",
      " [-9.00000000e-01  2.13800000e-01  6.45487913e-03]\n",
      " [-8.00000000e-01  2.13700000e-01  6.32831287e-03]\n",
      " [-7.00000000e-01  2.13600000e-01  6.20174661e-03]\n",
      " [-6.00000000e-01  2.13200000e-01  5.69548158e-03]\n",
      " [-5.00000000e-01  2.12700000e-01  5.06265030e-03]\n",
      " [-4.00000000e-01  2.12300000e-01  4.55638527e-03]\n",
      " [-3.00000000e-01  2.12200000e-01  4.42981901e-03]\n",
      " [-2.00000000e-01  2.12100000e-01  4.30325275e-03]\n",
      " [-1.00000000e-01  2.11900000e-01  4.05012024e-03]\n",
      " [-3.55271368e-14  2.11600000e-01  3.67042147e-03]\n",
      " [ 1.00000000e-01  2.11200000e-01  3.16415644e-03]\n",
      " [ 2.00000000e-01  2.11200000e-01  3.16415644e-03]\n",
      " [ 3.00000000e-01  2.11100000e-01  3.03759018e-03]\n",
      " [ 4.00000000e-01  2.11000000e-01  2.91102392e-03]\n",
      " [ 5.00000000e-01  2.10800000e-01  2.65789141e-03]\n",
      " [ 6.00000000e-01  2.10700000e-01  2.53132515e-03]\n",
      " [ 7.00000000e-01  2.10600000e-01  2.40475889e-03]\n",
      " [ 8.00000000e-01  2.10600000e-01  2.40475889e-03]\n",
      " [ 9.00000000e-01  2.10300000e-01  2.02506012e-03]\n",
      " [ 1.00000000e+00  2.10300000e-01  2.02506012e-03]\n",
      " [ 1.10000000e+00  2.10300000e-01  2.02506012e-03]\n",
      " [ 1.20000000e+00  2.10100000e-01  1.77192760e-03]\n",
      " [ 1.30000000e+00  2.09900000e-01  1.51879509e-03]\n",
      " [ 1.40000000e+00  2.09900000e-01  1.51879509e-03]\n",
      " [ 1.50000000e+00  2.09900000e-01  1.51879509e-03]\n",
      " [ 1.60000000e+00  2.09900000e-01  1.51879509e-03]\n",
      " [ 1.70000000e+00  2.09800000e-01  1.39222883e-03]\n",
      " [ 1.80000000e+00  2.09700000e-01  1.26566257e-03]\n",
      " [ 1.90000000e+00  2.09600000e-01  1.13909632e-03]\n",
      " [ 2.00000000e+00  2.09500000e-01  1.01253006e-03]\n",
      " [ 2.10000000e+00  2.09400000e-01  8.85963802e-04]\n",
      " [ 2.20000000e+00  2.09400000e-01  8.85963802e-04]\n",
      " [ 2.30000000e+00  2.09300000e-01  7.59397545e-04]\n",
      " [ 2.40000000e+00  2.09300000e-01  7.59397545e-04]\n",
      " [ 2.50000000e+00  2.09300000e-01  7.59397545e-04]\n",
      " [ 2.60000000e+00  2.09200000e-01  6.32831287e-04]\n",
      " [ 2.70000000e+00  2.09100000e-01  5.06265030e-04]\n",
      " [ 2.80000000e+00  2.09000000e-01  3.79698772e-04]\n",
      " [ 2.90000000e+00  2.08900000e-01  2.53132515e-04]\n",
      " [ 3.00000000e+00  2.08900000e-01  2.53132515e-04]\n",
      " [ 3.10000000e+00  2.08800000e-01  1.26566257e-04]\n",
      " [ 3.20000000e+00  2.08700000e-01  0.00000000e+00]\n",
      " [ 3.30000000e+00  2.08700000e-01  0.00000000e+00]\n",
      " [ 3.40000000e+00  2.08700000e-01  0.00000000e+00]\n",
      " [ 3.50000000e+00  2.08700000e-01  0.00000000e+00]\n",
      " [ 3.60000000e+00  2.08700000e-01  0.00000000e+00]\n",
      " [ 3.70000000e+00  2.08700000e-01  0.00000000e+00]\n",
      " [ 3.80000000e+00  2.08700000e-01  0.00000000e+00]\n",
      " [ 3.90000000e+00  2.08700000e-01  0.00000000e+00]\n",
      " [ 4.00000000e+00  2.08700000e-01  0.00000000e+00]\n",
      " [ 4.10000000e+00  2.08700000e-01  0.00000000e+00]\n",
      " [ 4.20000000e+00  2.08700000e-01  0.00000000e+00]\n",
      " [ 4.30000000e+00  2.08700000e-01  0.00000000e+00]\n",
      " [ 4.40000000e+00  2.08700000e-01  0.00000000e+00]\n",
      " [ 4.50000000e+00  2.08700000e-01  0.00000000e+00]\n",
      " [ 4.60000000e+00  2.08700000e-01  0.00000000e+00]\n",
      " [ 4.70000000e+00  2.08700000e-01  0.00000000e+00]\n",
      " [ 4.80000000e+00  2.08700000e-01  0.00000000e+00]\n",
      " [ 4.90000000e+00  2.08700000e-01  0.00000000e+00]\n",
      " [ 5.00000000e+00  2.08700000e-01  0.00000000e+00]\n",
      " [ 5.10000000e+00  2.08700000e-01  0.00000000e+00]\n",
      " [ 5.20000000e+00  2.08700000e-01  0.00000000e+00]\n",
      " [ 5.30000000e+00  2.08700000e-01  0.00000000e+00]\n",
      " [ 5.40000000e+00  2.08700000e-01  0.00000000e+00]\n",
      " [ 5.50000000e+00  2.08700000e-01  0.00000000e+00]\n",
      " [ 5.60000000e+00  2.08700000e-01  0.00000000e+00]\n",
      " [ 5.70000000e+00  2.08700000e-01  0.00000000e+00]\n",
      " [ 5.80000000e+00  2.08700000e-01  0.00000000e+00]\n",
      " [ 5.90000000e+00  2.08700000e-01  0.00000000e+00]\n",
      " [ 6.00000000e+00  2.08700000e-01  0.00000000e+00]\n",
      " [ 6.10000000e+00  2.08700000e-01  0.00000000e+00]\n",
      " [ 6.20000000e+00  2.08700000e-01  0.00000000e+00]\n",
      " [ 6.30000000e+00  2.08700000e-01  0.00000000e+00]\n",
      " [ 6.40000000e+00  2.08700000e-01  0.00000000e+00]\n",
      " [ 6.50000000e+00  2.08700000e-01  0.00000000e+00]\n",
      " [ 6.60000000e+00  2.08700000e-01  0.00000000e+00]\n",
      " [ 6.70000000e+00  2.08700000e-01  0.00000000e+00]\n",
      " [ 6.80000000e+00  2.08700000e-01  0.00000000e+00]\n",
      " [ 6.90000000e+00  2.08700000e-01  0.00000000e+00]\n",
      " [ 7.00000000e+00  2.08700000e-01  0.00000000e+00]\n",
      " [ 7.10000000e+00  2.08700000e-01  0.00000000e+00]\n",
      " [ 7.20000000e+00  2.08700000e-01  0.00000000e+00]\n",
      " [ 7.30000000e+00  2.08700000e-01  0.00000000e+00]\n",
      " [ 7.40000000e+00  2.08700000e-01  0.00000000e+00]\n",
      " [ 7.50000000e+00  2.08700000e-01  0.00000000e+00]\n",
      " [ 7.60000000e+00  2.08700000e-01  0.00000000e+00]\n",
      " [ 7.70000000e+00  2.08700000e-01  0.00000000e+00]\n",
      " [ 7.80000000e+00  2.08700000e-01  0.00000000e+00]\n",
      " [ 7.90000000e+00  2.08700000e-01  0.00000000e+00]\n",
      " [ 8.00000000e+00  2.08700000e-01  0.00000000e+00]\n",
      " [ 8.10000000e+00  2.08700000e-01  0.00000000e+00]\n",
      " [ 8.20000000e+00  2.08700000e-01  0.00000000e+00]\n",
      " [ 8.30000000e+00  2.08700000e-01  0.00000000e+00]\n",
      " [ 8.40000000e+00  2.08700000e-01  0.00000000e+00]\n",
      " [ 8.50000000e+00  2.08700000e-01  0.00000000e+00]\n",
      " [ 8.60000000e+00  2.08700000e-01  0.00000000e+00]\n",
      " [ 8.70000000e+00  2.08700000e-01  0.00000000e+00]\n",
      " [ 8.80000000e+00  2.08700000e-01  0.00000000e+00]\n",
      " [ 8.90000000e+00  2.08700000e-01  0.00000000e+00]\n",
      " [ 9.00000000e+00  2.08700000e-01  0.00000000e+00]\n",
      " [ 9.10000000e+00  2.08700000e-01  0.00000000e+00]\n",
      " [ 9.20000000e+00  2.08700000e-01  0.00000000e+00]\n",
      " [ 9.30000000e+00  2.08700000e-01  0.00000000e+00]\n",
      " [ 9.40000000e+00  2.08700000e-01  0.00000000e+00]\n",
      " [ 9.50000000e+00  2.08700000e-01  0.00000000e+00]\n",
      " [ 9.60000000e+00  2.08700000e-01  0.00000000e+00]\n",
      " [ 9.70000000e+00  2.08700000e-01  0.00000000e+00]\n",
      " [ 9.80000000e+00  2.08700000e-01  0.00000000e+00]\n",
      " [ 9.90000000e+00  2.08700000e-01  0.00000000e+00]\n",
      " [ 1.00000000e+01  2.08700000e-01  0.00000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "bias = unpickle('ResNet164/bias_search_7_8.txt')\n",
    "print(bias.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-10.        ,   0.4091    ,   0.27312998],\n",
       "       [ -9.9       ,   0.4078    ,   0.27085179],\n",
       "       [ -9.8       ,   0.4047    ,   0.26629541],\n",
       "       [ -9.7       ,   0.4034    ,   0.26363751],\n",
       "       [ -9.6       ,   0.4011    ,   0.25996709]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bias[:,bias[2,:].argsort()[-5:][::-1]].T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test with VGG16 as teacher model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "# Load teacher model\n",
    "big_model = VGG16()\n",
    "big_model.compile()\n",
    "# Load pre-trained model\n",
    "big_model.load_weights('VGG16/VGG16.h5')\n",
    "# Remove softmax from VGG16\n",
    "big_model_woSM = Model(inputs=big_model.model.input, outputs=big_model.model.layers[-2].output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 607s 12ms/step\n"
     ]
    }
   ],
   "source": [
    "# Predict to get logits\n",
    "logits_train = big_model_woSM.predict(x_train, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SoftMax(s):\n",
    "    # minus max to avoid large s case\n",
    "    p = np.exp(s-np.expand_dims(np.max(s,axis=1),axis=1))/\\\n",
    "    np.expand_dims(np.exp(s-np.expand_dims(np.max(s,axis=1),axis=1)).sum(axis=1),axis=1)  # matrix of size NxK\n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-3.1318357  -0.58660555 -6.1529765   7.2426195  -6.0088015  11.868018\n",
      " -0.74990106 -5.515557    0.960757    2.0794492 ]\n",
      "Train accuracy of big model: 0.99914\n"
     ]
    }
   ],
   "source": [
    "print(logits_train[0])\n",
    "y_pred_big = np.argmax(SoftMax(logits_train),axis=1)\n",
    "y_true = np.argmax(y_train,axis=1)\n",
    "print('Train accuracy of big model: {}'.format(np.mean(y_true==y_pred_big)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 10)\n"
     ]
    }
   ],
   "source": [
    "print(logits_train.shape)\n",
    "with open('VGG16/vgg16_logits_train.txt', 'wb') as fp:\n",
    "    pickle.dump(logits_train, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 165s 16ms/step\n"
     ]
    }
   ],
   "source": [
    "# Predict to get logits for test\n",
    "logits_test = big_model_woSM.predict(x_test, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-10.137868    7.378173    4.5927176   2.4612358  -3.1164281  -9.72687\n",
      "  -9.742915   21.030071   -8.707618    4.8068333]\n",
      "Train accuracy of big model: 0.9968\n"
     ]
    }
   ],
   "source": [
    "print(logits_test[0])\n",
    "y_pred_big = np.argmax(SoftMax(logits_test),axis=1)\n",
    "y_true = np.argmax(y_test,axis=1)\n",
    "print('Train accuracy of big model: {}'.format(np.mean(y_true==y_pred_big)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For being faster pick up file of logit from vgg16\n",
    "logits_train = unpickle('VGG16/vgg16_logits_train.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Iteration 1 / 500) loss: 31.080262\n",
      "(Epoch 0 / 1) train acc: 0.191260; val_acc: 0.195300\n",
      "(Iteration 101 / 500) loss: 11.306222\n",
      "(Iteration 201 / 500) loss: 9.500901\n",
      "(Iteration 301 / 500) loss: 9.689771\n",
      "(Iteration 401 / 500) loss: 10.326211\n",
      "(Epoch 1 / 1) train acc: 0.977080; val_acc: 0.975300\n",
      "Execution time:  533.5676369667053\n"
     ]
    }
   ],
   "source": [
    "# Train small model with distilling\n",
    "net = ThreeLayerConvNet(input_dim=(1, 28, 28),num_filters=28,filter_size=5,hidden_dim=50,\n",
    "                        reg=0.001,weight_scale=1,dtype=np.float32)\n",
    "small_model = myModel(net, data, \n",
    "                      num_epochs=1, batch_size=100,\n",
    "                      optimizer='adam',\n",
    "                      optim_config={\n",
    "                          'learning_rate': 1e-3,},\n",
    "                      temperature=5.0,logit_distill=logits_train,\n",
    "                      verbose=True, print_every=100)\n",
    "tic = time.time()\n",
    "small_model.train()\n",
    "toc = time.time()\n",
    "print('Execution time: ',toc-tic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.9765\n"
     ]
    }
   ],
   "source": [
    "print('Test accuracy: {}'.format(small_model.check_accuracy(data['X_test'],data['y_test'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Temperature 1.0, Training acc 0.96478, Validation acc 0.9625, Execution time 658.2517602443695\n",
      "Temperature 1.5, Training acc 0.97676, Validation acc 0.9761, Execution time 502.8496437072754\n",
      "Temperature 2.0, Training acc 0.9772, Validation acc 0.9777, Execution time 448.3176610469818\n",
      "Temperature 2.5, Training acc 0.97134, Validation acc 0.9717, Execution time 459.4270541667938\n",
      "Temperature 3.0, Training acc 0.98002, Validation acc 0.9794, Execution time 416.7173328399658\n",
      "Temperature 3.5, Training acc 0.97548, Validation acc 0.9761, Execution time 391.3283898830414\n",
      "Temperature 4.0, Training acc 0.97922, Validation acc 0.9777, Execution time 549.3627419471741\n",
      "Temperature 4.5, Training acc 0.98122, Validation acc 0.9815, Execution time 539.9320690631866\n",
      "Temperature 5.0, Training acc 0.97904, Validation acc 0.9775, Execution time 513.6396298408508\n",
      "Temperature 5.5, Training acc 0.9791, Validation acc 0.9797, Execution time 464.8682780265808\n",
      "Temperature 6.0, Training acc 0.9797, Validation acc 0.9811, Execution time 436.09042501449585\n",
      "Temperature 6.5, Training acc 0.97802, Validation acc 0.9792, Execution time 429.94104194641113\n",
      "Temperature 7.0, Training acc 0.97776, Validation acc 0.979, Execution time 427.51111817359924\n",
      "Temperature 7.5, Training acc 0.9779, Validation acc 0.9775, Execution time 431.22055077552795\n",
      "Temperature 8.0, Training acc 0.97956, Validation acc 0.98, Execution time 434.124605178833\n",
      "Temperature 8.5, Training acc 0.97818, Validation acc 0.9788, Execution time 428.94134616851807\n",
      "Temperature 9.0, Training acc 0.97888, Validation acc 0.9799, Execution time 427.42800283432007\n",
      "Temperature 9.5, Training acc 0.9768, Validation acc 0.9777, Execution time 432.30251598358154\n",
      "Temperature 10.0, Training acc 0.97758, Validation acc 0.9793, Execution time 427.3152189254761\n",
      "Temperature 10.5, Training acc 0.97562, Validation acc 0.9773, Execution time 427.82968401908875\n",
      "Temperature 11.0, Training acc 0.97456, Validation acc 0.9752, Execution time 426.5162229537964\n",
      "Temperature 11.5, Training acc 0.97414, Validation acc 0.9763, Execution time 429.4863090515137\n",
      "Temperature 12.0, Training acc 0.97526, Validation acc 0.9755, Execution time 427.56268310546875\n",
      "Temperature 12.5, Training acc 0.975, Validation acc 0.9785, Execution time 427.28328108787537\n",
      "Temperature 13.0, Training acc 0.97564, Validation acc 0.9774, Execution time 427.47957706451416\n",
      "Temperature 13.5, Training acc 0.97164, Validation acc 0.9732, Execution time 429.53988790512085\n",
      "Temperature 14.0, Training acc 0.97532, Validation acc 0.9801, Execution time 429.61003375053406\n",
      "Temperature 14.5, Training acc 0.9756, Validation acc 0.9769, Execution time 427.3763930797577\n",
      "Temperature 15.0, Training acc 0.97128, Validation acc 0.975, Execution time 432.0980951786041\n",
      "Temperature 15.5, Training acc 0.9743, Validation acc 0.975, Execution time 425.9910800457001\n",
      "Temperature 16.0, Training acc 0.97436, Validation acc 0.9774, Execution time 432.3391671180725\n",
      "Temperature 16.5, Training acc 0.9718, Validation acc 0.9734, Execution time 427.7675108909607\n",
      "Temperature 17.0, Training acc 0.97154, Validation acc 0.975, Execution time 432.07902216911316\n",
      "Temperature 17.5, Training acc 0.97336, Validation acc 0.9771, Execution time 451.5799939632416\n",
      "Temperature 18.0, Training acc 0.97272, Validation acc 0.9757, Execution time 514.1930508613586\n",
      "Temperature 18.5, Training acc 0.97176, Validation acc 0.9745, Execution time 462.39286494255066\n",
      "Temperature 19.0, Training acc 0.973, Validation acc 0.974, Execution time 429.64480686187744\n",
      "Temperature 19.5, Training acc 0.97404, Validation acc 0.9766, Execution time 428.22549986839294\n",
      "Temperature 20.0, Training acc 0.97182, Validation acc 0.9734, Execution time 427.16259384155273\n",
      "Temperature 20.5, Training acc 0.97092, Validation acc 0.9745, Execution time 428.31512117385864\n",
      "Temperature 21.0, Training acc 0.97248, Validation acc 0.9757, Execution time 428.16881108283997\n",
      "Temperature 21.5, Training acc 0.9768, Validation acc 0.9777, Execution time 430.2816982269287\n",
      "Temperature 22.0, Training acc 0.9752, Validation acc 0.9749, Execution time 426.7525861263275\n",
      "Temperature 22.5, Training acc 0.97188, Validation acc 0.9749, Execution time 427.1796898841858\n",
      "Temperature 23.0, Training acc 0.97562, Validation acc 0.9776, Execution time 438.27986693382263\n",
      "Temperature 23.5, Training acc 0.97114, Validation acc 0.9751, Execution time 430.0987010002136\n",
      "Temperature 24.0, Training acc 0.97254, Validation acc 0.9754, Execution time 425.62053394317627\n",
      "Temperature 24.5, Training acc 0.97202, Validation acc 0.9745, Execution time 426.01238775253296\n",
      "Temperature 25.0, Training acc 0.97206, Validation acc 0.9753, Execution time 424.6154532432556\n",
      "Temperature 25.5, Training acc 0.97218, Validation acc 0.9746, Execution time 430.09653091430664\n",
      "Temperature 26.0, Training acc 0.97158, Validation acc 0.9752, Execution time 430.15437388420105\n",
      "Temperature 26.5, Training acc 0.97584, Validation acc 0.9766, Execution time 430.57741713523865\n",
      "Temperature 27.0, Training acc 0.97248, Validation acc 0.9744, Execution time 433.87240982055664\n",
      "Temperature 27.5, Training acc 0.97336, Validation acc 0.9758, Execution time 439.81884002685547\n",
      "Temperature 28.0, Training acc 0.97016, Validation acc 0.9733, Execution time 434.2395751476288\n",
      "Temperature 28.5, Training acc 0.96856, Validation acc 0.972, Execution time 432.42784690856934\n",
      "Temperature 29.0, Training acc 0.97114, Validation acc 0.9733, Execution time 433.4776976108551\n",
      "Temperature 29.5, Training acc 0.97266, Validation acc 0.9752, Execution time 439.26413893699646\n",
      "Temperature 30.0, Training acc 0.9734, Validation acc 0.977, Execution time 434.11067295074463\n",
      "Temperature 30.5, Training acc 0.97392, Validation acc 0.9753, Execution time 441.2641191482544\n",
      "Temperature 31.0, Training acc 0.9703, Validation acc 0.9722, Execution time 433.99443221092224\n",
      "Temperature 31.5, Training acc 0.97464, Validation acc 0.977, Execution time 439.0602729320526\n",
      "Temperature 32.0, Training acc 0.97344, Validation acc 0.976, Execution time 436.4548809528351\n",
      "Temperature 32.5, Training acc 0.97014, Validation acc 0.973, Execution time 515.5930759906769\n",
      "Temperature 33.0, Training acc 0.97244, Validation acc 0.9751, Execution time 534.9397430419922\n",
      "Temperature 33.5, Training acc 0.97246, Validation acc 0.9762, Execution time 533.2816181182861\n",
      "Temperature 34.0, Training acc 0.97258, Validation acc 0.9745, Execution time 526.5899310112\n",
      "Temperature 34.5, Training acc 0.9725, Validation acc 0.9753, Execution time 474.58998823165894\n",
      "Temperature 35.0, Training acc 0.97314, Validation acc 0.976, Execution time 378.027672290802\n",
      "Temperature 35.5, Training acc 0.97196, Validation acc 0.9736, Execution time 373.9074070453644\n",
      "Temperature 36.0, Training acc 0.97272, Validation acc 0.975, Execution time 371.99621081352234\n",
      "Temperature 36.5, Training acc 0.97246, Validation acc 0.975, Execution time 370.8387050628662\n",
      "Temperature 37.0, Training acc 0.9703, Validation acc 0.9718, Execution time 372.78500509262085\n",
      "Temperature 37.5, Training acc 0.9725, Validation acc 0.9742, Execution time 373.4780662059784\n",
      "Temperature 38.0, Training acc 0.975, Validation acc 0.9761, Execution time 382.87750005722046\n",
      "Temperature 38.5, Training acc 0.97486, Validation acc 0.9751, Execution time 370.7003779411316\n",
      "Temperature 39.0, Training acc 0.97318, Validation acc 0.976, Execution time 405.0942018032074\n",
      "Temperature 39.5, Training acc 0.97198, Validation acc 0.9745, Execution time 396.4379768371582\n",
      "Temperature 40.0, Training acc 0.9718, Validation acc 0.9745, Execution time 442.43929290771484\n",
      "Temperature 40.5, Training acc 0.97318, Validation acc 0.9752, Execution time 572.9523918628693\n",
      "Temperature 41.0, Training acc 0.97354, Validation acc 0.9767, Execution time 566.314934015274\n",
      "Temperature 41.5, Training acc 0.9748, Validation acc 0.9773, Execution time 562.1614239215851\n",
      "Temperature 42.0, Training acc 0.97334, Validation acc 0.9767, Execution time 559.9060060977936\n",
      "Temperature 42.5, Training acc 0.97584, Validation acc 0.9791, Execution time 512.7679550647736\n",
      "Temperature 43.0, Training acc 0.96986, Validation acc 0.9732, Execution time 473.7580442428589\n",
      "Temperature 43.5, Training acc 0.97144, Validation acc 0.9735, Execution time 483.9498908519745\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Temperature 44.0, Training acc 0.97028, Validation acc 0.9734, Execution time 480.2203960418701\n",
      "Temperature 44.5, Training acc 0.9725, Validation acc 0.977, Execution time 489.51318287849426\n",
      "Temperature 45.0, Training acc 0.97332, Validation acc 0.9754, Execution time 428.68076610565186\n",
      "Temperature 45.5, Training acc 0.97074, Validation acc 0.9739, Execution time 489.9127428531647\n",
      "Temperature 46.0, Training acc 0.97102, Validation acc 0.9746, Execution time 583.3919117450714\n",
      "Temperature 46.5, Training acc 0.97208, Validation acc 0.9754, Execution time 535.7426490783691\n",
      "Temperature 47.0, Training acc 0.97248, Validation acc 0.9747, Execution time 540.3633768558502\n",
      "Temperature 47.5, Training acc 0.97332, Validation acc 0.9739, Execution time 586.9538519382477\n",
      "Temperature 48.0, Training acc 0.97058, Validation acc 0.9722, Execution time 499.61859607696533\n",
      "Temperature 48.5, Training acc 0.97408, Validation acc 0.9749, Execution time 464.3874228000641\n",
      "Temperature 49.0, Training acc 0.97562, Validation acc 0.9776, Execution time 458.96028113365173\n",
      "Temperature 49.5, Training acc 0.9748, Validation acc 0.9755, Execution time 463.8786151409149\n"
     ]
    }
   ],
   "source": [
    "searchDistill_temperature(data, num_epochs=1, batch_size=100,\n",
    "                          learning_rate=1e-3, logits_teacher=logits_train, \n",
    "                          save_name='VGG16/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
