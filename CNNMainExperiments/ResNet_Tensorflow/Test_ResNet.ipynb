{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "from ResNet import ResNet\n",
    "from utils import load_cifar100\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "# for auto-reloading external modules\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Foo():\n",
    "    def __init__(self, phase, dataset, epoch, batch_size, res_n, lr, checkpoint_dir, log_dir):\n",
    "        self.phase = phase\n",
    "        self.dataset = dataset\n",
    "        self.epoch = epoch\n",
    "        self.batch_size =batch_size\n",
    "        self.res_n=res_n\n",
    "        self.lr=lr\n",
    "        self.checkpoint_dir=checkpoint_dir\n",
    "        self.log_dir=log_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "x_train, y_train, x_test, y_test = load_cifar100()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'X_train': x_train[:49000].transpose(0,3,1,2).copy(), 'y_train': np.argmax(y_train[:49000],axis=1),\n",
    "        'X_val': x_train[49000:].transpose(0,3,1,2).copy(), 'y_val': np.argmax(y_train[49000:],axis=1),\n",
    "        'X_test': x_test.transpose(0,3,1,2).copy(), 'y_test': np.argmax(y_test,axis=1),\n",
    "       }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 32, 32, 3)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [*] Reading checkpoints...\n",
      " [*] Success to read ResNet.model-20000\n",
      " [*] Load SUCCESS\n"
     ]
    }
   ],
   "source": [
    "args = Foo(phase='train',\n",
    "           dataset='cifar100',\n",
    "           epoch=40,\n",
    "           batch_size=100,\n",
    "           res_n=18,\n",
    "           lr=0.1,\n",
    "           checkpoint_dir='checkpoint',\n",
    "           log_dir='logs')\n",
    "\n",
    "images = x_train[:49000]\n",
    "logits_predict = np.zeros((len(images),100))\n",
    "\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "\n",
    "with tf.Graph().as_default():\n",
    "        \n",
    "    with tf.Session(config=tf.ConfigProto(allow_soft_placement=True)) as sess:\n",
    "        cnn = ResNet(sess,args)\n",
    "        # build graph\n",
    "        cnn.build_model()\n",
    "        \n",
    "        tf.global_variables_initializer().run()\n",
    "\n",
    "        cnn.saver = tf.train.Saver()\n",
    "        could_load, _ = cnn.load(cnn.checkpoint_dir)\n",
    "\n",
    "        if could_load:\n",
    "            print(\" [*] Load SUCCESS\")\n",
    "        else:\n",
    "            print(\" [!] Load failed...\")        \n",
    "        \n",
    "        # get batch data\n",
    "        iteration = len(images)//cnn.batch_size\n",
    "        for idx in range(iteration):\n",
    "            batch_x = images[idx*cnn.batch_size:(idx+1)*cnn.batch_size]\n",
    "\n",
    "            predict_feed_dict = {\n",
    "                cnn.train_inptus : batch_x\n",
    "            }\n",
    "\n",
    "            logits = cnn.sess.run(cnn.train_logits, feed_dict=predict_feed_dict)\n",
    "            logits_predict[idx*cnn.batch_size:(idx+1)*cnn.batch_size] = logits\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(49000, 100)\n",
      "[-3.32770371 -2.74245572 -1.11332297  2.34665799  2.48451042 -6.06812906\n",
      "  2.02936721  0.18213981 -1.15276384 -1.29720879 -2.68880868 -1.79230702\n",
      "  1.27115953  0.4580842  -0.74583721  2.88306355 -2.76108265 -0.99674559\n",
      " -0.32749847  4.04755068 -3.51942849  5.56274509 -2.0092423   3.71169114\n",
      " -0.88281202 -3.58735561  0.26666641  1.8727057  -3.60197568 -1.24948847\n",
      "  2.50073552  5.4399457   3.10534453  2.285532   -0.22726886 -1.32995486\n",
      " -1.05093575 -0.78550661 -0.28507647 -2.67669797 -0.8436814  -1.86945808\n",
      " -0.86866707 -1.8867681  -0.48333511 -1.94488466  1.46266103  1.13487577\n",
      " -0.43671042  0.58670652 -1.11991513  2.5235517   0.47974521 -5.74578428\n",
      " -2.30505466  1.17884636  1.08945751 -4.9439292  -2.35735059  4.22439718\n",
      "  0.59201896 -3.98419762  1.35350811  5.92362976 -0.08460547  1.36316156\n",
      "  1.77266073  1.52367055  0.48252025  0.45280215 -2.11718726  1.7239995\n",
      "  6.47616339  5.24690723  3.72679043  4.6872468  -1.03298676  2.65097833\n",
      " -0.76894796  1.71192181  2.72173691  1.34979534 -0.1833282  -5.66419649\n",
      " -5.53301954  1.05825353 -3.59879684 -0.1875537  -2.96018291  0.09591345\n",
      "  7.36387682 -0.35039073 -1.59183121  0.47669908 -6.37848616  1.15000367\n",
      "  3.02457047 -0.28983045 -3.23882556 -2.87448692]\n"
     ]
    }
   ],
   "source": [
    "print(logits_predict.shape)\n",
    "print(logits_predict[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SoftMax(s):\n",
    "    # minus max to avoid large s case\n",
    "    p = np.exp(s-np.expand_dims(np.max(s,axis=1),axis=1))/\\\n",
    "    np.expand_dims(np.exp(s-np.expand_dims(np.max(s,axis=1),axis=1)).sum(axis=1),axis=1)  # matrix of size NxK\n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy of big model: 0.8726326530612245\n"
     ]
    }
   ],
   "source": [
    "y_pred_big = np.argmax(SoftMax(logits_predict),axis=1)\n",
    "y_true = np.argmax(y_train[:49000],axis=1)\n",
    "print('Train accuracy of big model: {}'.format(np.mean(y_true==y_pred_big)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('resnet18_logits_train.txt', 'wb') as fp:\n",
    "    pickle.dump(logits_predict, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [*] Reading checkpoints...\n",
      " [*] Success to read ResNet.model-20000\n",
      " [*] Load SUCCESS\n"
     ]
    }
   ],
   "source": [
    "# Check test accuracy\n",
    "with tf.Graph().as_default():\n",
    "        \n",
    "    with tf.Session(config=tf.ConfigProto(allow_soft_placement=True)) as sess:\n",
    "        cnn = ResNet(sess,args)\n",
    "        # build graph\n",
    "        cnn.build_model()\n",
    "\n",
    "        tf.global_variables_initializer().run()\n",
    "\n",
    "        cnn.saver = tf.train.Saver()\n",
    "        could_load, _ = cnn.load(cnn.checkpoint_dir)\n",
    "\n",
    "        if could_load:\n",
    "            print(\" [*] Load SUCCESS\")\n",
    "        else:\n",
    "            print(\" [!] Load failed...\")        \n",
    "\n",
    "\n",
    "        predict_feed_dict = {\n",
    "            cnn.test_inptus : x_test\n",
    "        }\n",
    "\n",
    "        logits_test = cnn.sess.run(cnn.test_logits, feed_dict=predict_feed_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 100)\n",
      "[-5.1639113e+00 -7.5697646e+00  1.9156983e+00  5.8520656e+00\n",
      " -1.0737603e+00  3.1251509e+00 -3.1966140e+00 -1.7989796e-01\n",
      " -5.8173418e-01 -2.2535324e+00 -4.7869942e-01  4.9313660e+00\n",
      "  7.0755067e+00  1.2944865e+00 -4.6343422e+00  2.5551825e+00\n",
      "  9.5872897e-01  3.7017753e+00  1.6514316e+00 -5.4881730e+00\n",
      " -3.0841486e+00  8.6602241e-01  6.5830040e-01  1.3590215e+00\n",
      "  3.4914798e-01  1.5674220e+00 -1.7908673e+00 -3.3286507e+00\n",
      " -3.9012530e+00 -2.2346768e+00  6.0295162e+00 -6.6462827e-01\n",
      "  1.6215535e+00 -1.6266257e-01 -1.5407908e+00  3.7863574e+00\n",
      " -1.1186889e+00  1.3114735e-03 -1.3134971e+00 -9.0551227e-03\n",
      "  5.1770344e+00 -6.5990796e+00 -1.6741199e+00 -4.0537977e+00\n",
      "  3.5908180e-01  4.2425418e-01  4.7662096e+00 -7.7134719e+00\n",
      " -1.5018659e+00  4.3662581e+00 -5.1767999e-01 -5.8424187e+00\n",
      " -4.2030573e+00 -7.6513343e+00 -3.3669430e-01  6.7252803e+00\n",
      "  2.6845725e+00 -1.8835118e+00 -1.9494309e+00 -1.3035301e+00\n",
      " -1.2396645e-01  8.8761449e-01 -5.4402494e-01  2.4234636e+00\n",
      "  4.9623609e-01 -1.8788347e+00  6.2474895e-01  7.0110941e-01\n",
      "  7.8322077e+00  1.4566087e+00 -4.0483751e+00  4.0419135e+00\n",
      "  6.1732340e+00  4.6810189e-01 -4.8737162e-01 -2.5421476e+00\n",
      "  3.4733620e+00  2.9528413e+00  1.1261503e+00  6.5154858e+00\n",
      " -1.3978498e+00  3.1190219e+00  1.9091243e-01 -7.9204526e+00\n",
      "  3.6580544e+00  5.6646325e-02 -1.0868979e+00  1.7503721e+00\n",
      " -1.1503556e+00 -2.6320860e+00  6.7982855e+00 -1.0240955e+00\n",
      " -4.9703383e+00  4.5964830e-02 -8.2633457e+00  3.3572822e+00\n",
      " -1.4436725e+00 -1.3625082e+00  4.2630334e+00 -2.0194879e+00]\n",
      "Train accuracy of big model: 0.6881\n"
     ]
    }
   ],
   "source": [
    "print(logits_test.shape)\n",
    "print(logits_test[0])\n",
    "y_pred_big = np.argmax(SoftMax(logits_test),axis=1)\n",
    "y_true = np.argmax(y_test,axis=1)\n",
    "print('Train accuracy of big model: {}'.format(np.mean(y_true==y_pred_big)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
