{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from data_utils import load_tiny_imagenet\n",
    "from CNN import ThreeLayerConvNet\n",
    "from model import myModel\n",
    "from ResNet164.resnet164 import ResNet164\n",
    "\n",
    "import h5py\n",
    "import time\n",
    "import pickle\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "# for auto-reloading external modules\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unpickle(file):    \n",
    "    with open(file, 'rb') as fo:\n",
    "        dict = pickle.load(fo)\n",
    "    return dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading training data for synset 20 / 200\n",
      "loading training data for synset 40 / 200\n",
      "loading training data for synset 60 / 200\n",
      "loading training data for synset 80 / 200\n",
      "loading training data for synset 100 / 200\n",
      "loading training data for synset 120 / 200\n",
      "loading training data for synset 140 / 200\n",
      "loading training data for synset 160 / 200\n",
      "loading training data for synset 180 / 200\n",
      "loading training data for synset 200 / 200\n"
     ]
    }
   ],
   "source": [
    "path = 'datasets/tiny-imagenet-200'\n",
    "data = load_tiny_imagenet(path, subtract_mean=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['class_names', 'X_train', 'y_train', 'X_val', 'y_val', 'X_test', 'y_test', 'mean_image'])\n"
     ]
    }
   ],
   "source": [
    "print(data.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "[['Egyptian cat'], ['reel'], ['volleyball'], ['rocking chair', 'rocker'], ['lemon'], ['bullfrog', 'Rana catesbeiana'], ['basketball'], ['cliff', 'drop', 'drop-off'], ['espresso'], ['plunger', \"plumber's helper\"]]\n"
     ]
    }
   ],
   "source": [
    "print(len(data['class_names']))\n",
    "print(data['class_names'][:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100000, 3, 64, 64) (100000,)\n",
      "(10000, 3, 64, 64) (10000,)\n",
      "(10000, 3, 64, 64) None\n"
     ]
    }
   ],
   "source": [
    "print(data['X_train'].shape, data['y_train'].shape)\n",
    "print(data['X_val'].shape, data['y_val'].shape)\n",
    "print(data['X_test'].shape, data['y_test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize data to (0,1)\n",
    "data['X_train'] /= 255\n",
    "data['X_val'] /= 255\n",
    "data['X_test'] /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Iteration 1 / 2000) loss: 6.690653\n",
      "Saving checkpoint to \"checkpoints/small_model_epoch_0.pkl\"\n",
      "(Epoch 0 / 2) train acc: 0.004780; val_acc: 0.004800\n",
      "(Iteration 101 / 2000) loss: 5.566889\n",
      "(Iteration 201 / 2000) loss: 5.210896\n",
      "(Iteration 301 / 2000) loss: 5.024302\n",
      "(Iteration 401 / 2000) loss: 4.829346\n",
      "(Iteration 501 / 2000) loss: 4.826147\n",
      "(Iteration 601 / 2000) loss: 4.693377\n",
      "(Iteration 701 / 2000) loss: 4.709728\n",
      "(Iteration 801 / 2000) loss: 4.456768\n",
      "(Iteration 901 / 2000) loss: 4.507597\n",
      "Saving checkpoint to \"checkpoints/small_model_epoch_1.pkl\"\n",
      "(Epoch 1 / 2) train acc: 0.145240; val_acc: 0.110700\n",
      "(Iteration 1001 / 2000) loss: 4.332254\n",
      "(Iteration 1101 / 2000) loss: 4.552447\n",
      "(Iteration 1201 / 2000) loss: 4.519354\n",
      "(Iteration 1301 / 2000) loss: 4.102624\n",
      "(Iteration 1401 / 2000) loss: 4.304476\n",
      "(Iteration 1501 / 2000) loss: 4.370089\n",
      "(Iteration 1601 / 2000) loss: 4.256931\n",
      "(Iteration 1701 / 2000) loss: 4.244580\n",
      "(Iteration 1801 / 2000) loss: 4.631620\n",
      "(Iteration 1901 / 2000) loss: 4.535921\n",
      "Saving checkpoint to \"checkpoints/small_model_epoch_2.pkl\"\n",
      "(Epoch 2 / 2) train acc: 0.199060; val_acc: 0.137400\n",
      "Execution time:  26920.484703063965\n"
     ]
    }
   ],
   "source": [
    "net = ThreeLayerConvNet(input_dim=(3, 64, 64), num_filters=16, filter_size=7,\n",
    "                        hidden_dim=1024, num_classes=200, reg=0.001, weight_scale=1)\n",
    "\n",
    "small_model = myModel(net, data, \n",
    "                      num_epochs=2, batch_size=100,\n",
    "                      optimizer='adam',\n",
    "                      optim_config={\n",
    "                          'learning_rate': 1e-3,},\n",
    "                      verbose=True, print_every=100,\n",
    "                      checkpoint_name='checkpoints/small_model')\n",
    "tic = time.time()\n",
    "small_model.train()\n",
    "toc = time.time()\n",
    "print('Execution time: ',toc-tic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Iteration 1 / 1000) loss: 3.820186\n",
      "Saving checkpoint to \"checkpoints/small_model_from2_epoch_2.pkl\"\n",
      "(Epoch 2 / 1) train acc: 0.145530; val_acc: 0.102200\n",
      "(Iteration 101 / 1000) loss: 4.155352\n",
      "(Iteration 201 / 1000) loss: 4.118600\n",
      "(Iteration 301 / 1000) loss: 4.164610\n",
      "(Iteration 401 / 1000) loss: 4.302248\n",
      "(Iteration 501 / 1000) loss: 4.022699\n",
      "(Iteration 601 / 1000) loss: 4.249676\n",
      "(Iteration 701 / 1000) loss: 4.129515\n",
      "(Iteration 801 / 1000) loss: 4.131288\n",
      "(Iteration 901 / 1000) loss: 4.060059\n",
      "Saving checkpoint to \"checkpoints/small_model_from2_epoch_3.pkl\"\n",
      "(Epoch 3 / 1) train acc: 0.247390; val_acc: 0.157600\n",
      "Execution time:  18239.308848142624\n"
     ]
    }
   ],
   "source": [
    "net = ThreeLayerConvNet(input_dim=(3, 64, 64), num_filters=16, filter_size=7,\n",
    "                        hidden_dim=1024, num_classes=200, reg=0.001, weight_scale=1)\n",
    "small_model = myModel(net, data, \n",
    "                      num_epochs=1, batch_size=100,\n",
    "                      optimizer='adam',\n",
    "                      optim_config={\n",
    "                          'learning_rate': 1e-3,},\n",
    "                      verbose=True, print_every=100,\n",
    "                      checkpoint_dir='checkpoints/small_model_epoch_2.pkl',\n",
    "                      checkpoint_name='checkpoints/small_model_from2')\n",
    "tic = time.time()\n",
    "small_model.train()\n",
    "toc = time.time()\n",
    "print('Execution time: ',toc-tic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
