{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from data_utils import get_CIFAR10_data, get_MNIST_data\n",
    "from CNN import ThreeLayerConvNet\n",
    "from model import myModel\n",
    "\n",
    "from ResNet164.resnet164 import ResNet164\n",
    "from keras.models import Model\n",
    "\n",
    "import h5py\n",
    "import time\n",
    "import pickle\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "# for auto-reloading external modules\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unpickle(file):    \n",
    "    with open(file, 'rb') as fo:\n",
    "        dict = pickle.load(fo, encoding='bytes')\n",
    "    return dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test with CIFAR-10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train:  (49000, 3, 32, 32)\n",
      "y_train:  (49000,)\n",
      "X_val:  (1000, 3, 32, 32)\n",
      "y_val:  (1000,)\n",
      "X_test:  (1000, 3, 32, 32)\n",
      "y_test:  (1000,)\n"
     ]
    }
   ],
   "source": [
    "# Load the (preprocessed) CIFAR10 data.\n",
    "\n",
    "cifar10_data = get_CIFAR10_data()\n",
    "for k, v in cifar10_data.items():\n",
    "  print('%s: ' % k, v.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Iteration 1 / 980) loss: 2.315664\n",
      "(Epoch 0 / 1) train acc: 0.124265; val_acc: 0.121000\n",
      "(Iteration 101 / 980) loss: 1.780725\n",
      "(Iteration 201 / 980) loss: 1.696385\n",
      "(Iteration 301 / 980) loss: 1.507722\n",
      "(Iteration 401 / 980) loss: 1.603677\n",
      "(Iteration 501 / 980) loss: 1.371052\n",
      "(Iteration 601 / 980) loss: 1.662679\n",
      "(Iteration 701 / 980) loss: 1.441571\n",
      "(Iteration 801 / 980) loss: 1.572337\n",
      "(Iteration 901 / 980) loss: 1.395455\n",
      "(Epoch 1 / 1) train acc: 0.503878; val_acc: 0.500000\n"
     ]
    }
   ],
   "source": [
    "net = ThreeLayerConvNet(reg=0.001,weight_scale=0.1)\n",
    "\n",
    "small_model = myModel(net, cifar10_data,\n",
    "                num_epochs=1, batch_size=50,\n",
    "                optimizer='adam',\n",
    "                optim_config={\n",
    "                  'learning_rate': 1e-3,\n",
    "                },\n",
    "                verbose=True, print_every=100)\n",
    "tic = time.time()\n",
    "small_model.train()\n",
    "toc = time.time()\n",
    "print('Execution time: ',toc-tic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test with MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train:  (59000, 1, 28, 28)\n",
      "y_train:  (59000,)\n",
      "X_val:  (1000, 1, 28, 28)\n",
      "y_val:  (1000,)\n",
      "X_test:  (10000, 1, 28, 28)\n",
      "y_test:  (10000,)\n"
     ]
    }
   ],
   "source": [
    "# Load MNIST data\n",
    "mnist_data = get_MNIST_data(num_test=10000)\n",
    "for k, v in mnist_data.items():\n",
    "  print('%s: ' % k, v.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Iteration 1 / 590) loss: 2.413948\n",
      "(Epoch 0 / 1) train acc: 0.195034; val_acc: 0.181000\n",
      "(Iteration 101 / 590) loss: 0.808981\n",
      "(Iteration 201 / 590) loss: 0.480308\n",
      "(Iteration 301 / 590) loss: 0.333304\n",
      "(Iteration 401 / 590) loss: 0.365276\n",
      "(Iteration 501 / 590) loss: 0.183830\n",
      "(Epoch 1 / 1) train acc: 0.959441; val_acc: 0.961000\n",
      "Execution time:  447.68891406059265\n"
     ]
    }
   ],
   "source": [
    "net = ThreeLayerConvNet(input_dim=(1, 28, 28),num_filters=28,filter_size=5,hidden_dim=10,\n",
    "                        reg=0.001,weight_scale=1,dtype=np.float32)\n",
    "small_model = myModel(net, mnist_data,\n",
    "                num_epochs=1, batch_size=100,\n",
    "                optimizer='adam',\n",
    "                optim_config={\n",
    "                  'learning_rate': 1e-3,\n",
    "                },\n",
    "                verbose=True, print_every=100)\n",
    "tic = time.time()\n",
    "small_model.train()\n",
    "toc = time.time()\n",
    "print('Execution time: ',toc-tic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.9578\n"
     ]
    }
   ],
   "source": [
    "X_test, y_test = mnist_data['X_test'], mnist_data['y_test']\n",
    "\n",
    "print('Test accuracy: {}'.format(small_model.check_accuracy(X_test,y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using data with own preprocessing ResNet164 gives ~87% in test accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(59000, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "# Data for ResNet164\n",
    "x_train = mnist_data['X_train'].transpose(0,2,3,1).copy()\n",
    "x_val = mnist_data['X_val'].transpose(0,2,3,1).copy()\n",
    "x_test = mnist_data['X_test'].transpose(0,2,3,1).copy()\n",
    "print(x_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distill ResNet to small_model for MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check accuracy of big model (ResNet164)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from ResNet164.utils import load_mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data used in ResNet164\n",
    "(x_train, y_train), (x_val, y_val), (x_test, y_test) = load_mnist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 28, 28, 1)\n",
      "(50000, 10)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "# Load ResNet which achieve 99.7% test accuracy\n",
    "big_model = ResNet164()\n",
    "\n",
    "big_model.compile()\n",
    "# Load pre-trained model\n",
    "big_model.load_weights('ResNet164/ResNet164.h5')\n",
    "\n",
    "# Remove softmax from VGG16\n",
    "big_model_woSM = Model(inputs=big_model.model.input, outputs=big_model.model.layers[-2].output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 1662s 33ms/step\n",
      "[-6.2030087  -3.9134192  -6.317644    6.6796656  -2.957327   12.809154\n",
      " -3.4207807   0.18087192  2.3757007   0.04373608]\n"
     ]
    }
   ],
   "source": [
    "logits_train = big_model_woSM.predict(x_train, verbose = 1)\n",
    "print(logits_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy of big model: 0.99966\n"
     ]
    }
   ],
   "source": [
    "y_pred_big = np.argmax(SoftMax(logits_train),axis=1)\n",
    "y_true = np.argmax(y_train,axis=1)\n",
    "print('Test accuracy of big model: {}'.format(np.mean(y_true==y_pred_big)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 10)\n"
     ]
    }
   ],
   "source": [
    "print(logits_train.shape)\n",
    "with open('resnet164_logits_train.txt', 'wb') as fp:\n",
    "    pickle.dump(logits_train, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For being faster pick up file of logit from resnet164\n",
    "logits_train = unpickle('resnet164_logits_train.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 329s 33ms/step\n"
     ]
    }
   ],
   "source": [
    "logits_test = big_model_woSM.predict(x_test, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SoftMax(s):\n",
    "    # minus max to avoid large s case\n",
    "    p = np.exp(s-np.expand_dims(np.max(s,axis=1),axis=1))/\\\n",
    "    np.expand_dims(np.exp(s-np.expand_dims(np.max(s,axis=1),axis=1)).sum(axis=1),axis=1)  # matrix of size NxK\n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy of big model: 0.997\n"
     ]
    }
   ],
   "source": [
    "y_pred_big = np.argmax(SoftMax(logits_test),axis=1)\n",
    "y_true = np.argmax(y_test,axis=1)\n",
    "print('Test accuracy of big model: {}'.format(np.mean(y_true==y_pred_big)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare accuracy of small model with and without using distillation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data to train with small model\n",
    "data = {'X_train': x_train.transpose(0,3,1,2).copy(), 'y_train': np.argmax(y_train,axis=1),\n",
    "        'X_val': x_val.transpose(0,3,1,2).copy(), 'y_val': np.argmax(y_val,axis=1),\n",
    "        'X_test': x_test.transpose(0,3,1,2).copy(), 'y_test': np.argmax(y_test,axis=1),\n",
    "       }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 28, 28, 1) (50000, 10)\n",
      "(50000, 1, 28, 28) (50000,)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape, y_train.shape)\n",
    "\n",
    "print(data['X_train'].shape, data['y_train'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Iteration 1 / 500) loss: 3.470583\n",
      "(Epoch 0 / 1) train acc: 0.172860; val_acc: 0.175800\n",
      "(Iteration 101 / 500) loss: 0.316082\n",
      "(Iteration 201 / 500) loss: 0.309362\n",
      "(Iteration 301 / 500) loss: 0.142844\n",
      "(Iteration 401 / 500) loss: 0.179971\n",
      "(Epoch 1 / 1) train acc: 0.975500; val_acc: 0.973300\n",
      "Execution time:  394.203412771225\n"
     ]
    }
   ],
   "source": [
    "# Train small model without distilling\n",
    "net = ThreeLayerConvNet(input_dim=(1, 28, 28),num_filters=28,filter_size=5,hidden_dim=50,\n",
    "                        reg=0.001,weight_scale=1,dtype=np.float32)\n",
    "small_model = myModel(net, data,\n",
    "                num_epochs=1, batch_size=100,\n",
    "                optimizer='adam',\n",
    "                optim_config={\n",
    "                  'learning_rate': 1e-3,\n",
    "                },\n",
    "                verbose=True, print_every=100)\n",
    "tic = time.time()\n",
    "small_model.train()\n",
    "toc = time.time()\n",
    "print('Execution time: ',toc-tic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.9702\n"
     ]
    }
   ],
   "source": [
    "print('Test accuracy: {}'.format(small_model.check_accuracy(data['X_test'],data['y_test'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Iteration 1 / 500) loss: 31.128427\n",
      "(Epoch 0 / 1) train acc: 0.207020; val_acc: 0.219400\n",
      "(Iteration 101 / 500) loss: 12.530449\n",
      "(Iteration 201 / 500) loss: 11.674805\n",
      "(Iteration 301 / 500) loss: 11.588711\n",
      "(Iteration 401 / 500) loss: 11.688246\n",
      "(Epoch 1 / 1) train acc: 0.980920; val_acc: 0.981300\n",
      "Execution time:  402.96113777160645\n"
     ]
    }
   ],
   "source": [
    "# Train small model with distilling knowledge from big model\n",
    "net = ThreeLayerConvNet(input_dim=(1, 28, 28),num_filters=28,filter_size=5,hidden_dim=50,\n",
    "                        reg=0.001,weight_scale=1,dtype=np.float32)\n",
    "small_model = myModel(net, data,\n",
    "                num_epochs=1, batch_size=100,\n",
    "                optimizer='adam',\n",
    "                optim_config={\n",
    "                  'learning_rate': 1e-3,\n",
    "                },\n",
    "                temperature=5.0,logit_distill=logits_train,\n",
    "                verbose=True, print_every=100)\n",
    "tic = time.time()\n",
    "small_model.train()\n",
    "toc = time.time()\n",
    "print('Execution time: ',toc-tic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.9816\n"
     ]
    }
   ],
   "source": [
    "print('Test accuracy: {}'.format(small_model.check_accuracy(data['X_test'],data['y_test'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Iteration 1 / 500) loss: 2.732309\n",
      "(Epoch 0 / 1) train acc: 0.386420; val_acc: 0.399900\n",
      "(Iteration 101 / 500) loss: 0.279304\n",
      "(Iteration 201 / 500) loss: 0.232153\n",
      "(Iteration 301 / 500) loss: 0.154236\n",
      "(Iteration 401 / 500) loss: 0.149580\n",
      "(Epoch 1 / 1) train acc: 0.979100; val_acc: 0.975600\n",
      "Execution time:  1348.2941009998322\n"
     ]
    }
   ],
   "source": [
    "# Train small model with batch normalization (without distilling)\n",
    "net = ThreeLayerConvNet(input_dim=(1, 28, 28),num_filters=28,filter_size=5,hidden_dim=50,\n",
    "                        reg=0.001,weight_scale=1,dtype=np.float32,batchnorm=True)\n",
    "small_model = myModel(net, data,\n",
    "                num_epochs=1, batch_size=100,\n",
    "                optimizer='adam',\n",
    "                optim_config={\n",
    "                  'learning_rate': 1e-3,\n",
    "                },\n",
    "                verbose=True, print_every=100)\n",
    "tic = time.time()\n",
    "small_model.train()\n",
    "toc = time.time()\n",
    "print('Execution time: ',toc-tic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.9755\n"
     ]
    }
   ],
   "source": [
    "print('Test accuracy: {}'.format(small_model.check_accuracy(data['X_test'],data['y_test'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Iteration 1 / 500) loss: 30.617924\n",
      "(Epoch 0 / 1) train acc: 0.241300; val_acc: 0.246700\n",
      "(Iteration 101 / 500) loss: 17.103761\n",
      "(Iteration 201 / 500) loss: 13.742485\n",
      "(Iteration 301 / 500) loss: 11.510487\n",
      "(Iteration 401 / 500) loss: 11.518176\n",
      "(Epoch 1 / 1) train acc: 0.984660; val_acc: 0.983600\n",
      "Execution time:  655.8659062385559\n",
      "Test accuracy: 0.983\n"
     ]
    }
   ],
   "source": [
    "# Train small model with batch normalization and with distilling knowledge from big model\n",
    "net = ThreeLayerConvNet(input_dim=(1, 28, 28),num_filters=28,filter_size=5,hidden_dim=50,\n",
    "                        reg=0.001,weight_scale=1,dtype=np.float32,batchnorm=True)\n",
    "small_model = myModel(net, data,\n",
    "                num_epochs=1, batch_size=100,\n",
    "                optimizer='adam',\n",
    "                optim_config={\n",
    "                  'learning_rate': 1e-3,\n",
    "                },\n",
    "                temperature=5.0,logit_distill=logits_train,\n",
    "                verbose=True, print_every=100)\n",
    "tic = time.time()\n",
    "small_model.train()\n",
    "toc = time.time()\n",
    "print('Execution time: ',toc-tic)\n",
    "print('Test accuracy: {}'.format(small_model.check_accuracy(data['X_test'],data['y_test'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use knowledge from big model to train small model using unlabeled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Iteration 1 / 500) loss: 58.469911\n",
      "(Epoch 0 / 1) train acc: 0.267340; val_acc: 0.266700\n",
      "(Iteration 101 / 500) loss: 26.392003\n",
      "(Iteration 201 / 500) loss: 23.601190\n",
      "(Iteration 301 / 500) loss: 23.303173\n",
      "(Iteration 401 / 500) loss: 22.829914\n",
      "(Epoch 1 / 1) train acc: 0.979360; val_acc: 0.979400\n",
      "Execution time:  386.4370698928833\n",
      "Test accuracy: 0.979\n"
     ]
    }
   ],
   "source": [
    "# Train small model with batch normalization and with distilling knowledge from big model\n",
    "net = ThreeLayerConvNet(input_dim=(1, 28, 28),num_filters=28,filter_size=5,hidden_dim=50,\n",
    "                        reg=0.001,weight_scale=1,dtype=np.float32)\n",
    "small_model = myModel(net, data,\n",
    "                num_epochs=1, batch_size=100,\n",
    "                optimizer='adam',\n",
    "                optim_config={\n",
    "                  'learning_rate': 1e-3,\n",
    "                },\n",
    "                temperature=5.0,logit_distill=logits_train,alpha=1.0,\n",
    "                verbose=True, print_every=100)\n",
    "tic = time.time()\n",
    "small_model.train()\n",
    "toc = time.time()\n",
    "print('Execution time: ',toc-tic)\n",
    "print('Test accuracy: {}'.format(small_model.check_accuracy(data['X_test'],data['y_test'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training data without digit 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_class(data, class_out=3):\n",
    "    data_not_3 = data.copy()\n",
    "    mask = data_not_3['y_train']!=class_out\n",
    "    \n",
    "    data_not_3['X_train'] = data_not_3['X_train'][mask]\n",
    "    data_not_3['y_train'] = data_not_3['y_train'][mask]\n",
    "    return data_not_3, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_not_3, mask = remove_class(data, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(44899, 1, 28, 28) (44899,)\n",
      "(50000, 1, 28, 28) (50000,)\n"
     ]
    }
   ],
   "source": [
    "# Verify original data which should not change\n",
    "print(data_not_3['X_train'].shape, data_not_3['y_train'].shape)\n",
    "print(data['X_train'].shape, data['y_train'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5 0 4 1 9 2 1 3 1 4 3 5 3 6 1 7 2 8 6 9]\n",
      "[5 0 4 1 9 2 1 1 4 5 6 1 7 2 8 6 9 4 0 9]\n"
     ]
    }
   ],
   "source": [
    "print(data['y_train'][:20].T)\n",
    "print(data_not_3['y_train'][:20].T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Iteration 1 / 448) loss: 3.319217\n",
      "(Epoch 0 / 1) train acc: 0.242856; val_acc: 0.215200\n",
      "(Iteration 101 / 448) loss: 0.257129\n",
      "(Iteration 201 / 448) loss: 0.183139\n",
      "(Iteration 301 / 448) loss: 0.157314\n",
      "(Iteration 401 / 448) loss: 0.240851\n",
      "(Epoch 1 / 1) train acc: 0.972227; val_acc: 0.873700\n",
      "Execution time:  502.87588810920715\n",
      "Test accuracy: 0.8742\n"
     ]
    }
   ],
   "source": [
    "# Train small model without distilling\n",
    "net = ThreeLayerConvNet(input_dim=(1, 28, 28),num_filters=28,filter_size=5,hidden_dim=50,\n",
    "                        reg=0.001,weight_scale=1,dtype=np.float32)\n",
    "small_model = myModel(net, data_not_3,\n",
    "                num_epochs=1, batch_size=100,\n",
    "                optimizer='adam',\n",
    "                optim_config={\n",
    "                  'learning_rate': 1e-3,\n",
    "                },\n",
    "                verbose=True, print_every=100)\n",
    "tic = time.time()\n",
    "small_model.train()\n",
    "toc = time.time()\n",
    "print('Execution time: ',toc-tic)\n",
    "print('Test accuracy: {}'.format(small_model.check_accuracy(data_not_3['X_test'],data_not_3['y_test'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.0\n"
     ]
    }
   ],
   "source": [
    "mask_3 = data_not_3['y_test']==3\n",
    "print('Test accuracy: {}'.\n",
    "      format(small_model.check_accuracy(data_not_3['X_test'][mask_3],data_not_3['y_test'][mask_3])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_3 = data_not_3['y_test']==3\n",
    "# remove digit 3 from knowledge come from big model\n",
    "logits_train_not_3 = logits_train[mask].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 10) (44899, 10)\n"
     ]
    }
   ],
   "source": [
    "# verify new and original data\n",
    "print(logits_train.shape, logits_train_not_3.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Iteration 1 / 448) loss: 12.767096\n",
      "(Epoch 0 / 1) train acc: 0.305508; val_acc: 0.271700\n",
      "(Iteration 101 / 448) loss: 2.125419\n",
      "(Iteration 201 / 448) loss: 1.406824\n",
      "(Iteration 301 / 448) loss: 1.317867\n",
      "(Iteration 401 / 448) loss: 1.553746\n",
      "(Epoch 1 / 1) train acc: 0.980512; val_acc: 0.879000\n",
      "Execution time:  367.10596680641174\n",
      "Test accuracy: 0.8813\n"
     ]
    }
   ],
   "source": [
    "# Train small model with distilling\n",
    "net = ThreeLayerConvNet(input_dim=(1, 28, 28),num_filters=28,filter_size=5,hidden_dim=50,\n",
    "                        reg=0.001,weight_scale=1,dtype=np.float32)\n",
    "small_model = myModel(net, data_not_3,\n",
    "                num_epochs=1, batch_size=100,\n",
    "                optimizer='adam',\n",
    "                optim_config={\n",
    "                  'learning_rate': 1e-3,\n",
    "                },\n",
    "                temperature=3.0, logit_distill=logits_train_not_3,\n",
    "                verbose=True, print_every=100)\n",
    "tic = time.time()\n",
    "small_model.train()\n",
    "toc = time.time()\n",
    "print('Execution time: ',toc-tic)\n",
    "print('Test accuracy: {}'.format(small_model.check_accuracy(data_not_3['X_test'],data_not_3['y_test'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.005940594059405941\n"
     ]
    }
   ],
   "source": [
    "print('Test accuracy: {}'.\n",
    "      format(small_model.check_accuracy(data_not_3['X_test'][mask_3],data_not_3['y_test'][mask_3])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.005940594059405941*sum(mask_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Iteration 1 / 448) loss: 8.714978\n",
      "(Epoch 0 / 1) train acc: 0.311009; val_acc: 0.289900\n",
      "(Iteration 101 / 448) loss: 1.726750\n",
      "(Iteration 201 / 448) loss: 0.588200\n",
      "(Iteration 301 / 448) loss: 0.818060\n",
      "(Iteration 401 / 448) loss: 0.530997\n",
      "(Epoch 1 / 1) train acc: 0.978196; val_acc: 0.878300\n",
      "Execution time:  365.2879328727722\n",
      "Test accuracy: 0.8768\n"
     ]
    }
   ],
   "source": [
    "# Train small model with distilling\n",
    "net = ThreeLayerConvNet(input_dim=(1, 28, 28),num_filters=28,filter_size=5,hidden_dim=50,\n",
    "                        reg=0.001,weight_scale=1,dtype=np.float32)\n",
    "small_model = myModel(net, data_not_3,\n",
    "                num_epochs=1, batch_size=100,\n",
    "                optimizer='adam',\n",
    "                optim_config={\n",
    "                  'learning_rate': 1e-3,\n",
    "                },\n",
    "                temperature=2.5, logit_distill=logits_train_not_3,\n",
    "                verbose=True, print_every=100)\n",
    "tic = time.time()\n",
    "small_model.train()\n",
    "toc = time.time()\n",
    "print('Execution time: ',toc-tic)\n",
    "print('Test accuracy: {}'.format(small_model.check_accuracy(data_not_3['X_test'],data_not_3['y_test'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.0019801980198019802\n"
     ]
    }
   ],
   "source": [
    "print('Test accuracy: {}'.\n",
    "      format(small_model.check_accuracy(data_not_3['X_test'][mask_3],data_not_3['y_test'][mask_3])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Iteration 1 / 448) loss: 19.946362\n",
      "(Epoch 0 / 1) train acc: 0.158868; val_acc: 0.143800\n",
      "(Iteration 101 / 448) loss: 5.611085\n",
      "(Iteration 201 / 448) loss: 4.812587\n",
      "(Iteration 301 / 448) loss: 5.758645\n",
      "(Iteration 401 / 448) loss: 4.807010\n",
      "(Epoch 1 / 1) train acc: 0.980400; val_acc: 0.882100\n",
      "Execution time:  361.6439278125763\n",
      "Test accuracy: 0.8833\n"
     ]
    }
   ],
   "source": [
    "# Train small model with distilling\n",
    "net = ThreeLayerConvNet(input_dim=(1, 28, 28),num_filters=28,filter_size=5,hidden_dim=50,\n",
    "                        reg=0.001,weight_scale=1,dtype=np.float32)\n",
    "small_model = myModel(net, data_not_3,\n",
    "                num_epochs=1, batch_size=100,\n",
    "                optimizer='adam',\n",
    "                optim_config={\n",
    "                  'learning_rate': 1e-3,\n",
    "                },\n",
    "                temperature=4.0, logit_distill=logits_train_not_3,\n",
    "                verbose=True, print_every=100)\n",
    "tic = time.time()\n",
    "small_model.train()\n",
    "toc = time.time()\n",
    "print('Execution time: ',toc-tic)\n",
    "print('Test accuracy: {}'.format(small_model.check_accuracy(data_not_3['X_test'],data_not_3['y_test'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.034653465346534656\n"
     ]
    }
   ],
   "source": [
    "print('Test accuracy: {}'.\n",
    "      format(small_model.check_accuracy(data_not_3['X_test'][mask_3],data_not_3['y_test'][mask_3])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35.0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.034653465346534656*sum(mask_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Iteration 1 / 448) loss: 461.625588\n",
      "(Epoch 0 / 1) train acc: 0.164347; val_acc: 0.152600\n",
      "(Iteration 101 / 448) loss: 446.038888\n",
      "(Iteration 201 / 448) loss: 446.381245\n",
      "(Iteration 301 / 448) loss: 445.294606\n",
      "(Iteration 401 / 448) loss: 443.807440\n",
      "(Epoch 1 / 1) train acc: 0.980935; val_acc: 0.893700\n",
      "Execution time:  360.6434180736542\n",
      "Test accuracy: 0.8934\n"
     ]
    }
   ],
   "source": [
    "# Train small model with distilling\n",
    "net = ThreeLayerConvNet(input_dim=(1, 28, 28),num_filters=28,filter_size=5,hidden_dim=50,\n",
    "                        reg=0.001,weight_scale=1,dtype=np.float32)\n",
    "small_model = myModel(net, data_not_3,\n",
    "                num_epochs=1, batch_size=100,\n",
    "                optimizer='adam',\n",
    "                optim_config={\n",
    "                  'learning_rate': 1e-3,\n",
    "                },\n",
    "                temperature=20.0, logit_distill=logits_train_not_3,\n",
    "                verbose=True, print_every=100)\n",
    "tic = time.time()\n",
    "small_model.train()\n",
    "toc = time.time()\n",
    "print('Execution time: ',toc-tic)\n",
    "print('Test accuracy: {}'.format(small_model.check_accuracy(data_not_3['X_test'],data_not_3['y_test'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.11188118811881188\n"
     ]
    }
   ],
   "source": [
    "mask_3 = data_not_3['y_test']==3\n",
    "print('Test accuracy: {}'.\n",
    "      format(small_model.check_accuracy(data_not_3['X_test'][mask_3],data_not_3['y_test'][mask_3])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "113.0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.11188118811881188*sum(mask_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Iteration 1 / 448) loss: 2879.750401\n",
      "(Epoch 0 / 1) train acc: 0.231698; val_acc: 0.207200\n",
      "(Iteration 101 / 448) loss: 2866.701205\n",
      "(Iteration 201 / 448) loss: 2865.685626\n",
      "(Iteration 301 / 448) loss: 2865.922503\n",
      "(Iteration 401 / 448) loss: 2865.657721\n",
      "(Epoch 1 / 1) train acc: 0.979086; val_acc: 0.879700\n",
      "Execution time:  349.06136202812195\n",
      "Test accuracy: 0.8819\n"
     ]
    }
   ],
   "source": [
    "# Train small model with distilling\n",
    "net = ThreeLayerConvNet(input_dim=(1, 28, 28),num_filters=28,filter_size=5,hidden_dim=50,\n",
    "                        reg=0.001,weight_scale=1,dtype=np.float32)\n",
    "small_model = myModel(net, data_not_3,\n",
    "                num_epochs=1, batch_size=100,\n",
    "                optimizer='adam',\n",
    "                optim_config={\n",
    "                  'learning_rate': 1e-3,\n",
    "                },\n",
    "                temperature=50.0, logit_distill=logits_train_not_3,\n",
    "                verbose=True, print_every=100)\n",
    "tic = time.time()\n",
    "small_model.train()\n",
    "toc = time.time()\n",
    "print('Execution time: ',toc-tic)\n",
    "print('Test accuracy: {}'.format(small_model.check_accuracy(data_not_3['X_test'],data_not_3['y_test'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.01782178217821782\n"
     ]
    }
   ],
   "source": [
    "print('Test accuracy: {}'.\n",
    "      format(small_model.check_accuracy(data_not_3['X_test'][mask_3],data_not_3['y_test'][mask_3])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add bias "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['W1', 'b1', 'W2', 'b2', 'W3', 'b3'])\n"
     ]
    }
   ],
   "source": [
    "# Check bias of 3-digit\n",
    "print(small_model.model.params.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.00169301  0.02463553  0.00436699 -0.00590691  0.00758079 -0.00038451\n",
      "  0.00223532 -0.01131989 -0.01801676  0.00932435]\n"
     ]
    }
   ],
   "source": [
    "print(small_model.model.params['b3'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.6930116e-03  2.4635525e-02  4.3669855e-03  3.4940932e+00\n",
      "  7.5807851e-03 -3.8450916e-04  2.2353220e-03 -1.1319885e-02\n",
      " -1.8016757e-02  9.3243457e-03]\n"
     ]
    }
   ],
   "source": [
    "bias_3 = np.zeros_like(small_model.model.params['b3'])\n",
    "bias_3[3] = 3.5\n",
    "small_model.model.params['b3'] += bias_3\n",
    "print(small_model.model.params['b3'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.4792079207920792\n"
     ]
    }
   ],
   "source": [
    "# accurancy of class 3 after increasing the bias at 3\n",
    "print('Test accuracy: {}'.\n",
    "      format(small_model.check_accuracy(data_not_3['X_test'][mask_3],data_not_3['y_test'][mask_3])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.9279\n"
     ]
    }
   ],
   "source": [
    "# test accurancy of the distilled model after increasing the bias at 3\n",
    "print('Test accuracy: {}'.\n",
    "      format(small_model.check_accuracy(data_not_3['X_test'],data_not_3['y_test'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train distillation model with only 2 classes or 1 class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10017 5175 4842\n"
     ]
    }
   ],
   "source": [
    "mask_7 = data['y_train']==7\n",
    "mask_8 = data['y_train']==8\n",
    "mask_7_8 = mask_7+mask_8\n",
    "print(sum(mask_7_8), sum(mask_7), sum(mask_8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5 0 4 1 9 2 1 1 4 5 6 1 7 2 8 6 9 4 0 9 1 1 2 4 2 7 8 6 9 0 5 6 0 7 6 1 8\n",
      " 7 9 9 8 5 9 0 7 4 9 8 0 9]\n"
     ]
    }
   ],
   "source": [
    "print(data['y_train'][:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10017, 1, 28, 28) (10017,)\n"
     ]
    }
   ],
   "source": [
    "data_7_8 = data.copy()\n",
    "data_7_8['X_train'] = data_7_8['X_train'][mask_7_8]\n",
    "data_7_8['y_train'] = data_7_8['y_train'][mask_7_8]\n",
    "print(data_7_8['X_train'].shape, data_7_8['y_train'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 1, 28, 28) (50000,)\n",
      "(10017, 1, 28, 28) (10017,)\n"
     ]
    }
   ],
   "source": [
    "print(data['X_train'].shape, data['y_train'].shape)\n",
    "print(data_7_8['X_train'].shape, data_7_8['y_train'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Iteration 1 / 100) loss: 2.175337\n",
      "(Epoch 0 / 1) train acc: 0.905361; val_acc: 0.192200\n",
      "(Epoch 1 / 1) train acc: 0.991814; val_acc: 0.208400\n",
      "Execution time:  94.81561994552612\n",
      "Test accuracy: 0.1981\n"
     ]
    }
   ],
   "source": [
    "# Train small model with distilling\n",
    "net = ThreeLayerConvNet(input_dim=(1, 28, 28),num_filters=28,filter_size=5,hidden_dim=50,\n",
    "                        reg=0.001,weight_scale=1,dtype=np.float32)\n",
    "small_model = myModel(net, data_7_8,\n",
    "                num_epochs=1, batch_size=100,\n",
    "                optimizer='adam',\n",
    "                optim_config={\n",
    "                  'learning_rate': 1e-3,\n",
    "                },\n",
    "                verbose=True, print_every=100)\n",
    "tic = time.time()\n",
    "small_model.train()\n",
    "toc = time.time()\n",
    "print('Execution time: ',toc-tic)\n",
    "print('Test accuracy: {}'.format(small_model.check_accuracy(data_7_8['X_test'],data_7_8['y_test'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7998\n",
      "Test accuracy: 0.0\n"
     ]
    }
   ],
   "source": [
    "mask_not_7_8 = np.logical_and(data['y_test']!=7, data['y_test']!=8)\n",
    "print(sum(mask_not_7_8))\n",
    "print('Test accuracy: {}'.\n",
    "      format(small_model.check_accuracy(data_7_8['X_test'][mask_not_7_8],data_7_8['y_test'][mask_not_7_8])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 10) (10017, 10)\n"
     ]
    }
   ],
   "source": [
    "# take only 7 and 8 digit from knowledge come from big model\n",
    "logits_train_7_8 = logits_train[mask_7_8].copy()\n",
    "# verify new and original data\n",
    "print(logits_train.shape, logits_train_7_8.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Iteration 1 / 100) loss: 464.934103\n",
      "(Epoch 0 / 1) train acc: 0.544375; val_acc: 0.115700\n",
      "(Epoch 1 / 1) train acc: 0.994010; val_acc: 0.208500\n",
      "Execution time:  95.38177514076233\n",
      "Test accuracy: 0.1988\n"
     ]
    }
   ],
   "source": [
    "# Train small model with distilling\n",
    "net = ThreeLayerConvNet(input_dim=(1, 28, 28),num_filters=28,filter_size=5,hidden_dim=50,\n",
    "                        reg=0.001,weight_scale=1,dtype=np.float32)\n",
    "small_model = myModel(net, data_7_8,\n",
    "                num_epochs=1, batch_size=100,\n",
    "                optimizer='adam',\n",
    "                optim_config={\n",
    "                  'learning_rate': 1e-3,\n",
    "                },\n",
    "                temperature=20.0, logit_distill=logits_train_7_8,\n",
    "                verbose=True, print_every=100)\n",
    "tic = time.time()\n",
    "small_model.train()\n",
    "toc = time.time()\n",
    "print('Execution time: ',toc-tic)\n",
    "print('Test accuracy: {}'.format(small_model.check_accuracy(data_7_8['X_test'],data_7_8['y_test'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.00012503125781445363\n"
     ]
    }
   ],
   "source": [
    "print('Test accuracy: {}'.\n",
    "      format(small_model.check_accuracy(data_7_8['X_test'][mask_not_7_8],data_7_8['y_test'][mask_not_7_8])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.01286919  0.00903602 -0.0188286   0.00395877 -0.00949581  0.00819844\n",
      " -0.01376974  0.00276909  0.00058601 -0.00525341]\n"
     ]
    }
   ],
   "source": [
    "print(small_model.model.params['b3'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.2869191e-02  9.0360213e-03 -1.8828603e-02  3.9587682e-03\n",
      " -9.4958069e-03  8.1984363e-03 -1.3769737e-02 -7.5972309e+00\n",
      " -7.5994139e+00 -5.2534081e-03]\n"
     ]
    }
   ],
   "source": [
    "bias_7_8 = np.zeros_like(small_model.model.params['b3'])\n",
    "bias_7_8[7] = 7.6\n",
    "bias_7_8[8] = 7.6\n",
    "small_model.model.params['b3'] -= bias_7_8\n",
    "print(small_model.model.params['b3'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.12253063265816454\n"
     ]
    }
   ],
   "source": [
    "# Accuracy on class 7 & 8\n",
    "print('Test accuracy: {}'.\n",
    "      format(small_model.check_accuracy(data_7_8['X_test'][mask_not_7_8],data_7_8['y_test'][mask_not_7_8])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.2909\n"
     ]
    }
   ],
   "source": [
    "# Accuracy on whole test set\n",
    "print('Test accuracy: {}'.format(small_model.check_accuracy(data_7_8['X_test'],data_7_8['y_test'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Iteration 1 / 100) loss: 2880.486162\n",
      "(Epoch 0 / 1) train acc: 0.579714; val_acc: 0.124200\n",
      "(Epoch 1 / 1) train acc: 0.994809; val_acc: 0.209900\n",
      "Execution time:  90.94003295898438\n",
      "Test accuracy: 0.2\n"
     ]
    }
   ],
   "source": [
    "# Train small model with distilling\n",
    "net = ThreeLayerConvNet(input_dim=(1, 28, 28),num_filters=28,filter_size=5,hidden_dim=50,\n",
    "                        reg=0.001,weight_scale=1,dtype=np.float32)\n",
    "small_model = myModel(net, data_7_8,\n",
    "                num_epochs=1, batch_size=100,\n",
    "                optimizer='adam',\n",
    "                optim_config={\n",
    "                  'learning_rate': 1e-3,\n",
    "                },\n",
    "                temperature=50.0, logit_distill=logits_train_7_8,\n",
    "                verbose=True, print_every=100)\n",
    "tic = time.time()\n",
    "small_model.train()\n",
    "toc = time.time()\n",
    "print('Execution time: ',toc-tic)\n",
    "print('Test accuracy: {}'.format(small_model.check_accuracy(data_7_8['X_test'],data_7_8['y_test'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.0017504376094023505\n"
     ]
    }
   ],
   "source": [
    "print('Test accuracy: {}'.\n",
    "      format(small_model.check_accuracy(data_7_8['X_test'][mask_not_7_8],data_7_8['y_test'][mask_not_7_8])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.00720396  0.00685708 -0.00248807 -0.00164515 -0.01292054 -0.00159284\n",
      " -0.00695635  0.00915938 -0.00256593  0.01327047]\n",
      "[ 7.2039641e-03  6.8570757e-03 -2.4880739e-03 -1.6451530e-03\n",
      " -1.2920539e-02 -1.5928353e-03 -6.9563491e-03 -7.5908403e+00\n",
      " -7.6025658e+00  1.3270469e-02]\n"
     ]
    }
   ],
   "source": [
    "print(small_model.model.params['b3'])\n",
    "# reduce bias on 7 and 8 class\n",
    "small_model.model.params['b3'] -= bias_7_8\n",
    "print(small_model.model.params['b3'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.19617404351087772\n",
      "Test accuracy: 0.3485\n"
     ]
    }
   ],
   "source": [
    "# Accuracy on class 7 & 8\n",
    "print('Test accuracy: {}'.\n",
    "      format(small_model.check_accuracy(data_7_8['X_test'][mask_not_7_8],data_7_8['y_test'][mask_not_7_8])))\n",
    "# Accuracy on whole test set\n",
    "print('Test accuracy: {}'.format(small_model.check_accuracy(data_7_8['X_test'],data_7_8['y_test'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4 5 6 0 0 9]\n"
     ]
    }
   ],
   "source": [
    "a = np.arange(10)\n",
    "a[[7,8]] = 0\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
