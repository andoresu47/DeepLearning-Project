{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import concatenate\n",
    "from keras.layers.core import Dense, Activation, Dropout, Flatten, Lambda \n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D\n",
    "from scipy.ndimage.interpolation import rotate, shift, zoom\n",
    "from keras.constraints import max_norm\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.layers import Flatten,  MaxPooling2D, Conv2D\n",
    "from keras.callbacks import TensorBoard\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import json\n",
    "from PIL import Image\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.utils import to_categorical\n",
    "from prediction_utils import predict_proba\n",
    "from shufflenet import get_shufflenet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_v = tf.logging.get_verbosity()\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SOFTMAX(s_):\n",
    "    return np.exp(s_) / np.matmul(np.ones((1, s_.shape[0])), np.exp(s_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def soft_targets(temp, logits, n_classes):\n",
    "    soft_targets_ = np.zeros((len(logits), n_classes))\n",
    "    for i in range(len(logits)):\n",
    "        soft_targets_[i] = SOFTMAX(logits[i]/temp)\n",
    "    return soft_targets_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def knowledge_distillation_loss(y_true, y_pred, alpha):\n",
    "\n",
    "    # Extract the one-hot encoded values and the softs separately so that we can create two objective functions\n",
    "    y_true, y_true_softs = y_true[: , :nb_classes], y_true[: , nb_classes:]\n",
    "    \n",
    "    y_pred, y_pred_softs = y_pred[: , :nb_classes], y_pred[: , nb_classes:]\n",
    "    \n",
    "    loss =(alpha * tf.keras.losses.categorical_crossentropy(y_true, y_pred) +\n",
    "           tf.keras.losses.categorical_crossentropy(y_true_softs, y_pred_softs))\n",
    "    return loss\n",
    "\n",
    "def acc(y_true, y_pred):\n",
    "    y_true = y_true[:, :nb_classes]\n",
    "    y_pred = y_pred[:, :nb_classes]\n",
    "    return tf.keras.metrics.categorical_accuracy(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this file is created after training is finished\n",
    "config_path = 'logs/run0/model_config.txt'\n",
    "\n",
    "# folder where validation dataset is\n",
    "validation_images = 'tiny-imagenet-200/validation/'\n",
    "\n",
    "# this file is created when you run `image_dataset_to_tfrecords.py`\n",
    "class_encoder_path = 'tiny-imagenet-200/class_encoder.npy'\n",
    "\n",
    "# this file comes with dataset\n",
    "class_names_file = 'tiny-imagenet-200/words.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# folder name -> class name in human readable format\n",
    "class_names = pd.read_csv(class_names_file, sep='\\t', header=None)\n",
    "names = dict(class_names.set_index(0)[1])\n",
    "\n",
    "# folder name -> class index\n",
    "encoder = np.load(class_encoder_path)[()]\n",
    "\n",
    "# class index -> class name in human readable format\n",
    "decoder = {encoder[i]: names[i] for i in encoder}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher_train_logits = np.load(\n",
    "    'new_teacher_train_logits.npz')['arr_0']\n",
    "teacher_val_logits = np.load(\n",
    "    'new_teacher_val_logits.npz')['arr_0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_val = np.load('x_val.npz')['arr_0']\n",
    "x_train = np.load('new_x_train.npz')['arr_0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.load('new_y_train.npz')['arr_0']\n",
    "y_val = np.load('y_val.npz')['arr_0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's verify the teacher predictions on the validation set  are the same as before:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_path = 'logs/run0/model_config.txt'\n",
    "config = json.load(open(config_path))\n",
    "\n",
    "graph, ops = get_shufflenet(\n",
    "    groups=config['groups'], \n",
    "    complexity_scale_factor=config['complexity_scale_factor']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_val = predict_proba(graph, ops, x_val, run=config['run'])\n",
    "predictions_argmax = np.argmax(predictions_val, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5072213181448332"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean((y_val == predictions_argmax))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's verify the teacher predictions on the training set  are the same as before:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#I'm batching so my computer doesn't pass out.\n",
    "batch_size = 10000\n",
    "# predictions_training = [predict_proba(graph, ops, X[i], run=config['run']) for i in ]\n",
    "predictions_training = []\n",
    "for batch_idx in range(x_train.shape[0] // batch_size + 1):\n",
    "    #print(\"new batch\")\n",
    "    X_batch = x_train[batch_idx * batch_size: (batch_idx + 1) * batch_size]\n",
    "    batch_pred = predict_proba(graph, ops, X_batch, run=config['run'])\n",
    "    predictions_training.append(batch_pred)\n",
    "concatenated_predictions_training = predictions_training[0]\n",
    "for batch_prediction in predictions_training[1:]:\n",
    "    concatenated_predictions_training = np.concatenate((concatenated_predictions_training, batch_prediction), axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_argmax = np.argmax(concatenated_predictions_training, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.598620886340256"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean((y_train == predictions_argmax))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoding labels in one hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_classes = 200\n",
    "#one hot representation\n",
    "y_train = to_categorical(y_train)\n",
    "y_val= to_categorical(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training without distillation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model without distillation:\n",
    "model = Sequential()\n",
    "model.add(Flatten(input_shape=(56,56,3)))\n",
    "model.add(Dense(800, activation='relu'))\n",
    "model.add(Dense(800, activation='relu'))\n",
    "model.add(Dense(nb_classes))\n",
    "model.add(Activation('softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "tensor_board = TensorBoard('./logs/tiny-imagenet-t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 98179 samples, validate on 9832 samples\n",
      "Epoch 1/50\n",
      "98179/98179 [==============================] - 9s 91us/step - loss: 5.0301 - acc: 0.0321 - val_loss: 4.7585 - val_acc: 0.0504\n",
      "Epoch 2/50\n",
      "98179/98179 [==============================] - 9s 89us/step - loss: 4.6713 - acc: 0.0603 - val_loss: 4.6312 - val_acc: 0.0661\n",
      "Epoch 3/50\n",
      "98179/98179 [==============================] - 9s 89us/step - loss: 4.5427 - acc: 0.0765 - val_loss: 4.5402 - val_acc: 0.0783\n",
      "Epoch 4/50\n",
      "98179/98179 [==============================] - 9s 89us/step - loss: 4.4489 - acc: 0.0870 - val_loss: 4.4932 - val_acc: 0.0878\n",
      "Epoch 5/50\n",
      "98179/98179 [==============================] - 9s 89us/step - loss: 4.3699 - acc: 0.0968 - val_loss: 4.4909 - val_acc: 0.0831\n",
      "Epoch 6/50\n",
      "98179/98179 [==============================] - 9s 89us/step - loss: 4.2952 - acc: 0.1063 - val_loss: 4.4494 - val_acc: 0.0933\n",
      "Epoch 7/50\n",
      "98179/98179 [==============================] - 9s 90us/step - loss: 4.2334 - acc: 0.1143 - val_loss: 4.4539 - val_acc: 0.0928\n",
      "Epoch 8/50\n",
      "98179/98179 [==============================] - 9s 89us/step - loss: 4.1664 - acc: 0.1216 - val_loss: 4.4279 - val_acc: 0.1012\n",
      "Epoch 9/50\n",
      "98179/98179 [==============================] - 9s 89us/step - loss: 4.1097 - acc: 0.1302 - val_loss: 4.4836 - val_acc: 0.0931\n",
      "Epoch 10/50\n",
      "98179/98179 [==============================] - 9s 89us/step - loss: 4.0574 - acc: 0.1349 - val_loss: 4.4473 - val_acc: 0.1015\n",
      "Epoch 11/50\n",
      "98179/98179 [==============================] - 9s 89us/step - loss: 4.0047 - acc: 0.1419 - val_loss: 4.4733 - val_acc: 0.0980\n",
      "Epoch 12/50\n",
      "98179/98179 [==============================] - 9s 89us/step - loss: 3.9428 - acc: 0.1488 - val_loss: 4.5005 - val_acc: 0.1000\n",
      "Epoch 13/50\n",
      "98179/98179 [==============================] - 9s 89us/step - loss: 3.8967 - acc: 0.1555 - val_loss: 4.5108 - val_acc: 0.1012\n",
      "Epoch 14/50\n",
      "98179/98179 [==============================] - 9s 89us/step - loss: 3.8400 - acc: 0.1632 - val_loss: 4.5753 - val_acc: 0.0957\n",
      "Epoch 15/50\n",
      "98179/98179 [==============================] - 9s 89us/step - loss: 3.7835 - acc: 0.1717 - val_loss: 4.5650 - val_acc: 0.0993\n",
      "Epoch 16/50\n",
      "98179/98179 [==============================] - 9s 89us/step - loss: 3.7388 - acc: 0.1767 - val_loss: 4.6138 - val_acc: 0.1003\n",
      "Epoch 17/50\n",
      "98179/98179 [==============================] - 9s 89us/step - loss: 3.6896 - acc: 0.1844 - val_loss: 4.6288 - val_acc: 0.0990\n",
      "Epoch 18/50\n",
      "98179/98179 [==============================] - 9s 89us/step - loss: 3.6417 - acc: 0.1902 - val_loss: 4.6875 - val_acc: 0.0997\n",
      "Epoch 19/50\n",
      "98179/98179 [==============================] - 9s 89us/step - loss: 3.5861 - acc: 0.1999 - val_loss: 4.7528 - val_acc: 0.0974\n",
      "Epoch 20/50\n",
      "98179/98179 [==============================] - 9s 89us/step - loss: 3.5462 - acc: 0.2036 - val_loss: 4.8016 - val_acc: 0.0970\n",
      "Epoch 21/50\n",
      "98179/98179 [==============================] - 9s 89us/step - loss: 3.5090 - acc: 0.2100 - val_loss: 4.8674 - val_acc: 0.0914\n",
      "Epoch 22/50\n",
      "98179/98179 [==============================] - 9s 89us/step - loss: 3.4539 - acc: 0.2196 - val_loss: 4.8481 - val_acc: 0.0969\n",
      "Epoch 23/50\n",
      "98179/98179 [==============================] - 9s 89us/step - loss: 3.4035 - acc: 0.2276 - val_loss: 4.8848 - val_acc: 0.0958\n",
      "Epoch 24/50\n",
      "98179/98179 [==============================] - 9s 89us/step - loss: 3.3800 - acc: 0.2318 - val_loss: 4.9632 - val_acc: 0.0925\n",
      "Epoch 25/50\n",
      "98179/98179 [==============================] - 9s 89us/step - loss: 3.3343 - acc: 0.2382 - val_loss: 5.0048 - val_acc: 0.0978\n",
      "Epoch 26/50\n",
      "98179/98179 [==============================] - 9s 89us/step - loss: 3.3008 - acc: 0.2434 - val_loss: 5.0493 - val_acc: 0.0892\n",
      "Epoch 27/50\n",
      "98179/98179 [==============================] - 9s 89us/step - loss: 3.2757 - acc: 0.2481 - val_loss: 5.1016 - val_acc: 0.0928\n",
      "Epoch 28/50\n",
      "98179/98179 [==============================] - 9s 89us/step - loss: 3.2219 - acc: 0.2568 - val_loss: 5.1127 - val_acc: 0.0931\n",
      "Epoch 29/50\n",
      "98179/98179 [==============================] - 9s 89us/step - loss: 3.2077 - acc: 0.2590 - val_loss: 5.1790 - val_acc: 0.0922\n",
      "Epoch 30/50\n",
      "98179/98179 [==============================] - 9s 89us/step - loss: 3.1616 - acc: 0.2667 - val_loss: 5.3069 - val_acc: 0.0892\n",
      "Epoch 31/50\n",
      "98179/98179 [==============================] - 8s 85us/step - loss: 3.1453 - acc: 0.2699 - val_loss: 5.1882 - val_acc: 0.0942\n",
      "Epoch 32/50\n",
      "98179/98179 [==============================] - 8s 86us/step - loss: 3.1022 - acc: 0.2777 - val_loss: 5.2791 - val_acc: 0.0906\n",
      "Epoch 33/50\n",
      "98179/98179 [==============================] - 8s 85us/step - loss: 3.0756 - acc: 0.2815 - val_loss: 5.3674 - val_acc: 0.0932\n",
      "Epoch 34/50\n",
      "98179/98179 [==============================] - 8s 84us/step - loss: 3.0445 - acc: 0.2878 - val_loss: 5.4685 - val_acc: 0.0872\n",
      "Epoch 35/50\n",
      "98179/98179 [==============================] - 9s 88us/step - loss: 3.0287 - acc: 0.2903 - val_loss: 5.4447 - val_acc: 0.0887\n",
      "Epoch 36/50\n",
      "98179/98179 [==============================] - 9s 89us/step - loss: 2.9931 - acc: 0.2968 - val_loss: 5.4426 - val_acc: 0.0874\n",
      "Epoch 37/50\n",
      "98179/98179 [==============================] - 9s 89us/step - loss: 2.9804 - acc: 0.2994 - val_loss: 5.5056 - val_acc: 0.0833\n",
      "Epoch 38/50\n",
      "98179/98179 [==============================] - 9s 89us/step - loss: 2.9506 - acc: 0.3056 - val_loss: 5.5930 - val_acc: 0.0842\n",
      "Epoch 39/50\n",
      "98179/98179 [==============================] - 9s 89us/step - loss: 2.9288 - acc: 0.3100 - val_loss: 5.5611 - val_acc: 0.0886\n",
      "Epoch 40/50\n",
      "98179/98179 [==============================] - 9s 89us/step - loss: 2.9018 - acc: 0.3146 - val_loss: 5.6936 - val_acc: 0.0831\n",
      "Epoch 41/50\n",
      "98179/98179 [==============================] - 9s 89us/step - loss: 2.8763 - acc: 0.3198 - val_loss: 5.6767 - val_acc: 0.0862\n",
      "Epoch 42/50\n",
      "98179/98179 [==============================] - 9s 89us/step - loss: 2.8556 - acc: 0.3221 - val_loss: 5.7936 - val_acc: 0.0852\n",
      "Epoch 43/50\n",
      "98179/98179 [==============================] - 9s 89us/step - loss: 2.8331 - acc: 0.3273 - val_loss: 5.8528 - val_acc: 0.0898\n",
      "Epoch 44/50\n",
      "98179/98179 [==============================] - 9s 89us/step - loss: 2.8143 - acc: 0.3307 - val_loss: 5.8677 - val_acc: 0.0843\n",
      "Epoch 45/50\n",
      "98179/98179 [==============================] - 9s 89us/step - loss: 2.7843 - acc: 0.3355 - val_loss: 5.9683 - val_acc: 0.0829\n",
      "Epoch 46/50\n",
      "98179/98179 [==============================] - 9s 89us/step - loss: 2.7879 - acc: 0.3352 - val_loss: 5.8983 - val_acc: 0.0823\n",
      "Epoch 47/50\n",
      "98179/98179 [==============================] - 9s 89us/step - loss: 2.7629 - acc: 0.3413 - val_loss: 5.9499 - val_acc: 0.0797\n",
      "Epoch 48/50\n",
      "98179/98179 [==============================] - 9s 89us/step - loss: 2.7351 - acc: 0.3454 - val_loss: 5.9754 - val_acc: 0.0842\n",
      "Epoch 49/50\n",
      "98179/98179 [==============================] - 9s 89us/step - loss: 2.7115 - acc: 0.3511 - val_loss: 6.0501 - val_acc: 0.0794\n",
      "Epoch 50/50\n",
      "98179/98179 [==============================] - 9s 89us/step - loss: 2.7084 - acc: 0.3505 - val_loss: 6.0529 - val_acc: 0.0822\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f5e0c1d8d68>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, batch_size=256, epochs=50, verbose=1,\n",
    "          validation_data=(x_val, y_val), callbacks=[tensor_board])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training with distillation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#soft targets\n",
    "temp = 20\n",
    "nb_classes = 200\n",
    "train_soft_targets = soft_targets(temp, teacher_train_logits, nb_classes)\n",
    "val_soft_targets = soft_targets(temp, teacher_val_logits, nb_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train_new = np.concatenate([y_train, train_soft_targets], axis=1)\n",
    "Y_val_new =  np.concatenate([y_val, val_soft_targets], axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_weight = 0.5 * 1 / temp**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00125"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00125"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1 / 800"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp=4\n",
    "#student model:\n",
    "nb_classes = 200\n",
    "student_m = Sequential()\n",
    "student_m.add(Flatten(input_shape=(56,56,3)))\n",
    "student_m.add(Dense(800, activation='relu'))\n",
    "student_m.add(Dense(800, activation='relu'))\n",
    "student_m.add(Dense(nb_classes))\n",
    "#student_m.add(Activation('softmax'))\n",
    "student_m.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "# print(student_m.summary())\n",
    "\n",
    "logits = student_m.layers[-1].output\n",
    "probs = Activation('softmax')(logits)\n",
    "\n",
    "logits_T = Lambda(lambda x: x / temp)(logits)\n",
    "probs_T = Activation('softmax')(logits_T)\n",
    "\n",
    "output = concatenate([probs, probs_T])\n",
    "\n",
    "student_m = Model(student_m.input, output)\n",
    "\n",
    "loss_weight = 0.5 * 1 / temp**2\n",
    "student_m.compile(optimizer='adam',\n",
    "                      loss=lambda y_true, y_pred: knowledge_distillation_loss(y_true, y_pred, loss_weight),\n",
    "                      metrics=[acc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 98179 samples, validate on 9832 samples\n",
      "Epoch 1/100\n",
      "98179/98179 [==============================] - 10s 99us/step - loss: 5.3033 - acc: 0.0373 - val_loss: 5.3029 - val_acc: 0.0548\n",
      "Epoch 2/100\n",
      "98179/98179 [==============================] - 9s 88us/step - loss: 5.3026 - acc: 0.0674 - val_loss: 5.3025 - val_acc: 0.0747\n",
      "Epoch 3/100\n",
      "98179/98179 [==============================] - 9s 89us/step - loss: 5.3023 - acc: 0.0858 - val_loss: 5.3023 - val_acc: 0.0855\n",
      "Epoch 4/100\n",
      "98179/98179 [==============================] - 9s 88us/step - loss: 5.3021 - acc: 0.0987 - val_loss: 5.3022 - val_acc: 0.0928\n",
      "Epoch 5/100\n",
      "98179/98179 [==============================] - 9s 88us/step - loss: 5.3019 - acc: 0.1090 - val_loss: 5.3022 - val_acc: 0.0962\n",
      "Epoch 6/100\n",
      "98179/98179 [==============================] - 9s 88us/step - loss: 5.3018 - acc: 0.1179 - val_loss: 5.3021 - val_acc: 0.1021\n",
      "Epoch 7/100\n",
      "98179/98179 [==============================] - 9s 89us/step - loss: 5.3016 - acc: 0.1266 - val_loss: 5.3020 - val_acc: 0.1037\n",
      "Epoch 8/100\n",
      "98179/98179 [==============================] - 9s 89us/step - loss: 5.3015 - acc: 0.1337 - val_loss: 5.3020 - val_acc: 0.1064\n",
      "Epoch 9/100\n",
      "98179/98179 [==============================] - 9s 88us/step - loss: 5.3014 - acc: 0.1409 - val_loss: 5.3019 - val_acc: 0.1100\n",
      "Epoch 10/100\n",
      "98179/98179 [==============================] - 9s 90us/step - loss: 5.3013 - acc: 0.1464 - val_loss: 5.3019 - val_acc: 0.1116\n",
      "Epoch 11/100\n",
      "98179/98179 [==============================] - 9s 90us/step - loss: 5.3012 - acc: 0.1534 - val_loss: 5.3019 - val_acc: 0.1155\n",
      "Epoch 12/100\n",
      "98179/98179 [==============================] - 9s 88us/step - loss: 5.3012 - acc: 0.1602 - val_loss: 5.3019 - val_acc: 0.1167\n",
      "Epoch 13/100\n",
      "98179/98179 [==============================] - 9s 88us/step - loss: 5.3011 - acc: 0.1668 - val_loss: 5.3019 - val_acc: 0.1119\n",
      "Epoch 14/100\n",
      "98179/98179 [==============================] - 9s 88us/step - loss: 5.3010 - acc: 0.1708 - val_loss: 5.3018 - val_acc: 0.1192\n",
      "Epoch 15/100\n",
      "98179/98179 [==============================] - 9s 88us/step - loss: 5.3010 - acc: 0.1774 - val_loss: 5.3019 - val_acc: 0.1141\n",
      "Epoch 16/100\n",
      "98179/98179 [==============================] - 9s 88us/step - loss: 5.3009 - acc: 0.1832 - val_loss: 5.3019 - val_acc: 0.1181\n",
      "Epoch 17/100\n",
      "98179/98179 [==============================] - 9s 88us/step - loss: 5.3008 - acc: 0.1879 - val_loss: 5.3018 - val_acc: 0.1196\n",
      "Epoch 18/100\n",
      "98179/98179 [==============================] - 9s 89us/step - loss: 5.3008 - acc: 0.1940 - val_loss: 5.3019 - val_acc: 0.1170\n",
      "Epoch 19/100\n",
      "98179/98179 [==============================] - 9s 88us/step - loss: 5.3007 - acc: 0.1989 - val_loss: 5.3019 - val_acc: 0.1156\n",
      "Epoch 20/100\n",
      "98179/98179 [==============================] - 9s 88us/step - loss: 5.3006 - acc: 0.2042 - val_loss: 5.3019 - val_acc: 0.1201\n",
      "Epoch 21/100\n",
      "98179/98179 [==============================] - 9s 88us/step - loss: 5.3006 - acc: 0.2110 - val_loss: 5.3019 - val_acc: 0.1188\n",
      "Epoch 22/100\n",
      "98179/98179 [==============================] - 9s 88us/step - loss: 5.3005 - acc: 0.2146 - val_loss: 5.3019 - val_acc: 0.1209\n",
      "Epoch 23/100\n",
      "98179/98179 [==============================] - 9s 88us/step - loss: 5.3005 - acc: 0.2187 - val_loss: 5.3020 - val_acc: 0.1154\n",
      "Epoch 24/100\n",
      "98179/98179 [==============================] - 9s 89us/step - loss: 5.3004 - acc: 0.2247 - val_loss: 5.3019 - val_acc: 0.1173\n",
      "Epoch 25/100\n",
      "98179/98179 [==============================] - 9s 88us/step - loss: 5.3004 - acc: 0.2297 - val_loss: 5.3021 - val_acc: 0.1150\n",
      "Epoch 26/100\n",
      "98179/98179 [==============================] - 9s 89us/step - loss: 5.3003 - acc: 0.2348 - val_loss: 5.3020 - val_acc: 0.1162\n",
      "Epoch 27/100\n",
      "98179/98179 [==============================] - 9s 88us/step - loss: 5.3003 - acc: 0.2368 - val_loss: 5.3022 - val_acc: 0.1117\n",
      "Epoch 28/100\n",
      "98179/98179 [==============================] - 9s 88us/step - loss: 5.3003 - acc: 0.2404 - val_loss: 5.3021 - val_acc: 0.1168\n",
      "Epoch 29/100\n",
      "98179/98179 [==============================] - 9s 88us/step - loss: 5.3002 - acc: 0.2458 - val_loss: 5.3021 - val_acc: 0.1149\n",
      "Epoch 30/100\n",
      "98179/98179 [==============================] - 9s 88us/step - loss: 5.3002 - acc: 0.2499 - val_loss: 5.3021 - val_acc: 0.1168\n",
      "Epoch 31/100\n",
      "98179/98179 [==============================] - 9s 88us/step - loss: 5.3001 - acc: 0.2550 - val_loss: 5.3021 - val_acc: 0.1157\n",
      "Epoch 32/100\n",
      "98179/98179 [==============================] - 9s 88us/step - loss: 5.3001 - acc: 0.2587 - val_loss: 5.3021 - val_acc: 0.1145\n",
      "Epoch 33/100\n",
      "98179/98179 [==============================] - 9s 88us/step - loss: 5.3001 - acc: 0.2607 - val_loss: 5.3021 - val_acc: 0.1162\n",
      "Epoch 34/100\n",
      "98179/98179 [==============================] - 9s 88us/step - loss: 5.3000 - acc: 0.2661 - val_loss: 5.3022 - val_acc: 0.1175\n",
      "Epoch 35/100\n",
      "98179/98179 [==============================] - 9s 88us/step - loss: 5.3000 - acc: 0.2682 - val_loss: 5.3021 - val_acc: 0.1145\n",
      "Epoch 36/100\n",
      "98179/98179 [==============================] - 9s 88us/step - loss: 5.2999 - acc: 0.2725 - val_loss: 5.3023 - val_acc: 0.1124\n",
      "Epoch 37/100\n",
      "98179/98179 [==============================] - 9s 88us/step - loss: 5.2999 - acc: 0.2788 - val_loss: 5.3021 - val_acc: 0.1151\n",
      "Epoch 38/100\n",
      "98179/98179 [==============================] - 9s 88us/step - loss: 5.2999 - acc: 0.2818 - val_loss: 5.3023 - val_acc: 0.1090\n",
      "Epoch 39/100\n",
      "98179/98179 [==============================] - 9s 88us/step - loss: 5.2999 - acc: 0.2811 - val_loss: 5.3023 - val_acc: 0.1104\n",
      "Epoch 40/100\n",
      "98179/98179 [==============================] - 9s 88us/step - loss: 5.2998 - acc: 0.2851 - val_loss: 5.3023 - val_acc: 0.1097\n",
      "Epoch 41/100\n",
      "98179/98179 [==============================] - 9s 88us/step - loss: 5.2998 - acc: 0.2907 - val_loss: 5.3022 - val_acc: 0.1118\n",
      "Epoch 42/100\n",
      "98179/98179 [==============================] - 9s 88us/step - loss: 5.2997 - acc: 0.2933 - val_loss: 5.3023 - val_acc: 0.1081\n",
      "Epoch 43/100\n",
      "98179/98179 [==============================] - 9s 88us/step - loss: 5.2997 - acc: 0.2955 - val_loss: 5.3023 - val_acc: 0.1128\n",
      "Epoch 44/100\n",
      "98179/98179 [==============================] - 9s 88us/step - loss: 5.2997 - acc: 0.3012 - val_loss: 5.3023 - val_acc: 0.1117\n",
      "Epoch 45/100\n",
      "98179/98179 [==============================] - 9s 89us/step - loss: 5.2997 - acc: 0.3016 - val_loss: 5.3025 - val_acc: 0.1097\n",
      "Epoch 46/100\n",
      "98179/98179 [==============================] - 9s 88us/step - loss: 5.2996 - acc: 0.3082 - val_loss: 5.3024 - val_acc: 0.1084\n",
      "Epoch 47/100\n",
      "98179/98179 [==============================] - 9s 88us/step - loss: 5.2996 - acc: 0.3106 - val_loss: 5.3024 - val_acc: 0.1110\n",
      "Epoch 48/100\n",
      "98179/98179 [==============================] - 9s 88us/step - loss: 5.2995 - acc: 0.3139 - val_loss: 5.3023 - val_acc: 0.1120\n",
      "Epoch 49/100\n",
      "98179/98179 [==============================] - 9s 88us/step - loss: 5.2995 - acc: 0.3126 - val_loss: 5.3023 - val_acc: 0.1108\n",
      "Epoch 50/100\n",
      "98179/98179 [==============================] - 9s 87us/step - loss: 5.2995 - acc: 0.3207 - val_loss: 5.3024 - val_acc: 0.1090\n",
      "Epoch 51/100\n",
      "98179/98179 [==============================] - 9s 88us/step - loss: 5.2995 - acc: 0.3201 - val_loss: 5.3024 - val_acc: 0.1076\n",
      "Epoch 52/100\n",
      "98179/98179 [==============================] - 9s 88us/step - loss: 5.2994 - acc: 0.3229 - val_loss: 5.3025 - val_acc: 0.1120\n",
      "Epoch 53/100\n",
      "98179/98179 [==============================] - 9s 88us/step - loss: 5.2994 - acc: 0.3262 - val_loss: 5.3024 - val_acc: 0.1047\n",
      "Epoch 54/100\n",
      "98179/98179 [==============================] - 9s 88us/step - loss: 5.2994 - acc: 0.3295 - val_loss: 5.3025 - val_acc: 0.1077\n",
      "Epoch 55/100\n",
      "98179/98179 [==============================] - 9s 88us/step - loss: 5.2994 - acc: 0.3325 - val_loss: 5.3024 - val_acc: 0.1091\n",
      "Epoch 56/100\n",
      "98179/98179 [==============================] - 9s 88us/step - loss: 5.2993 - acc: 0.3337 - val_loss: 5.3025 - val_acc: 0.1100\n",
      "Epoch 57/100\n",
      "98179/98179 [==============================] - 9s 88us/step - loss: 5.2993 - acc: 0.3373 - val_loss: 5.3025 - val_acc: 0.1095\n",
      "Epoch 58/100\n",
      "98179/98179 [==============================] - 9s 88us/step - loss: 5.2993 - acc: 0.3425 - val_loss: 5.3025 - val_acc: 0.1097\n",
      "Epoch 59/100\n",
      "98179/98179 [==============================] - 9s 88us/step - loss: 5.2992 - acc: 0.3442 - val_loss: 5.3026 - val_acc: 0.1061\n",
      "Epoch 60/100\n",
      "98179/98179 [==============================] - 9s 88us/step - loss: 5.2992 - acc: 0.3450 - val_loss: 5.3027 - val_acc: 0.1110\n",
      "Epoch 61/100\n",
      "98179/98179 [==============================] - 9s 88us/step - loss: 5.2992 - acc: 0.3485 - val_loss: 5.3026 - val_acc: 0.1057\n",
      "Epoch 62/100\n",
      "98179/98179 [==============================] - 9s 88us/step - loss: 5.2992 - acc: 0.3511 - val_loss: 5.3027 - val_acc: 0.1030\n",
      "Epoch 63/100\n",
      "98179/98179 [==============================] - 9s 88us/step - loss: 5.2991 - acc: 0.3543 - val_loss: 5.3026 - val_acc: 0.1014\n",
      "Epoch 64/100\n",
      "98179/98179 [==============================] - 9s 88us/step - loss: 5.2991 - acc: 0.3568 - val_loss: 5.3028 - val_acc: 0.1040\n",
      "Epoch 65/100\n",
      "98179/98179 [==============================] - 9s 88us/step - loss: 5.2991 - acc: 0.3581 - val_loss: 5.3028 - val_acc: 0.1075\n",
      "Epoch 66/100\n",
      "98179/98179 [==============================] - 9s 88us/step - loss: 5.2991 - acc: 0.3605 - val_loss: 5.3028 - val_acc: 0.1084\n",
      "Epoch 67/100\n",
      "98179/98179 [==============================] - 9s 88us/step - loss: 5.2991 - acc: 0.3656 - val_loss: 5.3027 - val_acc: 0.1061\n",
      "Epoch 68/100\n",
      "98179/98179 [==============================] - 9s 88us/step - loss: 5.2990 - acc: 0.3671 - val_loss: 5.3027 - val_acc: 0.1059\n",
      "Epoch 69/100\n",
      "98179/98179 [==============================] - 9s 88us/step - loss: 5.2990 - acc: 0.3687 - val_loss: 5.3028 - val_acc: 0.1058\n",
      "Epoch 70/100\n",
      "98179/98179 [==============================] - 9s 88us/step - loss: 5.2990 - acc: 0.3712 - val_loss: 5.3028 - val_acc: 0.1055\n",
      "Epoch 71/100\n",
      "98179/98179 [==============================] - 9s 88us/step - loss: 5.2990 - acc: 0.3724 - val_loss: 5.3027 - val_acc: 0.1076\n",
      "Epoch 72/100\n",
      "98179/98179 [==============================] - 9s 88us/step - loss: 5.2990 - acc: 0.3750 - val_loss: 5.3030 - val_acc: 0.1044\n",
      "Epoch 73/100\n",
      "98179/98179 [==============================] - 9s 88us/step - loss: 5.2990 - acc: 0.3765 - val_loss: 5.3028 - val_acc: 0.1047\n",
      "Epoch 74/100\n",
      "98179/98179 [==============================] - 9s 88us/step - loss: 5.2989 - acc: 0.3768 - val_loss: 5.3028 - val_acc: 0.1031\n",
      "Epoch 75/100\n",
      "98179/98179 [==============================] - 9s 88us/step - loss: 5.2989 - acc: 0.3818 - val_loss: 5.3029 - val_acc: 0.1011\n",
      "Epoch 76/100\n",
      "98179/98179 [==============================] - 9s 88us/step - loss: 5.2989 - acc: 0.3826 - val_loss: 5.3029 - val_acc: 0.1012\n",
      "Epoch 77/100\n",
      "98179/98179 [==============================] - 9s 88us/step - loss: 5.2989 - acc: 0.3877 - val_loss: 5.3029 - val_acc: 0.1010\n",
      "Epoch 78/100\n",
      "98179/98179 [==============================] - 9s 88us/step - loss: 5.2988 - acc: 0.3876 - val_loss: 5.3030 - val_acc: 0.0997\n",
      "Epoch 79/100\n",
      "98179/98179 [==============================] - 9s 88us/step - loss: 5.2988 - acc: 0.3889 - val_loss: 5.3029 - val_acc: 0.1017\n",
      "Epoch 80/100\n",
      "98179/98179 [==============================] - 9s 90us/step - loss: 5.2988 - acc: 0.3887 - val_loss: 5.3029 - val_acc: 0.1029\n",
      "Epoch 81/100\n",
      "98179/98179 [==============================] - 9s 88us/step - loss: 5.2988 - acc: 0.3930 - val_loss: 5.3030 - val_acc: 0.1004\n",
      "Epoch 82/100\n",
      "98179/98179 [==============================] - 9s 88us/step - loss: 5.2988 - acc: 0.3930 - val_loss: 5.3029 - val_acc: 0.1021\n",
      "Epoch 83/100\n",
      "98179/98179 [==============================] - 9s 88us/step - loss: 5.2988 - acc: 0.3963 - val_loss: 5.3029 - val_acc: 0.1010\n",
      "Epoch 84/100\n",
      "98179/98179 [==============================] - 9s 89us/step - loss: 5.2987 - acc: 0.4009 - val_loss: 5.3029 - val_acc: 0.1036\n",
      "Epoch 85/100\n",
      "98179/98179 [==============================] - 9s 88us/step - loss: 5.2987 - acc: 0.3995 - val_loss: 5.3029 - val_acc: 0.1038\n",
      "Epoch 86/100\n",
      "98179/98179 [==============================] - 9s 88us/step - loss: 5.2987 - acc: 0.4021 - val_loss: 5.3031 - val_acc: 0.1013\n",
      "Epoch 87/100\n",
      "98179/98179 [==============================] - 9s 87us/step - loss: 5.2987 - acc: 0.4060 - val_loss: 5.3031 - val_acc: 0.1019\n",
      "Epoch 88/100\n",
      "98179/98179 [==============================] - 9s 88us/step - loss: 5.2987 - acc: 0.4066 - val_loss: 5.3032 - val_acc: 0.1021\n",
      "Epoch 89/100\n",
      "98179/98179 [==============================] - 9s 87us/step - loss: 5.2987 - acc: 0.4068 - val_loss: 5.3031 - val_acc: 0.1026\n",
      "Epoch 90/100\n",
      "98179/98179 [==============================] - 9s 88us/step - loss: 5.2987 - acc: 0.4093 - val_loss: 5.3030 - val_acc: 0.0977\n",
      "Epoch 91/100\n",
      "98179/98179 [==============================] - 9s 89us/step - loss: 5.2986 - acc: 0.4124 - val_loss: 5.3030 - val_acc: 0.1001\n",
      "Epoch 92/100\n",
      "98179/98179 [==============================] - 9s 88us/step - loss: 5.2986 - acc: 0.4143 - val_loss: 5.3031 - val_acc: 0.1047\n",
      "Epoch 93/100\n",
      "98179/98179 [==============================] - 9s 88us/step - loss: 5.2986 - acc: 0.4139 - val_loss: 5.3031 - val_acc: 0.0989\n",
      "Epoch 94/100\n",
      "98179/98179 [==============================] - 9s 88us/step - loss: 5.2986 - acc: 0.4166 - val_loss: 5.3030 - val_acc: 0.0984\n",
      "Epoch 95/100\n",
      "98179/98179 [==============================] - 9s 88us/step - loss: 5.2986 - acc: 0.4187 - val_loss: 5.3032 - val_acc: 0.0989\n",
      "Epoch 96/100\n",
      "98179/98179 [==============================] - 9s 88us/step - loss: 5.2985 - acc: 0.4222 - val_loss: 5.3032 - val_acc: 0.0991\n",
      "Epoch 97/100\n",
      "98179/98179 [==============================] - 9s 88us/step - loss: 5.2986 - acc: 0.4222 - val_loss: 5.3032 - val_acc: 0.1007\n",
      "Epoch 98/100\n",
      "98179/98179 [==============================] - 9s 88us/step - loss: 5.2985 - acc: 0.4250 - val_loss: 5.3032 - val_acc: 0.1010\n",
      "Epoch 99/100\n",
      "98179/98179 [==============================] - 9s 88us/step - loss: 5.2985 - acc: 0.4227 - val_loss: 5.3031 - val_acc: 0.0972\n",
      "Epoch 100/100\n",
      "98179/98179 [==============================] - 9s 87us/step - loss: 5.2985 - acc: 0.4288 - val_loss: 5.3032 - val_acc: 0.1007\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f5da6e53c18>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "student_m.fit(x_train, Y_train_new,\n",
    "              batch_size=256,\n",
    "              epochs=100,\n",
    "              verbose=1,\n",
    "              validation_data= (x_val, Y_val_new))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 98179 samples, validate on 9832 samples\n",
      "Epoch 1/50\n",
      "98179/98179 [==============================] - 8s 82us/step - loss: 10.5376 - acc: 0.0152 - val_loss: 10.4530 - val_acc: 0.0235\n",
      "Epoch 2/50\n",
      "98179/98179 [==============================] - 7s 71us/step - loss: 10.3702 - acc: 0.0283 - val_loss: 10.3034 - val_acc: 0.0328\n",
      "Epoch 3/50\n",
      "98179/98179 [==============================] - 6s 65us/step - loss: 10.2514 - acc: 0.0381 - val_loss: 10.2276 - val_acc: 0.0374\n",
      "Epoch 4/50\n",
      "98179/98179 [==============================] - 7s 69us/step - loss: 10.1776 - acc: 0.0463 - val_loss: 10.1702 - val_acc: 0.0451\n",
      "Epoch 5/50\n",
      "98179/98179 [==============================] - 7s 70us/step - loss: 10.1177 - acc: 0.0531 - val_loss: 10.1226 - val_acc: 0.0513\n",
      "Epoch 6/50\n",
      "98179/98179 [==============================] - 7s 70us/step - loss: 10.0665 - acc: 0.0585 - val_loss: 10.0894 - val_acc: 0.0561\n",
      "Epoch 7/50\n",
      "98179/98179 [==============================] - 7s 69us/step - loss: 10.0235 - acc: 0.0636 - val_loss: 10.0491 - val_acc: 0.0593\n",
      "Epoch 8/50\n",
      "98179/98179 [==============================] - 7s 68us/step - loss: 9.9850 - acc: 0.0692 - val_loss: 10.0290 - val_acc: 0.0611\n",
      "Epoch 9/50\n",
      "98179/98179 [==============================] - 7s 68us/step - loss: 9.9522 - acc: 0.0733 - val_loss: 10.0015 - val_acc: 0.0657\n",
      "Epoch 10/50\n",
      "98179/98179 [==============================] - 7s 68us/step - loss: 9.9227 - acc: 0.0771 - val_loss: 9.9869 - val_acc: 0.0677\n",
      "Epoch 11/50\n",
      "98179/98179 [==============================] - 7s 68us/step - loss: 9.8958 - acc: 0.0804 - val_loss: 9.9724 - val_acc: 0.0711\n",
      "Epoch 12/50\n",
      "98179/98179 [==============================] - 7s 67us/step - loss: 9.8715 - acc: 0.0842 - val_loss: 9.9656 - val_acc: 0.0699\n",
      "Epoch 13/50\n",
      "98179/98179 [==============================] - 7s 68us/step - loss: 9.8480 - acc: 0.0876 - val_loss: 9.9299 - val_acc: 0.0789\n",
      "Epoch 14/50\n",
      "98179/98179 [==============================] - 7s 68us/step - loss: 9.8242 - acc: 0.0908 - val_loss: 9.9199 - val_acc: 0.0778\n",
      "Epoch 15/50\n",
      "98179/98179 [==============================] - 7s 68us/step - loss: 9.8030 - acc: 0.0935 - val_loss: 9.9103 - val_acc: 0.0774\n",
      "Epoch 16/50\n",
      "98179/98179 [==============================] - 7s 68us/step - loss: 9.7822 - acc: 0.0968 - val_loss: 9.8985 - val_acc: 0.0769\n",
      "Epoch 17/50\n",
      "98179/98179 [==============================] - 7s 68us/step - loss: 9.7614 - acc: 0.1006 - val_loss: 9.8896 - val_acc: 0.0792\n",
      "Epoch 18/50\n",
      "98179/98179 [==============================] - 7s 68us/step - loss: 9.7420 - acc: 0.1014 - val_loss: 9.8794 - val_acc: 0.0835\n",
      "Epoch 19/50\n",
      "98179/98179 [==============================] - 7s 68us/step - loss: 9.7216 - acc: 0.1057 - val_loss: 9.8912 - val_acc: 0.0815\n",
      "Epoch 20/50\n",
      "98179/98179 [==============================] - 7s 67us/step - loss: 9.7035 - acc: 0.1080 - val_loss: 9.8603 - val_acc: 0.0864\n",
      "Epoch 21/50\n",
      "98179/98179 [==============================] - 7s 68us/step - loss: 9.6835 - acc: 0.1095 - val_loss: 9.8519 - val_acc: 0.0881\n",
      "Epoch 22/50\n",
      "98179/98179 [==============================] - 7s 68us/step - loss: 9.6653 - acc: 0.1134 - val_loss: 9.8346 - val_acc: 0.0890\n",
      "Epoch 23/50\n",
      "98179/98179 [==============================] - 7s 69us/step - loss: 9.6473 - acc: 0.1146 - val_loss: 9.8319 - val_acc: 0.0905\n",
      "Epoch 24/50\n",
      "98179/98179 [==============================] - 7s 68us/step - loss: 9.6298 - acc: 0.1188 - val_loss: 9.8238 - val_acc: 0.0922\n",
      "Epoch 25/50\n",
      "98179/98179 [==============================] - 7s 69us/step - loss: 9.6125 - acc: 0.1203 - val_loss: 9.8155 - val_acc: 0.0942\n",
      "Epoch 26/50\n",
      "98179/98179 [==============================] - 7s 68us/step - loss: 9.5947 - acc: 0.1230 - val_loss: 9.8157 - val_acc: 0.0896\n",
      "Epoch 27/50\n",
      "98179/98179 [==============================] - 7s 68us/step - loss: 9.5785 - acc: 0.1258 - val_loss: 9.8088 - val_acc: 0.0946\n",
      "Epoch 28/50\n",
      "98179/98179 [==============================] - 7s 68us/step - loss: 9.5614 - acc: 0.1277 - val_loss: 9.7950 - val_acc: 0.0947\n",
      "Epoch 29/50\n",
      "98179/98179 [==============================] - 7s 68us/step - loss: 9.5445 - acc: 0.1296 - val_loss: 9.7897 - val_acc: 0.0987\n",
      "Epoch 30/50\n",
      "98179/98179 [==============================] - 7s 68us/step - loss: 9.5278 - acc: 0.1322 - val_loss: 9.7966 - val_acc: 0.0983\n",
      "Epoch 31/50\n",
      "98179/98179 [==============================] - 7s 68us/step - loss: 9.5107 - acc: 0.1351 - val_loss: 9.8186 - val_acc: 0.0948\n",
      "Epoch 32/50\n",
      "98179/98179 [==============================] - 7s 68us/step - loss: 9.4950 - acc: 0.1376 - val_loss: 9.7804 - val_acc: 0.0985\n",
      "Epoch 33/50\n",
      "98179/98179 [==============================] - 7s 71us/step - loss: 9.4780 - acc: 0.1404 - val_loss: 9.7659 - val_acc: 0.0983\n",
      "Epoch 34/50\n",
      "98179/98179 [==============================] - 7s 68us/step - loss: 9.4626 - acc: 0.1428 - val_loss: 9.7664 - val_acc: 0.0997\n",
      "Epoch 35/50\n",
      "98179/98179 [==============================] - 7s 68us/step - loss: 9.4464 - acc: 0.1449 - val_loss: 9.7753 - val_acc: 0.1012\n",
      "Epoch 36/50\n",
      "98179/98179 [==============================] - 7s 68us/step - loss: 9.4303 - acc: 0.1483 - val_loss: 9.7609 - val_acc: 0.1007\n",
      "Epoch 37/50\n",
      "98179/98179 [==============================] - 7s 68us/step - loss: 9.4133 - acc: 0.1502 - val_loss: 9.7621 - val_acc: 0.0992\n",
      "Epoch 38/50\n",
      "98179/98179 [==============================] - 7s 69us/step - loss: 9.3989 - acc: 0.1524 - val_loss: 9.7594 - val_acc: 0.0996\n",
      "Epoch 39/50\n",
      "98179/98179 [==============================] - 7s 68us/step - loss: 9.3812 - acc: 0.1550 - val_loss: 9.7568 - val_acc: 0.1007\n",
      "Epoch 40/50\n",
      "98179/98179 [==============================] - 7s 68us/step - loss: 9.3659 - acc: 0.1579 - val_loss: 9.7555 - val_acc: 0.1007\n",
      "Epoch 41/50\n",
      "98179/98179 [==============================] - 7s 68us/step - loss: 9.3479 - acc: 0.1611 - val_loss: 9.7578 - val_acc: 0.0994\n",
      "Epoch 42/50\n",
      "98179/98179 [==============================] - 7s 69us/step - loss: 9.3320 - acc: 0.1628 - val_loss: 9.7448 - val_acc: 0.1020\n",
      "Epoch 43/50\n",
      "98179/98179 [==============================] - 7s 68us/step - loss: 9.3159 - acc: 0.1657 - val_loss: 9.7571 - val_acc: 0.1017\n",
      "Epoch 44/50\n",
      "98179/98179 [==============================] - 7s 68us/step - loss: 9.2996 - acc: 0.1676 - val_loss: 9.7318 - val_acc: 0.1028\n",
      "Epoch 45/50\n",
      "98179/98179 [==============================] - 7s 68us/step - loss: 9.2839 - acc: 0.1707 - val_loss: 9.7323 - val_acc: 0.1032\n",
      "Epoch 46/50\n",
      "98179/98179 [==============================] - 7s 68us/step - loss: 9.2678 - acc: 0.1730 - val_loss: 9.7315 - val_acc: 0.1049\n",
      "Epoch 47/50\n",
      "98179/98179 [==============================] - 7s 68us/step - loss: 9.2493 - acc: 0.1763 - val_loss: 9.7191 - val_acc: 0.1051\n",
      "Epoch 48/50\n",
      "98179/98179 [==============================] - 7s 67us/step - loss: 9.2330 - acc: 0.1786 - val_loss: 9.7143 - val_acc: 0.1073\n",
      "Epoch 49/50\n",
      "98179/98179 [==============================] - 7s 68us/step - loss: 9.2158 - acc: 0.1801 - val_loss: 9.7201 - val_acc: 0.1056\n",
      "Epoch 50/50\n",
      "98179/98179 [==============================] - 7s 68us/step - loss: 9.2001 - acc: 0.1841 - val_loss: 9.7379 - val_acc: 0.1036\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f987784beb8>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "student_m.fit(x_train, Y_train_new,\n",
    "              batch_size=256,\n",
    "              epochs=50,\n",
    "              verbose=1,\n",
    "              validation_data= (x_val, Y_val_new))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
